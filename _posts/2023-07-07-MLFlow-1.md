---
layout: post
title:  "Introduction to MLflow"
author: seungki
categories: [ MLflow, MLops ]
image: post_images/MLflow-logo-696x395-1.png
toc: True

---
---
## MLFlow로 해결할 Pain Point
1. 실험 추적이 어렵다
2. 코드 재현이 어렵다
3. 모델 패키징 및 배포가 어렵다
4. 모델을 관리하기 위한 중앙 저장소가 없다

### 그럼 MLFlow란?

* 머신러닝 실험, 배포를 쉽게 관리할 수 있는 오픈 소스
* CLI, GUI(웹 인터페이스) 지원

### Example

```python
from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV

import mlflow

def main():
    mlflow.sklearn.autolog()

    iris = datasets.load_iris()
    parameters = {"kernel": ("linear", "rbf"), "C": [1, 10]}
    svc = svm.SVC()
    clf = GridSearchCV(svc, parameters)

    with mlflow.start_run() as run:
        clf.fit(iris.data, iris.target)

if __name__ == "__main__":
    main()
```

---

## MLFlow의 핵심 기능

1. Experiment Management & Tracking
   * 머신러닝 관련 실험들을 관리하고, 각 실험의 내용 기록
     * 여러 사람이 하나의 mlflow 서버 위에서 각자 자기 실험을 만들고 공유 할 수 있음
   * 실험을 정의하고 실험을 실행 할 수 있음, 실행은 머신러닝 훈련코드를 실행한 기록
     * 각 실행에 사용한 소스코드, 하이퍼 파라미터, metric, 부산물(artifact, image..) 등을 저장
2. Model Registry
   * MLflow로 실행한 머신러닝 모델을 Model registry(모델 저장소)에 등록 가능
   * 모델 저장소에 모델이 저장될 때마다 해당 모델에 버전이 자동으로 올라감
   * 모델 저장소에 등록된 모델은 다른 사람들에게 쉽게 공유 가능
3. Model Serving
   * Model Registry에 등록한 모델을 REST API형태의 서버로 serving 가능
   * Input == 모델의 Input
   * Output == 모델의 Output
   * 직접 도커 이미지를 만들지 않아도 생성 가능

---

## MLflow Component

1. MLflow Tracking
   * 머신러닝 코드 실행, 로깅을 위한 api, ui
   * MLflow Tracking을 사용해 결과를 local, server에 기록해 여러 실행과 비교 가능
   * 팀에선 다른 사용자의 결과와 비교하며 협업가능
2. MLflow Project
   * 머신러닝 프로젝트 코드를 패키징하기 위한 표준
   * Project
     * 간단하게 소스 코드가 저장된 폴더
     * Git repo
     * 의존성과 어떻게 실행해야 하는지 저장
   * MLflow Tracking API를 사용하면 MLflow는 프로젝트 버전을 모든 파라미터와 자동으로 로깅

3. MLflow Model
   * 모델은 모델 파일과 코드로 저장
   * 다양한 플랫폼에 배포할 수 있는 여러 도구 제공
   * MLflow Tracking API를 사용하면 MLflow는 자동으로 해당 프로젝트에 대한 내용을 사용함
4. MLflow Registry
   * MLflow Model의 전체 lifecycle에서 사용할 수 있는 중앙 모델 저장소

---

## MLflow 사용하기

```pip install mlflow```

### 1. Experiment 생성

* 하나의 Experiment는 진행하고 있는 머신러닝 프로젝트 단위로 구성
  * 개/고양이 분류 실험, 수요량 예측 실험 ..
* 정해진 Metric으로 모델 평가
  * RMSE, MSE, MAE, Accuracy..
* 하나의 실험 여러개의 run

```mlflow experiments create --experiment-name my-first-experiment``` : Experiment 생성

```ls -al```로 mlruns 폴더 확인

```mlflow experiments search``` : 생성한 experiments 목록 확인 (list는 현재 deprecated)

```pip install numpy sklearn``` : 모델에 필요한 라이브러리 설치 (상황 마다 바뀜)

```mkdir logistic_regression ``` : 폴더 생성

```vi logistic_regression/train.py``` : 머신러닝 코드 생성

#### train.py

```python
import numpy as np
from sklearn.linear_model import LogisticRegression

import mlflow
import mlflow.sklearn

if __name__ == "__main__":
    X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)
    y = np.array([0, 0, 1, 1, 1, 0])

    penalty = "elasticnet"
    l1_ratio = 0.1
    lr = LogisticRegression(penalty=penalty, l1_ratio=l1_ratio, solver="saga")

    lr.fit(X, y)

    score = lr.score(X, y)
    print("Score: %s" % score)
   
  # auto 나오기 전에는 이렇게 사용했음
    mlflow.log_param("penalty", penalty)
    mlflow.log_param("l1_ratio", l1_ratio)
    mlflow.log_metric("score", score)
    mlflow.sklearn.log_model(lr, "model")
```



### 2. MLProject

* Mlflow를 사용한 코드의 프로젝트 메타 정보 저장
* 프로젝트를 어떤 환경에서 어떻게 실행시킬지 정의
* 패키지 모듈의 상단에 위치
* 이름은 MLProject 라는 이름을 꼭 사용해야함

``` vi logistic_regression/MLProject ```: MLProject 생성

 #### MLProject

``` 
name: tutorial

entry_points:
    main:
        command: "python train.py"
```



### 3. Run

* 하나의 Run은 코드를 1번 실행한 것을 의미
* 보통 Run은 모델 학습 코드를 실행
* 한번의 코드 실행 == 하나의 Run 생성
* Run을 하면 여러가지 내용이 기록됨
  * source : 실행한 project의 이름
  * version : 실행 Hash
  * start & end time
  * parameters : 모든 파라미터
  * metrics : 모델의 평가 지표, metric 시각화
  * tags
  * artifacts : 실행과정에서 생기는 다양한 파일들(이미지, 모델 피클 ..)

```mlflow run logistic_regression --experiment-name my-first-experiment --env-manager {환경} ``` : Run으로 실행

![스크린샷 2023-07-05 오후 1.18.40](../post_images/2023-07-07-MLFlow-1/스크린샷 2023-07-05 오후 1.18.40.png)

```mlflow ui``` : UI 실헹

---

## MLflow Autolog

> Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements.

* 파라미터를 매번 명시하는게 귀찮음
* 자동으로 로깅을 해줌
* 모든 프레임 워크에서 사용가능한 것은 아님!
  * pytorch.nn.Module 지원 x, pytorch lightning은 지원 .. 

---

## MLflow 배포하기

### MLflow Architecture

1. Python Code(with MLflow package)
   * 모델을 만들고 학습하는 코드
   * MLflow run으로 실행
2. Tracking Server
   * 파이썬 코드가 실행되는 동안 parameter, metric, model 등 메타 정보 저장
   * 파일 혹은 DB에 저장
     * Tracking server는 결국 DB를 바라봄
3. Artifact Store
   * 파이썬 코드가 실행되는 동안 생기는 model file, image 등의 아티팩트를 저장
   * 파일 혹은 스토리지에 저장
     * Artifact Store는 결국 storage를 바라봄

```mlflow server --backend-store-uri {uri} --default-artifact-root {}``` : mlflow server 명령어로 Backend Store URI 지정가능



<img src="../post_images/2023-07-07-MLFlow-1/스크린샷 2023-07-05 오후 1.47.26.png" alt="스크린샷 2023-07-05 오후 1.47.26" style="zoom:67%;" class="center-image"/>

---

## MLflow 실제 Use Case

MLflow Tracking Server는 하나로 통합 운영

* Tracking Server를 하나 배포하고, 팀 내 모든 리서처가 이 Tracking Server에 실험 기록
  * 배포할 때는 Docker Image, Kubernetes 등에 진행(회사 인프라에 따라 다름)

* 로그나 모델이 한 곳에 저장되므로 팀 내 모든 실험을 공유 가능
* Artifact Storage는 GCS나 S3 같은 스토리지 사용
* DB는 CloudSQL이나 Aurora RDS 같은 DB 사용
* 두 저장소는 Tracking Server에 의해 관리

<br>

## 참고

---

1. [https://github.com/zzsza](https://github.com/zzsza)
2. Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤)
3. [https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html)
