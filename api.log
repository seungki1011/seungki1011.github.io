/Users/seungkikim/.pyenv/versions/3.10.0/bin/python: can't open file '/Users/seungkikim/Desktop/seungki1011.github.io/fetch-post/get_reddit_posts.py': [Errno 1] Operation not permitted
/Users/seungkikim/.pyenv/versions/3.10.0/bin/python: can't open file '/Users/seungkikim/Desktop/seungki1011.github.io/fetch-post/get_reddit_posts.py': [Errno 1] Operation not permitted
/Users/seungkikim/.pyenv/versions/3.10.0/bin/python: can't open file '/Users/seungkikim/Desktop/seungki1011.github.io/fetch-post/get_reddit_posts.py': [Errno 1] Operation not permitted
Traceback (most recent call last):
  File "/Users/seungkikim/Desktop/seungki1011.github.io/fetch-post/get_reddit_posts.py", line 11, in <module>
    client_id=os.environ['REDDIT_CLIENT_ID'],
  File "/Users/seungkikim/.pyenv/versions/3.10.0/lib/python3.10/os.py", line 679, in __getitem__
    raise KeyError(key) from None
KeyError: 'REDDIT_CLIENT_ID'
Traceback (most recent call last):
  File "/Users/seungkikim/Desktop/seungki1011.github.io/fetch-post/get_reddit_posts.py", line 6, in <module>
    print(os.environ['REDDIT_CLIENT_ID'])
  File "/Users/seungkikim/.pyenv/versions/3.10.0/lib/python3.10/os.py", line 679, in __getitem__
    raise KeyError(key) from None
KeyError: 'REDDIT_CLIENT_ID'
0xNUaXnjSjBxbZfSUoETmA
uYoYccDYTndSYK_IUv5nh3TSWBaoRg
automatic-post-summarization/v1.0 (by u/OddIncrease8302)
Title: GPT-5 is coming it's codename: Gobi
Content: OpenAI is reportedly accelerating efforts to release an advanced multimodal LLM called GPT-Vision, codenamed **Gobi.**  ([Source](https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm))

**The Promise of Multimodal AI**

* ***Processes Text and Images:*** Multimodal LLMs can understand and generate content combining text and images, offering expanded capabilities.
* **GPT-Vision is stuck in safety reviews:** but “OpenAI’s engineers seem close to satisfying legal concerns.”
* ***Key Edge Over Rivals***: Launching first with multimodal abilities could give OpenAI a critical advantage over competitors.

**OpenAI's Reported Rush to Release Gobi**

* ***Aiming to Beat Google:*** OpenAI seems intent on launching Gobi before Google can debut [Gemini](https://www.theinformation.com/articles/google-nears-release-of-gemini-ai-to-rival-openai) to dominate the multimodal space.
* **Expanding GPT-4's Abilities:** Gobi may build on GPT-4 by adding enhanced visual and multimodal features that OpenAI previewed earlier.
* ***The Enduring Nature of Progress***: Both firms recognize the long-term, competitive nature of AI advancement.

**TL;DR:** OpenAI looks to stay ahead of Google in the AI race by rushing to launch an advanced multimodal LLM before Google's Gemini, a preemptive move that could disrupt Google's plans and ambitions.

**PS:** Get the latest AI developments, tools, and use cases by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16mx186/gpt5_is_coming_its_codename_gobi/
-----
Title: AI that’s smarter than humans? Americans say a firm “no thank you.”
Content: 63% of Americans want regulation to actively prevent superintelligent AI, a new poll reveals.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Public Opinion on Superintelligent AI**

* **Skeptical Majority:** 63% of Americans believe regulation should actively prevent AI superintelligence.
* **Companies' Goals:** Organizations like OpenAI aim to develop artificial general intelligence (AGI), assuming its existence benefits humanity.
* **Voices of Dissent:** Concerns arise that the pursuit of AGI is driven by a select few without public consensus on its potential risks.

**Tech Sector Power and Influence**

* **Historical Ideology:** The belief in technological solutionism, or technology as a solution to major problems, dates back centuries.
* **Modern-Day Acceleration:** Today's tech acceleration in the U.S. is driven by capitalism and the race against foreign powers, championed by Silicon Valley.
* **Disconnect with Public:** Many Americans now distrust tech leaders, associating technological progress with potential societal disruptions.

[Source (Vox)](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,500+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16nnq2c/ai_thats_smarter_than_humans_americans_say_a_firm/
-----
Title: Two-minute Daily AI Update (Date: 09/21/2023): News from OpenAI, Amazon, Google DeepMind, GitHub, Uber, and NVIDIA
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **OpenAI unveils DALL·E 3**  
\- It understands significantly more nuance and detail than its previous systems. DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall. It is built natively on ChatGPT, which lets you use ChatGPT as a brainstorming partner and refiner of your prompts.
* **Amazon brings generative AI to Alexa and Fire TV**  
\- At its annual devices event, Amazon introduced generative AI updates for its Fire TV voice search to bring more conversational ways to interact with Alexa and discover new content.  
\- It will also use a new generative AI model to power improved experiences across its Echo family of devices.
* **Google DeepMind’s ‘Language Modeling Is Compression’**  
\- This paper views the prediction problem through the lens of compression and evaluates the compression capabilities of large (foundation) models. It shows that LLMs are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning.
* **GitHub’s Copilot Chat will now be available to individual users**  
\- It is available in public beta for GitHub Copilot individual users in Visual Studio and Visual Studio Code.
* **Uber Eats to roll out AI-powered assistant**  
\- It will help users find deals and explore different food options seamlessly.
* **NVIDIA to train 50,000 Infosys employees on AI technology**  
\- Infosys will set up NVIDIA Centre of Excellence to train and certify employees on NVIDIA’s AI technologies. Also, NVIDIA’s AI Enterprise ecosystem of models, tools, runtimes, and GPU systems will be brought to Infosys’s AI-first offering Topaz.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/openai-unveils-dalle3-amazon-ai-updates-deepmind).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16oi0cn/twominute_daily_ai_update_date_09212023_news_from/
-----
Title: Google's Bard can now access all of your Google apps
Content: Google today expanded its AI chatbot Bard with new capabilities, allowing it to tap into users' Gmail, Drive, Maps and other Google services. ([Source](https://techcrunch.com/2023/09/19/googles-bard-chatbot-can-now-tap-into-your-google-apps-double-check-answers-and-more/))

**Bard's New Integrations with Google Apps**

* ***Access to Personal Data***: Bard can now pull user information from Gmail, Drive, etc. to customize responses, if users opt in.
* ***Powerful but Concerning:*** This allows for very personalized answers, but some may worry about privacy despite Google's assurances.
* ***Double Checking Responses:*** Users can tap a button to validate Bard's answers against Google Search results.
* ***Collaboration Feature***: People can now build on Bard chats shared via links to collectively ask questions.
* ***Multilingual Expansion:*** Bard's existing capabilities now work in 40 more languages beyond English.

**TL;DR:** Google updated Bard with new features like Gmail integration to boost its capabilities, but needs to carefully balance utility and user trust. It also expanded language support as it continues working to improve Bard.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16mxi5l/googles_bard_can_now_access_all_of_your_google/
-----
Title: Sean Penn to Hollywood studios wanting actors’ likenesses for AI: ‘I want your daughter’s’
Content: Sean Penn confronts Hollywood studios over their intent to use AI to exploit actors' likenesses, suggesting they trade their children's likenesses if they want his.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**Sean Penn Challenges Hollywood on AI Use**

* **Provocative Trade Offer**: Sean Penn proposes Hollywood executives trade their daughters' likeness if they want to use his for AI purposes.
* **A Stand Against Exploitation**: Penn expresses anger over the potential use of AI to exploit actors' voices and faces for upcoming projects.

**Recent Struggles with AI in Entertainment**

* **Studios vs. Actors and Writers**: Ongoing negotiations have pitted studios against actors and writers on the topic of AI use. There's been a prolonged strike for better contracts.
* **Studios Invest in AI**: Major companies like Netflix and Disney have started offering lucrative salaries for AI-related roles in the entertainment industry.

**Penn's Morality Argument**

* **Indecent Proposal**: Penn stresses that the studios' intent isn't just about business but represents a moral failing in the industry.

[Source (NYPost)](https://nypost.com/2023/09/13/sean-penn-slams-studios-for-wanting-actors-likenesses-for-ai/)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,500+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16kyiun/sean_penn_to_hollywood_studios_wanting_actors/
-----
News posts saved as '2023-09-23-reddit_news_posts.md'
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pi4tp/indeeds_ceo_says_college_students_might_be/
-----
Title: GPT-5 is coming it's codename: Gobi
Content: OpenAI is reportedly accelerating efforts to release an advanced multimodal LLM called GPT-Vision, codenamed **Gobi.**  ([Source](https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm))

**The Promise of Multimodal AI**

* ***Processes Text and Images:*** Multimodal LLMs can understand and generate content combining text and images, offering expanded capabilities.
* **GPT-Vision is stuck in safety reviews:** but “OpenAI’s engineers seem close to satisfying legal concerns.”
* ***Key Edge Over Rivals***: Launching first with multimodal abilities could give OpenAI a critical advantage over competitors.

**OpenAI's Reported Rush to Release Gobi**

* ***Aiming to Beat Google:*** OpenAI seems intent on launching Gobi before Google can debut [Gemini](https://www.theinformation.com/articles/google-nears-release-of-gemini-ai-to-rival-openai) to dominate the multimodal space.
* **Expanding GPT-4's Abilities:** Gobi may build on GPT-4 by adding enhanced visual and multimodal features that OpenAI previewed earlier.
* ***The Enduring Nature of Progress***: Both firms recognize the long-term, competitive nature of AI advancement.

**TL;DR:** OpenAI looks to stay ahead of Google in the AI race by rushing to launch an advanced multimodal LLM before Google's Gemini, a preemptive move that could disrupt Google's plans and ambitions.

**PS:** Get the latest AI developments, tools, and use cases by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16mx186/gpt5_is_coming_its_codename_gobi/
-----
Title: AI that’s smarter than humans? Americans say a firm “no thank you.”
Content: 63% of Americans want regulation to actively prevent superintelligent AI, a new poll reveals.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Public Opinion on Superintelligent AI**

* **Skeptical Majority:** 63% of Americans believe regulation should actively prevent AI superintelligence.
* **Companies' Goals:** Organizations like OpenAI aim to develop artificial general intelligence (AGI), assuming its existence benefits humanity.
* **Voices of Dissent:** Concerns arise that the pursuit of AGI is driven by a select few without public consensus on its potential risks.

**Tech Sector Power and Influence**

* **Historical Ideology:** The belief in technological solutionism, or technology as a solution to major problems, dates back centuries.
* **Modern-Day Acceleration:** Today's tech acceleration in the U.S. is driven by capitalism and the race against foreign powers, championed by Silicon Valley.
* **Disconnect with Public:** Many Americans now distrust tech leaders, associating technological progress with potential societal disruptions.

[Source (Vox)](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,500+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16nnq2c/ai_thats_smarter_than_humans_americans_say_a_firm/
-----
Title: Two-minute Daily AI Update (Date: 09/21/2023): News from OpenAI, Amazon, Google DeepMind, GitHub, Uber, and NVIDIA
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **OpenAI unveils DALL·E 3**  
\- It understands significantly more nuance and detail than its previous systems. DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall. It is built natively on ChatGPT, which lets you use ChatGPT as a brainstorming partner and refiner of your prompts.
* **Amazon brings generative AI to Alexa and Fire TV**  
\- At its annual devices event, Amazon introduced generative AI updates for its Fire TV voice search to bring more conversational ways to interact with Alexa and discover new content.  
\- It will also use a new generative AI model to power improved experiences across its Echo family of devices.
* **Google DeepMind’s ‘Language Modeling Is Compression’**  
\- This paper views the prediction problem through the lens of compression and evaluates the compression capabilities of large (foundation) models. It shows that LLMs are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning.
* **GitHub’s Copilot Chat will now be available to individual users**  
\- It is available in public beta for GitHub Copilot individual users in Visual Studio and Visual Studio Code.
* **Uber Eats to roll out AI-powered assistant**  
\- It will help users find deals and explore different food options seamlessly.
* **NVIDIA to train 50,000 Infosys employees on AI technology**  
\- Infosys will set up NVIDIA Centre of Excellence to train and certify employees on NVIDIA’s AI technologies. Also, NVIDIA’s AI Enterprise ecosystem of models, tools, runtimes, and GPU systems will be brought to Infosys’s AI-first offering Topaz.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/openai-unveils-dalle3-amazon-ai-updates-deepmind).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16oi0cn/twominute_daily_ai_update_date_09212023_news_from/
-----
Title: Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT
Content: Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**AI Detection Tool Concerns**

* **False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.
* **High False Positive Rate**: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.

**ChatGPT's Rise & Challenges**

* **Popularity Among Students**: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.
* **Misidentification Issues**: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.

**OpenAI's Stance**

* **Difficulty in AI Text Detection**: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.
* **Bias Against Non-English Writers**: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

[Source (Business Insider)](https://www.businessinsider.com/universities-ditch-ai-detectors-over-fears-students-falsely-accused-cheating-2023-9?r=US&IR=T)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,700+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pahu7/some_universities_are_ditching_ai_detection/
-----
News posts saved as '2023-09-24-reddit_news_posts.md'
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pi4tp/indeeds_ceo_says_college_students_might_be/
-----
Title: GPT-5 is coming it's codename: Gobi
Content: OpenAI is reportedly accelerating efforts to release an advanced multimodal LLM called GPT-Vision, codenamed **Gobi.**  ([Source](https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm))

**The Promise of Multimodal AI**

* ***Processes Text and Images:*** Multimodal LLMs can understand and generate content combining text and images, offering expanded capabilities.
* **GPT-Vision is stuck in safety reviews:** but “OpenAI’s engineers seem close to satisfying legal concerns.”
* ***Key Edge Over Rivals***: Launching first with multimodal abilities could give OpenAI a critical advantage over competitors.

**OpenAI's Reported Rush to Release Gobi**

* ***Aiming to Beat Google:*** OpenAI seems intent on launching Gobi before Google can debut [Gemini](https://www.theinformation.com/articles/google-nears-release-of-gemini-ai-to-rival-openai) to dominate the multimodal space.
* **Expanding GPT-4's Abilities:** Gobi may build on GPT-4 by adding enhanced visual and multimodal features that OpenAI previewed earlier.
* ***The Enduring Nature of Progress***: Both firms recognize the long-term, competitive nature of AI advancement.

**TL;DR:** OpenAI looks to stay ahead of Google in the AI race by rushing to launch an advanced multimodal LLM before Google's Gemini, a preemptive move that could disrupt Google's plans and ambitions.

**PS:** Get the latest AI developments, tools, and use cases by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16mx186/gpt5_is_coming_its_codename_gobi/
-----
Title: AI that’s smarter than humans? Americans say a firm “no thank you.”
Content: 63% of Americans want regulation to actively prevent superintelligent AI, a new poll reveals.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Public Opinion on Superintelligent AI**

* **Skeptical Majority:** 63% of Americans believe regulation should actively prevent AI superintelligence.
* **Companies' Goals:** Organizations like OpenAI aim to develop artificial general intelligence (AGI), assuming its existence benefits humanity.
* **Voices of Dissent:** Concerns arise that the pursuit of AGI is driven by a select few without public consensus on its potential risks.

**Tech Sector Power and Influence**

* **Historical Ideology:** The belief in technological solutionism, or technology as a solution to major problems, dates back centuries.
* **Modern-Day Acceleration:** Today's tech acceleration in the U.S. is driven by capitalism and the race against foreign powers, championed by Silicon Valley.
* **Disconnect with Public:** Many Americans now distrust tech leaders, associating technological progress with potential societal disruptions.

[Source (Vox)](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,500+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16nnq2c/ai_thats_smarter_than_humans_americans_say_a_firm/
-----
Title: Microsoft’s Copilot puts AI into everything, YouTube announces 3 new AI features for creators, 4 Crucial Factors for Evaluating LLMs in Industry Applications, AI Detection Tool Concerns, Amazon brings Generative AI to Alexa and Fire TV, DALL·E 3
Content: [https://youtu.be/qe5tBvkvrf8](https://youtu.be/qe5tBvkvrf8)

# Summary:

# Microsoft’s Copilot puts AI into everything

Microsoft has announced a new AI-powered feature, Microsoft Copilot. It’ll bring AI features into various Windows 11, Microsoft 365, Edge, and Bing. Our first impressions are that it’s Bing but for Windows. You can use Copilot to rearrange windows, generate text, open apps on the web, edit pictures and more.Copilot can be accessed via an app or with a simple right-click and will be rolled out across Bing, Edge, and Microsoft 365 this fall, with the free Windows 11 update starting on September 26th.Why does this matter?While we don’t see any revolutionary use cases of Copilot as of now, it’s still a huge step towards the democratization of AI. As more users get their hands on this AI copilot, we’ll know the true extent of its effectiveness. If all goes well, Microsoft will end up grabbing an even bigger share of the AI market as it will deliver AI natively to all Windows devices.

# YouTube announces 3 new AI features for creators

In a YouTube event, the company announced 3 AI-powered features for YouTube Shorts creators.

**Dream Screen**: It allows users to create image or video backgrounds using AI. All you need to do is type what you want to see in the background and AI will create it for you.

**Creator Music**: This was a previously available feature but got an AI revamp this time around. Creators can simply type in the kind and length of the music they need and AI will find the most relevant suggestions for their needs.

**AI Insights for Creators:** This is an inspiration tool which generates video ideas based on AI’s analysis of what the audiences are already watching and prefer.Why does this matter?It seems like a strategic decision to natively introduce AI features to support users. It’s a trend we are seeing increasingly more across the landscape. For the users, it's great news since they get free AI assistance in their creative endeavors.

# Google’s innovative approach to train smaller language models

Large language models (LLMs) have enabled new capabilities in few-shot learning, but their massive size makes deployment challenging. To address this, the authors propose a new method called distilling step-by-step, which trains smaller task-specific models using less data while surpassing LLM performance.First, the key idea is to extract rationales - intermediate reasoning steps - from an LLM using few-shot chain-of-thought prompting. These rationales are then used alongside labels to train smaller models in a multi-task framework, with tasks for label prediction and rationale generation. Experiments across NLI, QA, and math datasets show this approach reduces training data needs by 75-80% compared to standard fine-tuning.Why does this matter?This new approach to train smaller models with higher accuracy has the potential to support language models that can be deployed on local devices while retaining the performance that was previously achievable only through LLMs.

# 4 Crucial Factors for Evaluating Large Language Models in Industry Applications

Based on your end goal, you might fancy one LLM over the other. For instance, some industries value privacy over anything while others might put data accuracy over everything else. In this article, Skanda Vivek shares the 4 critical factors you should always consider when picking a large language model.He mentions Quality, Economic, Latency, and Privacy to be the 4 resting pillars of your decision. He then goes into details discussing each of these parameters and how you should evaluate a given model against them.Why does this matter?The ability to make the right decision when choosing the underlying LLM for your applications is massively important. This article will provide you with valuable insights when it comes to choosing the right LLM.

# Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT

Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.AI Detection Tool Concerns

**False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.High False Positive Rate: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.ChatGPT's Rise & ChallengesPopularity Among Students: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.Misidentification Issues: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.OpenAI's StanceDifficulty in AI Text Detection: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.Bias Against Non-English Writers: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

# X ranks lowest in tackling climate misinformation, study reveals

X, formerly known as Twitter, has ranked last in a new assessment by Climate Action Against Disinformation for its management of climate misinformation.Pinterest scored the highest in terms of addressing climate change misinformation, while other platforms like YouTube, Meta, and Instagram also ranked higher than X.Changes under Elon Musk's ownership, including unclear policies on climate misinformation and a less communicative content moderation team, have contributed to X's low ranking.Google sued after Maps allegedly directed a man to drive off a collapsed bridgePhilip Paxson, a father of two, died after Google Maps directed him to a collapsed bridge, leading to a fatal car plunge, according to a lawsuit filed by his family.The family claims Google was informed of the bridge's collapse but failed to update its navigation system, making the tech company negligent in Paxson's death.Despite having received reports about the bridge's state through its 'suggest and edit' feature, Google allegedly took no further actions to correct the route information.Study finds 95% of NFTs are now worthlessAccording to a study by dappGambl, 95% of NFTs are now practically worthless, with the majority of the 73,257 NFT collections analyzed having a market cap of zero Ether.Enthusiasm for NFTs has substantially dropped and prices have plunged, with even hyped-up collections becoming virtually valueless.The future of NFTs is uncertain; they will need to prove they have inherent value, such as cultural relevance or representing actual art, to survive.

&#x200B;

# Google expands AI coding assistant to 170 countries

\- Google launched Studio Bot in 170 countries. It was previously launched in May for Android developers in the US. The assistant helps devs generate code, fix errors and answer questions about Android.

&#x200B;

# OpenAI unveils DALL·E 3

DALL·E 3 is built natively on ChatGPT, which lets you use ChatGPT to generate tailored, detailed prompts for DALL·E 3. If it’s not quite right, you can ask ChatGPT to make tweaks.

Even with the same prompt, DALL·E 3 delivers significant improvements over DALL·E 2, as shown below (Left: DALL·E 2 results, Right: DALL·E 3). The prompt: “An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.”

OpenAI has taken steps to limit DALL·E 3’s ability to generate violent, adult, or hateful content.DALL·E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can also opt their images out from training of OpenAI’s future image generation models.

DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall.Why does this matter?As OpenAI notes, modern text-to-image systems have a tendency to ignore words or descriptions, forcing users to learn prompt engineering. DALL·E 3 represents a leap forward in AI’s ability to generate images that exactly adhere to the text you provide. Will other image generators like Midjourney and Stable Diffusion keep up?

&#x200B;

# DALL-E 3 will be available in Bing chat

\- Microsoft’s recently announced DALL-E 3 will be available in Bing as Microsoft announced users will be able to create images in a chat. DALL-E 3 will be rolled out for enterprise users in October.

&#x200B;

# ChatGPT can now generate images

Our new text-to-image model, DALL·E 3, can translate nuanced requests into extremely detailed and accurate images.Coming soon to ChatGPT Plus & Enterprise, which can help you craft amazing prompts to bring your ideas to life:[https://openai.com/dall-e-3](https://openai.com/dall-e-3)

&#x200B;

# Cisco to buy Splunk in $28 billion

In its bid to expand software and AI powered data analysis, Cisco announced it will buy cybersecurity firm, Splunk, in $28 billion. Splunk has announced AI features that detect and respond to data anomalies, earlier this year.

# Anthropic releases policy on ‘catastrophic risks’

\- Anthropic, the company behind Claude chatbot, shared a policy highlighting its commitment to responsible scaling of AI systems. The policy acknowledges AI’s potential to cause “thousands of deaths or hundreds of billions of dollars in damage.”

&#x200B;

# Amazon brings Generative AI to Alexa and Fire TV

At its annual devices event, Amazon announced a few AI updates:It will soon use a new generative AI model to power improved experiences across its Echo family of devices. The new model is specifically optimized for voice and will take into account body language as well as a person’s eye contact and gestures for more powerful conversational experiences.It also introduced generative AI updates for its Fire TV voice search, which promises to bring more conversational ways to interact with Alexa and discover new content based on specifics.Why does this matter?Integrating LLMs with voice assistants is a perfect use case. But Amazon's generative AI revamp for Alexa marks a game-changer. It promises voice assistants that understand context better, carry over information from previous conversations, and become more personalized for users.

# Amazon is turning Alexa into a hands-free ChatGPT

Amazon is upgrading Alexa, its voice assistant, with the technology behind chatbots for more complex and open-ended conversation capabilities.The new feature, which is still in progress, will show more simulated personality, interpret body language with devices equipped with cameras and modulate its voice for a more natural conversation.While this advancement holds promise, challenges like responding to body language and the fact that these large language models can sometimes blur out inappropriate or nonsensical things, remains to refine.ChatGPT Usage is Rising Again as Students Return to School

# Zuckerberg's philanthropy project is building a massive GPU cluster to ‘cure all diseases

The Chan Zuckerberg Initiative (CZI), founded by Mark Zuckerberg and his wife Priscilla Chan, plans to build one of the world's largest GPU clusters for AI-driven biomedical research.The CZI aims to use large language models to understand disease development at cellular levels and predict cell behaviors, necessitating over 1,000 Nvidia's H100 GPUs for computational requirements.The high-performance computing system, expected to be operational in 2024, will accelerate biomedical research, from mapping varied cell types in different organisms to designing potential drugs and therapeutics.

# After declining over the summer, ChatGPT usage has increased, most likely as a result of students returning to class and concerns about AI cheating.

12% Traffic Increase Last Week: ChatGPT saw a sizable jump in US web traffic as fall classes resumed.Big Drop Over Summer Break: Traffic declined steadily from May through August when school was out.Still Below Early 2022 Peaks: But current usage remains below ChatGPT's peak levels earlier this year. Back to School Brings Old ProblemsCheating Fears Resurface: Easier student access with school back raises fresh concerns about AI-aided cheating.Schools Still Debating Rules: Many institutions continue deciding whether to ban, incorporate or ignore the technology.Potential Revenue Uncertainty: Reliance on students could be problematic for monetizing ChatGPT.With the new school year boosting ChatGPT traffic, managing responsible AI use in academics remains a complex balancing act for educators.

&#x200B;

# Intel’s ‘AI PC’ can run generative AI chatbots directly on laptops

Intel’s new chip, due in December, will be able to run a generative AI chatbot on a laptop rather than having to tap into cloud data centers for computing power. It is made possible by new AI data-crunching features built into Intel's forthcoming "Meteor Lake" laptop chip and from new software tools the company is releasing.Intel also demonstrated laptops that could generate a song in the style of Taylor Swift and answer questions in a conversational style, all while disconnected from the Internet. Moreover, Microsoft's Copilot AI assistant will be able to run on Intel-based PCs.Why does this matter?This will let businesses test ChatGPT-style AI models without sending sensitive data off their own computers. Intel seems to be on track to become the lead chip manufacturer again, competing with Nvidia to make powerful chips that train AI systems such as ChatGPT and Stability AI’s models.

&#x200B;

# DeepMind’s new AI can predict genetic diseases

Google DeepMind’s new system, called AlphaMissense, can tell if the letters in the DNA will produce the correct shape. If not, it is listed as potentially disease-causing.AlphaMissense can predict the likelihood of genetic diseases by analyzing genetic mutations called missense variants.AlphaMissense operates like a large language model, trained on human and primate biology, capable of identifying normal sequences of proteins and detecting changes that could suggest a disease.With 90% accuracy, AlphaMissense is more reliable than existing tools, potentially accelerating the process of identifying disease-causing genetic mutations, which previously required months of meticulous research.

Currently, genetic disease hunters have fairly limited knowledge of which areas of human DNA can lead to disease and have to search across billions of chemical building blocks that make up DNA. They have classified 0.1% of letter changes, or mutations, as either benign or disease-causing. DeepMind's new model pushed that percentage up to 89%.Why does this matter?AI is changing nearly everything we do at the moment and might revolutionize molecular biology and life sciences, too. This development is expected to speed up diagnosis and help search for better genetic disease treatments.

&#x200B;

# Google is turning its Bard AI chatbot into a personal assistant

  
Google's Bard AI now has enhanced capabilities, pulling real-time data from Google's other applications and a user's data silo to deliver more relevant chatbot responses.  
A new feature named Bard Extensions allows the AI to access user's personal Google data to provide specific answers about their daily activities, while promising not to be used for ad targeting or training the AI model.  
To increase transparency and accuracy, Google is introducing a 'Double Check' feature where Bard audits its responses and highlights contradictory or heavily referenced statements.

&#x200B;

# DeepMind’s New AI Can Predict Genetic Diseases

AlphaMissense, a new model from Google’s artificial intelligence team, analyzes the effects of DNA mutations and will accelerate research into rare diseases.  
About 10 years ago, Žiga Avsec was a PhD physics student who found himself taking a crash course in genomics via a university module on machine learning. He was soon working in a lab that studied rare diseases, on a project aiming to pin down the exact genetic mutation that caused an unusual mitochondrial disease.  
This was, Avsec says, a “needle in a haystack” problem. There were millions of potential culprits lurking in the genetic code—DNA mutations that could wreak havoc on a person’s biology. Of particular interest were so-called missense variants: single-letter changes to genetic code that result in a different amino acid being made within a protein. Amino acids are the building blocks of proteins, and proteins are the building blocks of everything else in the body, so even small changes can have large and far-reaching effects.

&#x200B;

# Podcast Detailed Transcript:

Microsoft recently announced a game-changing feature called Microsoft Copilot. This exciting new addition will infuse AI capabilities into various Windows 11, Microsoft 365, Edge, and Bing applications. Think of it as Bing, but specifically designed for Windows devices. So, what can Copilot do? Quite a lot, actually. With this tool, you can rearrange windows effortlessly, generate text, open web apps, edit pictures, and much more. It's accessible both via an app and through a simple right-click, making it convenient for users to tap into its AI-powered goodness. But when can we start using Copilot? Well, the good news is that it's just around the corner. Microsoft plans to roll out Copilot this fall, making it available across Bing, Edge, and Microsoft 365. And for Windows users, you'll get to enjoy this feature sooner than you think. The free Windows 11 update will begin on September 26th. Now, you might be wondering, why is this such a big deal? The answer lies in the democratization of AI. While we don't have any mind-blowing use cases for Copilot just yet, this step forward by Microsoft is significant. As more users get their hands on this AI copilot, we'll start to see its true capabilities. And if all goes well, Microsoft could dominate an even larger share of the AI market by delivering AI natively.YouTube just announced some exciting news for creators! They're rolling out three new AI-powered features for YouTube Shorts creators. Let me break it down for you. First up, we have Dream Screen. This feature lets you create image or video backgrounds using AI. All you have to do is type in what you want to see in the background, and AI will make it happen. How cool is that? Next, we've got Creator Music. This feature got an AI revamp, making it even better than before. Now, creators can simply type in the kind and length of the music they need, and AI will find the most relevant suggestions. It's like having your own personal music assistant. Last but not least, we have AI Insights for Creators. This is a tool that generates video ideas for creators based on AI's analysis of what audiences are already watching and preferring. So, if you're looking for some inspiration, AI has got your back. This move by YouTube seems like a smart strategic decision to integrate AI features directly into the platform.

When it comes to evaluating large language models (LLMs) for industry applications, there are four crucial factors to consider. Skanda Vivek highlights these factors, which include quality, economic aspects, latency, and privacy. Each of these factors plays a significant role in determining the suitability of a particular LLM. The quality of the LLM is of utmost importance. Depending on your end goal, you may prioritize different aspects of quality, such as data accuracy, contextual understanding, or fluency. Consider what matters most to your industry and choose an LLM that aligns with those preferences. Economic factors also come into play. It's essential to assess the cost-effectiveness of implementing a particular LLM. Does it provide value for money? Can it fit within your organization's budget? Analyzing the economic aspects ensures you make an informed decision. Latency, or the response time of the LLM, is another vital factor. Some applications require real-time or near-instantaneous responses. Evaluating an LLM's latency helps you select the model that meets your specific timing requirements. Finally, privacy is increasingly significant for many industries. Skanda Vivek emphasizes the need to consider privacy when choosing an LLM. Depending on your industry, data security and privacy regulations may be a top priority. Ensuring the chosen model aligns with your privacy needs is crucial. Choosing the right LLM is a critical decision that can significantly impact your applications. By carefully considering these four factors—quality, economic aspects, latency, and privacy—you can make an informed choice that aligns with your industry's requirements. In recent news, some universities are raising concerns about AI detection software used to catch cheating students. There are worries that students could be falsely accused of cheating when using tools like ChatGPT. As a result, some universities are opting to abandon these AI detection systems. The debate highlights the potential drawbacks and risks associated with relying entirely on AI tools for academic integrity.So, here's the thing. Some major universities have decided to ditch AI detection tools because they're worried about their accuracy. And let's face it, nobody wants to be falsely accused of cheating, right? One tool in particular, called ChatGPT, has caused quite a stir. The problem with ChatGPT is that it's gained popularity among students, and that's got educators really concerned about academic dishonesty. But it's not just about students using AI to write their essays. It's also about the tool itself misidentifying things and getting it all wrong. For example, one professor in Texas failed half of his class because of false detections by ChatGPT. Can you imagine? Talk about a nightmare scenario. And it's not just him. Other students have also been wrongly accused by anti-plagiarism software using ChatGPT. What's interesting is that even OpenAI, the company behind ChatGPT, has abandoned their own AI text detector due to its low accuracy rate. They've even warned educators about relying too heavily on AI content detectors. And here's another thing to consider: these detection tools often get it wrong when it comes to content written by non-English writers. So, yeah, there are some serious concerns here. That's why some universities, like Vanderbilt and Northwestern, have decided to say "no thanks" to these AI detection tools. It's better to be safe than sorry, right? After all, nobody wants to unfairly accuse a student of cheating.Hey there! Some interesting news for you today. According to Climate Action Against Disinformation, X, which we all know as Twitter, has ranked last when it comes to tackling climate misinformation. Quite the bummer, right? It turns out that Pinterest is leading the pack in addressing climate change misinformation, with YouTube, Meta (formerly known as Facebook), and Instagram not too far behind. But poor old X is lagging behind. So, what led to this low ranking for X? Well, it seems that since Elon Musk took over, things have changed, and not for the better. There are unclear policies on climate misinformation and a less communicative content moderation team, both of which have contributed to X's downward slide in the rankings. Maybe they need to step up their game a bit. In another news story, Google is facing a lawsuit after it allegedly directed a man, Philip Paxson, to drive off a collapsed bridge via Google Maps. Sadly, Paxson lost his life in the tragic accident. According to his family, Google was aware of the bridge's collapse but failed to update its navigation system, which they argue makes the tech giant negligent in Paxson's death. Google apparently received reports about the bridge's condition, but did nothing to fix the route information. It's a heartbreaking situation. And finally, brace yourself for this one. A study by dappGambl has found that a whopping 95% of NFTs are now practically worthless. Yep, you heard that right. NFTs, which were once all the rage, have lost their shine. Prices have plummeted, and most of the 73,257 NFT collections analyzed have a market cap of zero Ether. It's uncertain what the future holds for NFTs, but they'll need to prove their worth, whether through cultural significance or as a representation of actual art, if they want to stick around. So, that's the latest in tech and climate news. Stay tuned for more updates!OpenAI has just unveiled their latest model for text-to-image translation called DALL·E 3, and it's pretty impressive! This new version is built directly on ChatGPT, which means you can use ChatGPT to generate customized and detailed prompts for DALL·E 3. And if the results aren't exactly what you were hoping for, you can even ask ChatGPT to make some tweaks. Compared to its predecessor, DALL·E 2, DALL·E 3 delivers significant improvements in creating detailed images. OpenAI showcased this by providing a prompt for an expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula. The results from DALL·E 3 were far superior to those from DALL·E 2. OpenAI has also taken steps to ensure that DALL·E 3 doesn't generate violent, adult, or hateful content. They have designed it to decline requests for images in the style of living artists. Additionally, creators have the option to exclude their images from being used in the training of OpenAI's future image generation models, giving them more control over the use of their work. Currently, DALL·E 3 is in research preview and will be available to ChatGPT Plus and Enterprise customers in October through the API. It will later be made available in Labs for those interested. This new release is important because it addresses the limitations of previous text-to-image systems, which often ignored certain words or descriptions. With DALL·E 3, AI's ability to generate images that align precisely with the provided text takes a huge leap forward. It raises questions about how other image generators like Midjourney and Stable Diffusion will keep up. OpenAI has also prioritized safety improvements in DALL·E 3. They have implemented measures to prevent explicit content and have tools in place to identify risky words and block public figures. Furthermore, artists can now request that their work be blocked from AI copying, and DALL·E 3 won't mimic the styles of specific artists when named. OpenAI hopes that the integration with ChatGPT and the safety guards in DALL·E 3 will expand access to this technology while preventing misuse. However, there are still concerns and legal issues surrounding AI-generated art that need to be addressed.Amazon had some exciting announcements at its recent devices event. One of the standout updates is the integration of generative AI into their Echo family of devices. This new AI model is optimized for voice, taking into account not only what is said but also body language, eye contact, and gestures. This means that interactions with Alexa will become much more powerful and conversational, providing users with improved experiences. But that's not all. Amazon has also introduced generative AI updates for Fire TV's voice search. This update aims to enhance the conversational interaction between users and Alexa, allowing for a more natural and intuitive way to discover new content based on specific preferences. This development is significant because it showcases how integrating language models like Generative AI into voice assistants can revolutionize the way we interact with them. Amazon's revamp of Alexa using generative AI is a game-changer. It enables voice assistants to better understand context, seamlessly carry over information from previous conversations, and provide a more personalized experience for users. In fact, Amazon is transforming Alexa into a hands-free ChatGPT by leveraging the technology behind chatbots. This upgrade will give Alexa the ability to engage in more complex and open-ended conversations. It will also enhance its simulated personality, interpret body language (for devices with cameras), and modulate its voice for a more natural conversation. However, there are some challenges to overcome, such as responding accurately to body language and refining these large language models to prevent inappropriate or nonsensical responses. But with Amazon's dedication to improving AI experiences, we can expect significant advancements in these areas. Overall, Amazon's integration of generative AI into Alexa and Fire TV demonstrates their commitment to providing users with more intuitive, personalized, and conversational experiences.Hey there! Have you heard about Mark Zuckerberg's latest philanthropy project? It's got a pretty ambitious goal - to "cure all diseases". The project, called the Chan Zuckerberg Initiative (CZI), is a collaborative effort between Zuckerberg and his wife, Priscilla Chan. So here's the plan: CZI is planning to build one of the biggest GPU clusters in the world specifically for AI-driven biomedical research. They want to use large language models to dive deep into disease development at the cellular level and even predict how cells behave. And to do that, they're going to need some serious computational power - over 1,000 Nvidia's H100 GPUs! This high-performance computing system is expected to be up and running by 2024. And let me tell you, it's going to revolutionize biomedical research. From mapping out various cell types across different organisms to designing potential drugs and therapeutics, this GPU cluster will supercharge the entire process. I don't know about you, but I'm pretty excited to see what kind of breakthroughs this project will bring. Who knows, maybe we'll be living in a world where diseases are a thing of the past sooner than we think!So, let's dive into the latest AI updates from OpenAI, Microsoft, YouTube, Google, Cisco, and Anthropic. It seems like ChatGPT is back in the spotlight with an increase in usage, particularly because students are returning to school and concerns about AI cheating are on the rise. After experiencing a decline throughout the summer, ChatGPT has seen a 12% traffic increase since fall classes resumed in the US. However, it's important to note that current usage is still below the peak levels seen earlier this year. With students back in the classroom, concerns about AI-aided cheating have resurfaced. The easier access students have to AI technology raises fresh debates among schools about whether to ban, incorporate, or ignore such tools. For educators, managing responsible AI use in academics is becoming a complex balancing act. There's also some uncertainty surrounding potential revenue as ChatGPT's reliance on students could pose challenges for monetization. Moving on to other AI news, Microsoft has announced a new AI-powered feature called Microsoft Copilot. This feature, available in various Windows 11 applications, Microsoft 365, Edge, and Bing, allows users to rearrange windows, generate text, edit pictures, and more. It's like having Bing integrated into your Windows experience. YouTube is not far behind with its AI advancements. The platform has introduced three new AI-powered features specifically for Shorts creators. Dream Screen uses AI to generate background images and videos, Creator Music helps find the perfect track for Shorts, and AI Insights for Creators assists in brainstorming the next video idea. These features aim to enhance the content creation experience on YouTube. Meanwhile, Google has expanded its AI coding assistant, Studio Bot, to 170 countries. Initially launched for Android developers in the US, this assistant helps generate code, fix errors, and answer questions about Android development. It's a handy tool for developers worldwide. In the world of image creation, Microsoft's DALL-E 3 is making its way to Bing. Soon, users will be able to create images in a chat using DALL-E 3. This exciting feature will be rolled out for enterprise users in October, opening up new possibilities for visual communication. Now, let's switch gears to a significant acquisition. Cisco has announced its plan to acquire cybersecurity firm Splunk for $28 billion. This move aligns with Cisco's goal to expand its software and AI-powered data analysis capabilities. Splunk, which introduced AI features earlier this year to detect and respond to data anomalies, will play a vital role in Cisco's strategy. In the realm of responsible AI scaling, Anthropic, the company behind the Claude chatbot, has released a policy that emphasizes its commitment to responsible AI system development. The policy acknowledges the potential for AI systems to cause catastrophic risks, including thousands of deaths or immense financial damage. It's encouraging to see companies prioritizing responsible AI practices. In other tech news on September 22nd, 2023, Cisco is set to make its largest acquisition ever by acquiring Splunk for $28 billion. This move aims to boost security services and system performance troubleshooting. On a different note, NASA eagerly awaits the return of pristine asteroid Bennu samples, taken by OSIRIS-REx in 2020. The samples could unlock valuable insights into the origins of our solar system. In the legal world, lawyers who sued Tesla's board for excessive pay are seeking a jaw-dropping $10,000 an hour. The case is sure to attract attention as it unfolds. Another interesting development involves an anonymous developer who used OpenAI's ChatGPT API to program an AI that created and launched an ERC-20 token called AstroPepeX. Within just 24 hours, the token generated an astonishing $12.9 million in trading. It's a testament to the possibilities AI offers in the realm of finance and entrepreneurship. Lastly, Ilya Sutskever, one of OpenAI's renowned figures, along with machine ethicist Thomas Krendl Gilbert, have described AI development as "alchemy." This comparison underscores the unpredictable and mysterious nature of AI outcomes, sparking heated debate within the industry. And there you have it, the latest AI updates featuring ChatGPT, Microsoft, YouTube, Google, Cisco, and Anthropic. Stay tuned for more exciting advancements in the world of artificial intelligence.Hey there! If you're excited about diving deeper into the world of artificial intelligence, I've got just the thing for you! There's this amazing book called "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence." Trust me, it's a game-changer! Now, let me tell you why you should totally get your hands on this gem. "AI Unraveled" is packed with all the answers to those burning questions you may have about AI. Think of it as your ultimate AI guidebook. It's like having a knowledgeable expert right by your side, unravelling the mysteries of artificial intelligence in a way that's easy to comprehend. The best part? You can grab a copy of this must-read book at three different platforms: Apple, Google, or Amazon. So, no matter whether you're an Apple aficionado, a Google guru, or an Amazon enthusiast, there's a way for you to access this invaluable resource. So, why wait any longer? Dive into "AI Unraveled" today and expand your understanding of artificial intelligence like never before. This book is a game-changer, and it's ready to be enjoyed by curious minds like yours. Happy reading!In today's episode, we covered Microsoft's AI-powered Copilot, YouTube's new AI features for creators, evaluating large language models in industry, concerns with AI detection tools in universities, rankings of tech companies tackling misinformation, OpenAI's DALL·E 3 text-to-image model, generative AI updates from Amazon, Zuckerberg's philanthropy in AI-driven research, ChatGPT usage concerns, and other notable news - plus, don't forget to expand your AI knowledge with the essential book 'AI Unraveled'. Join us next time on AI Unraveled as we continue to demystify frequently asked questions on artificial intelligence and bring you the latest trends in AI, including ChatGPT advancements and the exciting collaboration between Google Brain and DeepMind. Stay informed, stay curious, and don't forget to subscribe for more!

# Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence," available at Apple, Google, or Amazon today today:

# AI Unraveled @ Amazon: [https://amzn.to/3ZrpkCu](https://amzn.to/3ZrpkCu)

# AI Unraveled @ Apple: [http://books.apple.com/us/book/id6445730691](http://books.apple.com/us/book/id6445730691)

# AI Unraveled @ Google: [https://play.google.com/store/books/details?id=oySuEAAAQBAJ](https://play.google.com/store/books/details?id=oySuEAAAQBAJ)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pp2h6/microsofts_copilot_puts_ai_into_everything/
-----
Title: Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT
Content: Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**AI Detection Tool Concerns**

* **False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.
* **High False Positive Rate**: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.

**ChatGPT's Rise & Challenges**

* **Popularity Among Students**: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.
* **Misidentification Issues**: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.

**OpenAI's Stance**

* **Difficulty in AI Text Detection**: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.
* **Bias Against Non-English Writers**: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

[Source (Business Insider)](https://www.businessinsider.com/universities-ditch-ai-detectors-over-fears-students-falsely-accused-cheating-2023-9?r=US&IR=T)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,700+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pahu7/some_universities_are_ditching_ai_detection/
-----
News posts saved as '2023-09-25-reddit_news_posts.md'
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pi4tp/indeeds_ceo_says_college_students_might_be/
-----
Title: GPT-5 is coming it's codename: Gobi
Content: OpenAI is reportedly accelerating efforts to release an advanced multimodal LLM called GPT-Vision, codenamed **Gobi.**  ([Source](https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm))

**The Promise of Multimodal AI**

* ***Processes Text and Images:*** Multimodal LLMs can understand and generate content combining text and images, offering expanded capabilities.
* **GPT-Vision is stuck in safety reviews:** but “OpenAI’s engineers seem close to satisfying legal concerns.”
* ***Key Edge Over Rivals***: Launching first with multimodal abilities could give OpenAI a critical advantage over competitors.

**OpenAI's Reported Rush to Release Gobi**

* ***Aiming to Beat Google:*** OpenAI seems intent on launching Gobi before Google can debut [Gemini](https://www.theinformation.com/articles/google-nears-release-of-gemini-ai-to-rival-openai) to dominate the multimodal space.
* **Expanding GPT-4's Abilities:** Gobi may build on GPT-4 by adding enhanced visual and multimodal features that OpenAI previewed earlier.
* ***The Enduring Nature of Progress***: Both firms recognize the long-term, competitive nature of AI advancement.

**TL;DR:** OpenAI looks to stay ahead of Google in the AI race by rushing to launch an advanced multimodal LLM before Google's Gemini, a preemptive move that could disrupt Google's plans and ambitions.

**PS:** Get the latest AI developments, tools, and use cases by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16mx186/gpt5_is_coming_its_codename_gobi/
-----
Title: AI that’s smarter than humans? Americans say a firm “no thank you.”
Content: 63% of Americans want regulation to actively prevent superintelligent AI, a new poll reveals.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Public Opinion on Superintelligent AI**

* **Skeptical Majority:** 63% of Americans believe regulation should actively prevent AI superintelligence.
* **Companies' Goals:** Organizations like OpenAI aim to develop artificial general intelligence (AGI), assuming its existence benefits humanity.
* **Voices of Dissent:** Concerns arise that the pursuit of AGI is driven by a select few without public consensus on its potential risks.

**Tech Sector Power and Influence**

* **Historical Ideology:** The belief in technological solutionism, or technology as a solution to major problems, dates back centuries.
* **Modern-Day Acceleration:** Today's tech acceleration in the U.S. is driven by capitalism and the race against foreign powers, championed by Silicon Valley.
* **Disconnect with Public:** Many Americans now distrust tech leaders, associating technological progress with potential societal disruptions.

[Source (Vox)](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,500+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16nnq2c/ai_thats_smarter_than_humans_americans_say_a_firm/
-----
Title: Microsoft’s Copilot puts AI into everything, YouTube announces 3 new AI features for creators, 4 Crucial Factors for Evaluating LLMs in Industry Applications, AI Detection Tool Concerns, Amazon brings Generative AI to Alexa and Fire TV, DALL·E 3
Content: [https://youtu.be/qe5tBvkvrf8](https://youtu.be/qe5tBvkvrf8)

# Summary:

# Microsoft’s Copilot puts AI into everything

Microsoft has announced a new AI-powered feature, Microsoft Copilot. It’ll bring AI features into various Windows 11, Microsoft 365, Edge, and Bing. Our first impressions are that it’s Bing but for Windows. You can use Copilot to rearrange windows, generate text, open apps on the web, edit pictures and more.Copilot can be accessed via an app or with a simple right-click and will be rolled out across Bing, Edge, and Microsoft 365 this fall, with the free Windows 11 update starting on September 26th.Why does this matter?While we don’t see any revolutionary use cases of Copilot as of now, it’s still a huge step towards the democratization of AI. As more users get their hands on this AI copilot, we’ll know the true extent of its effectiveness. If all goes well, Microsoft will end up grabbing an even bigger share of the AI market as it will deliver AI natively to all Windows devices.

# YouTube announces 3 new AI features for creators

In a YouTube event, the company announced 3 AI-powered features for YouTube Shorts creators.

**Dream Screen**: It allows users to create image or video backgrounds using AI. All you need to do is type what you want to see in the background and AI will create it for you.

**Creator Music**: This was a previously available feature but got an AI revamp this time around. Creators can simply type in the kind and length of the music they need and AI will find the most relevant suggestions for their needs.

**AI Insights for Creators:** This is an inspiration tool which generates video ideas based on AI’s analysis of what the audiences are already watching and prefer.Why does this matter?It seems like a strategic decision to natively introduce AI features to support users. It’s a trend we are seeing increasingly more across the landscape. For the users, it's great news since they get free AI assistance in their creative endeavors.

# Google’s innovative approach to train smaller language models

Large language models (LLMs) have enabled new capabilities in few-shot learning, but their massive size makes deployment challenging. To address this, the authors propose a new method called distilling step-by-step, which trains smaller task-specific models using less data while surpassing LLM performance.First, the key idea is to extract rationales - intermediate reasoning steps - from an LLM using few-shot chain-of-thought prompting. These rationales are then used alongside labels to train smaller models in a multi-task framework, with tasks for label prediction and rationale generation. Experiments across NLI, QA, and math datasets show this approach reduces training data needs by 75-80% compared to standard fine-tuning.Why does this matter?This new approach to train smaller models with higher accuracy has the potential to support language models that can be deployed on local devices while retaining the performance that was previously achievable only through LLMs.

# 4 Crucial Factors for Evaluating Large Language Models in Industry Applications

Based on your end goal, you might fancy one LLM over the other. For instance, some industries value privacy over anything while others might put data accuracy over everything else. In this article, Skanda Vivek shares the 4 critical factors you should always consider when picking a large language model.He mentions Quality, Economic, Latency, and Privacy to be the 4 resting pillars of your decision. He then goes into details discussing each of these parameters and how you should evaluate a given model against them.Why does this matter?The ability to make the right decision when choosing the underlying LLM for your applications is massively important. This article will provide you with valuable insights when it comes to choosing the right LLM.

# Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT

Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.AI Detection Tool Concerns

**False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.High False Positive Rate: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.ChatGPT's Rise & ChallengesPopularity Among Students: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.Misidentification Issues: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.OpenAI's StanceDifficulty in AI Text Detection: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.Bias Against Non-English Writers: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

# X ranks lowest in tackling climate misinformation, study reveals

X, formerly known as Twitter, has ranked last in a new assessment by Climate Action Against Disinformation for its management of climate misinformation.Pinterest scored the highest in terms of addressing climate change misinformation, while other platforms like YouTube, Meta, and Instagram also ranked higher than X.Changes under Elon Musk's ownership, including unclear policies on climate misinformation and a less communicative content moderation team, have contributed to X's low ranking.Google sued after Maps allegedly directed a man to drive off a collapsed bridgePhilip Paxson, a father of two, died after Google Maps directed him to a collapsed bridge, leading to a fatal car plunge, according to a lawsuit filed by his family.The family claims Google was informed of the bridge's collapse but failed to update its navigation system, making the tech company negligent in Paxson's death.Despite having received reports about the bridge's state through its 'suggest and edit' feature, Google allegedly took no further actions to correct the route information.Study finds 95% of NFTs are now worthlessAccording to a study by dappGambl, 95% of NFTs are now practically worthless, with the majority of the 73,257 NFT collections analyzed having a market cap of zero Ether.Enthusiasm for NFTs has substantially dropped and prices have plunged, with even hyped-up collections becoming virtually valueless.The future of NFTs is uncertain; they will need to prove they have inherent value, such as cultural relevance or representing actual art, to survive.

&#x200B;

# Google expands AI coding assistant to 170 countries

\- Google launched Studio Bot in 170 countries. It was previously launched in May for Android developers in the US. The assistant helps devs generate code, fix errors and answer questions about Android.

&#x200B;

# OpenAI unveils DALL·E 3

DALL·E 3 is built natively on ChatGPT, which lets you use ChatGPT to generate tailored, detailed prompts for DALL·E 3. If it’s not quite right, you can ask ChatGPT to make tweaks.

Even with the same prompt, DALL·E 3 delivers significant improvements over DALL·E 2, as shown below (Left: DALL·E 2 results, Right: DALL·E 3). The prompt: “An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.”

OpenAI has taken steps to limit DALL·E 3’s ability to generate violent, adult, or hateful content.DALL·E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can also opt their images out from training of OpenAI’s future image generation models.

DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall.Why does this matter?As OpenAI notes, modern text-to-image systems have a tendency to ignore words or descriptions, forcing users to learn prompt engineering. DALL·E 3 represents a leap forward in AI’s ability to generate images that exactly adhere to the text you provide. Will other image generators like Midjourney and Stable Diffusion keep up?

&#x200B;

# DALL-E 3 will be available in Bing chat

\- Microsoft’s recently announced DALL-E 3 will be available in Bing as Microsoft announced users will be able to create images in a chat. DALL-E 3 will be rolled out for enterprise users in October.

&#x200B;

# ChatGPT can now generate images

Our new text-to-image model, DALL·E 3, can translate nuanced requests into extremely detailed and accurate images.Coming soon to ChatGPT Plus & Enterprise, which can help you craft amazing prompts to bring your ideas to life:[https://openai.com/dall-e-3](https://openai.com/dall-e-3)

&#x200B;

# Cisco to buy Splunk in $28 billion

In its bid to expand software and AI powered data analysis, Cisco announced it will buy cybersecurity firm, Splunk, in $28 billion. Splunk has announced AI features that detect and respond to data anomalies, earlier this year.

# Anthropic releases policy on ‘catastrophic risks’

\- Anthropic, the company behind Claude chatbot, shared a policy highlighting its commitment to responsible scaling of AI systems. The policy acknowledges AI’s potential to cause “thousands of deaths or hundreds of billions of dollars in damage.”

&#x200B;

# Amazon brings Generative AI to Alexa and Fire TV

At its annual devices event, Amazon announced a few AI updates:It will soon use a new generative AI model to power improved experiences across its Echo family of devices. The new model is specifically optimized for voice and will take into account body language as well as a person’s eye contact and gestures for more powerful conversational experiences.It also introduced generative AI updates for its Fire TV voice search, which promises to bring more conversational ways to interact with Alexa and discover new content based on specifics.Why does this matter?Integrating LLMs with voice assistants is a perfect use case. But Amazon's generative AI revamp for Alexa marks a game-changer. It promises voice assistants that understand context better, carry over information from previous conversations, and become more personalized for users.

# Amazon is turning Alexa into a hands-free ChatGPT

Amazon is upgrading Alexa, its voice assistant, with the technology behind chatbots for more complex and open-ended conversation capabilities.The new feature, which is still in progress, will show more simulated personality, interpret body language with devices equipped with cameras and modulate its voice for a more natural conversation.While this advancement holds promise, challenges like responding to body language and the fact that these large language models can sometimes blur out inappropriate or nonsensical things, remains to refine.ChatGPT Usage is Rising Again as Students Return to School

# Zuckerberg's philanthropy project is building a massive GPU cluster to ‘cure all diseases

The Chan Zuckerberg Initiative (CZI), founded by Mark Zuckerberg and his wife Priscilla Chan, plans to build one of the world's largest GPU clusters for AI-driven biomedical research.The CZI aims to use large language models to understand disease development at cellular levels and predict cell behaviors, necessitating over 1,000 Nvidia's H100 GPUs for computational requirements.The high-performance computing system, expected to be operational in 2024, will accelerate biomedical research, from mapping varied cell types in different organisms to designing potential drugs and therapeutics.

# After declining over the summer, ChatGPT usage has increased, most likely as a result of students returning to class and concerns about AI cheating.

12% Traffic Increase Last Week: ChatGPT saw a sizable jump in US web traffic as fall classes resumed.Big Drop Over Summer Break: Traffic declined steadily from May through August when school was out.Still Below Early 2022 Peaks: But current usage remains below ChatGPT's peak levels earlier this year. Back to School Brings Old ProblemsCheating Fears Resurface: Easier student access with school back raises fresh concerns about AI-aided cheating.Schools Still Debating Rules: Many institutions continue deciding whether to ban, incorporate or ignore the technology.Potential Revenue Uncertainty: Reliance on students could be problematic for monetizing ChatGPT.With the new school year boosting ChatGPT traffic, managing responsible AI use in academics remains a complex balancing act for educators.

&#x200B;

# Intel’s ‘AI PC’ can run generative AI chatbots directly on laptops

Intel’s new chip, due in December, will be able to run a generative AI chatbot on a laptop rather than having to tap into cloud data centers for computing power. It is made possible by new AI data-crunching features built into Intel's forthcoming "Meteor Lake" laptop chip and from new software tools the company is releasing.Intel also demonstrated laptops that could generate a song in the style of Taylor Swift and answer questions in a conversational style, all while disconnected from the Internet. Moreover, Microsoft's Copilot AI assistant will be able to run on Intel-based PCs.Why does this matter?This will let businesses test ChatGPT-style AI models without sending sensitive data off their own computers. Intel seems to be on track to become the lead chip manufacturer again, competing with Nvidia to make powerful chips that train AI systems such as ChatGPT and Stability AI’s models.

&#x200B;

# DeepMind’s new AI can predict genetic diseases

Google DeepMind’s new system, called AlphaMissense, can tell if the letters in the DNA will produce the correct shape. If not, it is listed as potentially disease-causing.AlphaMissense can predict the likelihood of genetic diseases by analyzing genetic mutations called missense variants.AlphaMissense operates like a large language model, trained on human and primate biology, capable of identifying normal sequences of proteins and detecting changes that could suggest a disease.With 90% accuracy, AlphaMissense is more reliable than existing tools, potentially accelerating the process of identifying disease-causing genetic mutations, which previously required months of meticulous research.

Currently, genetic disease hunters have fairly limited knowledge of which areas of human DNA can lead to disease and have to search across billions of chemical building blocks that make up DNA. They have classified 0.1% of letter changes, or mutations, as either benign or disease-causing. DeepMind's new model pushed that percentage up to 89%.Why does this matter?AI is changing nearly everything we do at the moment and might revolutionize molecular biology and life sciences, too. This development is expected to speed up diagnosis and help search for better genetic disease treatments.

&#x200B;

# Google is turning its Bard AI chatbot into a personal assistant

  
Google's Bard AI now has enhanced capabilities, pulling real-time data from Google's other applications and a user's data silo to deliver more relevant chatbot responses.  
A new feature named Bard Extensions allows the AI to access user's personal Google data to provide specific answers about their daily activities, while promising not to be used for ad targeting or training the AI model.  
To increase transparency and accuracy, Google is introducing a 'Double Check' feature where Bard audits its responses and highlights contradictory or heavily referenced statements.

&#x200B;

# DeepMind’s New AI Can Predict Genetic Diseases

AlphaMissense, a new model from Google’s artificial intelligence team, analyzes the effects of DNA mutations and will accelerate research into rare diseases.  
About 10 years ago, Žiga Avsec was a PhD physics student who found himself taking a crash course in genomics via a university module on machine learning. He was soon working in a lab that studied rare diseases, on a project aiming to pin down the exact genetic mutation that caused an unusual mitochondrial disease.  
This was, Avsec says, a “needle in a haystack” problem. There were millions of potential culprits lurking in the genetic code—DNA mutations that could wreak havoc on a person’s biology. Of particular interest were so-called missense variants: single-letter changes to genetic code that result in a different amino acid being made within a protein. Amino acids are the building blocks of proteins, and proteins are the building blocks of everything else in the body, so even small changes can have large and far-reaching effects.

&#x200B;

# Podcast Detailed Transcript:

Microsoft recently announced a game-changing feature called Microsoft Copilot. This exciting new addition will infuse AI capabilities into various Windows 11, Microsoft 365, Edge, and Bing applications. Think of it as Bing, but specifically designed for Windows devices. So, what can Copilot do? Quite a lot, actually. With this tool, you can rearrange windows effortlessly, generate text, open web apps, edit pictures, and much more. It's accessible both via an app and through a simple right-click, making it convenient for users to tap into its AI-powered goodness. But when can we start using Copilot? Well, the good news is that it's just around the corner. Microsoft plans to roll out Copilot this fall, making it available across Bing, Edge, and Microsoft 365. And for Windows users, you'll get to enjoy this feature sooner than you think. The free Windows 11 update will begin on September 26th. Now, you might be wondering, why is this such a big deal? The answer lies in the democratization of AI. While we don't have any mind-blowing use cases for Copilot just yet, this step forward by Microsoft is significant. As more users get their hands on this AI copilot, we'll start to see its true capabilities. And if all goes well, Microsoft could dominate an even larger share of the AI market by delivering AI natively.YouTube just announced some exciting news for creators! They're rolling out three new AI-powered features for YouTube Shorts creators. Let me break it down for you. First up, we have Dream Screen. This feature lets you create image or video backgrounds using AI. All you have to do is type in what you want to see in the background, and AI will make it happen. How cool is that? Next, we've got Creator Music. This feature got an AI revamp, making it even better than before. Now, creators can simply type in the kind and length of the music they need, and AI will find the most relevant suggestions. It's like having your own personal music assistant. Last but not least, we have AI Insights for Creators. This is a tool that generates video ideas for creators based on AI's analysis of what audiences are already watching and preferring. So, if you're looking for some inspiration, AI has got your back. This move by YouTube seems like a smart strategic decision to integrate AI features directly into the platform.

When it comes to evaluating large language models (LLMs) for industry applications, there are four crucial factors to consider. Skanda Vivek highlights these factors, which include quality, economic aspects, latency, and privacy. Each of these factors plays a significant role in determining the suitability of a particular LLM. The quality of the LLM is of utmost importance. Depending on your end goal, you may prioritize different aspects of quality, such as data accuracy, contextual understanding, or fluency. Consider what matters most to your industry and choose an LLM that aligns with those preferences. Economic factors also come into play. It's essential to assess the cost-effectiveness of implementing a particular LLM. Does it provide value for money? Can it fit within your organization's budget? Analyzing the economic aspects ensures you make an informed decision. Latency, or the response time of the LLM, is another vital factor. Some applications require real-time or near-instantaneous responses. Evaluating an LLM's latency helps you select the model that meets your specific timing requirements. Finally, privacy is increasingly significant for many industries. Skanda Vivek emphasizes the need to consider privacy when choosing an LLM. Depending on your industry, data security and privacy regulations may be a top priority. Ensuring the chosen model aligns with your privacy needs is crucial. Choosing the right LLM is a critical decision that can significantly impact your applications. By carefully considering these four factors—quality, economic aspects, latency, and privacy—you can make an informed choice that aligns with your industry's requirements. In recent news, some universities are raising concerns about AI detection software used to catch cheating students. There are worries that students could be falsely accused of cheating when using tools like ChatGPT. As a result, some universities are opting to abandon these AI detection systems. The debate highlights the potential drawbacks and risks associated with relying entirely on AI tools for academic integrity.So, here's the thing. Some major universities have decided to ditch AI detection tools because they're worried about their accuracy. And let's face it, nobody wants to be falsely accused of cheating, right? One tool in particular, called ChatGPT, has caused quite a stir. The problem with ChatGPT is that it's gained popularity among students, and that's got educators really concerned about academic dishonesty. But it's not just about students using AI to write their essays. It's also about the tool itself misidentifying things and getting it all wrong. For example, one professor in Texas failed half of his class because of false detections by ChatGPT. Can you imagine? Talk about a nightmare scenario. And it's not just him. Other students have also been wrongly accused by anti-plagiarism software using ChatGPT. What's interesting is that even OpenAI, the company behind ChatGPT, has abandoned their own AI text detector due to its low accuracy rate. They've even warned educators about relying too heavily on AI content detectors. And here's another thing to consider: these detection tools often get it wrong when it comes to content written by non-English writers. So, yeah, there are some serious concerns here. That's why some universities, like Vanderbilt and Northwestern, have decided to say "no thanks" to these AI detection tools. It's better to be safe than sorry, right? After all, nobody wants to unfairly accuse a student of cheating.Hey there! Some interesting news for you today. According to Climate Action Against Disinformation, X, which we all know as Twitter, has ranked last when it comes to tackling climate misinformation. Quite the bummer, right? It turns out that Pinterest is leading the pack in addressing climate change misinformation, with YouTube, Meta (formerly known as Facebook), and Instagram not too far behind. But poor old X is lagging behind. So, what led to this low ranking for X? Well, it seems that since Elon Musk took over, things have changed, and not for the better. There are unclear policies on climate misinformation and a less communicative content moderation team, both of which have contributed to X's downward slide in the rankings. Maybe they need to step up their game a bit. In another news story, Google is facing a lawsuit after it allegedly directed a man, Philip Paxson, to drive off a collapsed bridge via Google Maps. Sadly, Paxson lost his life in the tragic accident. According to his family, Google was aware of the bridge's collapse but failed to update its navigation system, which they argue makes the tech giant negligent in Paxson's death. Google apparently received reports about the bridge's condition, but did nothing to fix the route information. It's a heartbreaking situation. And finally, brace yourself for this one. A study by dappGambl has found that a whopping 95% of NFTs are now practically worthless. Yep, you heard that right. NFTs, which were once all the rage, have lost their shine. Prices have plummeted, and most of the 73,257 NFT collections analyzed have a market cap of zero Ether. It's uncertain what the future holds for NFTs, but they'll need to prove their worth, whether through cultural significance or as a representation of actual art, if they want to stick around. So, that's the latest in tech and climate news. Stay tuned for more updates!OpenAI has just unveiled their latest model for text-to-image translation called DALL·E 3, and it's pretty impressive! This new version is built directly on ChatGPT, which means you can use ChatGPT to generate customized and detailed prompts for DALL·E 3. And if the results aren't exactly what you were hoping for, you can even ask ChatGPT to make some tweaks. Compared to its predecessor, DALL·E 2, DALL·E 3 delivers significant improvements in creating detailed images. OpenAI showcased this by providing a prompt for an expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula. The results from DALL·E 3 were far superior to those from DALL·E 2. OpenAI has also taken steps to ensure that DALL·E 3 doesn't generate violent, adult, or hateful content. They have designed it to decline requests for images in the style of living artists. Additionally, creators have the option to exclude their images from being used in the training of OpenAI's future image generation models, giving them more control over the use of their work. Currently, DALL·E 3 is in research preview and will be available to ChatGPT Plus and Enterprise customers in October through the API. It will later be made available in Labs for those interested. This new release is important because it addresses the limitations of previous text-to-image systems, which often ignored certain words or descriptions. With DALL·E 3, AI's ability to generate images that align precisely with the provided text takes a huge leap forward. It raises questions about how other image generators like Midjourney and Stable Diffusion will keep up. OpenAI has also prioritized safety improvements in DALL·E 3. They have implemented measures to prevent explicit content and have tools in place to identify risky words and block public figures. Furthermore, artists can now request that their work be blocked from AI copying, and DALL·E 3 won't mimic the styles of specific artists when named. OpenAI hopes that the integration with ChatGPT and the safety guards in DALL·E 3 will expand access to this technology while preventing misuse. However, there are still concerns and legal issues surrounding AI-generated art that need to be addressed.Amazon had some exciting announcements at its recent devices event. One of the standout updates is the integration of generative AI into their Echo family of devices. This new AI model is optimized for voice, taking into account not only what is said but also body language, eye contact, and gestures. This means that interactions with Alexa will become much more powerful and conversational, providing users with improved experiences. But that's not all. Amazon has also introduced generative AI updates for Fire TV's voice search. This update aims to enhance the conversational interaction between users and Alexa, allowing for a more natural and intuitive way to discover new content based on specific preferences. This development is significant because it showcases how integrating language models like Generative AI into voice assistants can revolutionize the way we interact with them. Amazon's revamp of Alexa using generative AI is a game-changer. It enables voice assistants to better understand context, seamlessly carry over information from previous conversations, and provide a more personalized experience for users. In fact, Amazon is transforming Alexa into a hands-free ChatGPT by leveraging the technology behind chatbots. This upgrade will give Alexa the ability to engage in more complex and open-ended conversations. It will also enhance its simulated personality, interpret body language (for devices with cameras), and modulate its voice for a more natural conversation. However, there are some challenges to overcome, such as responding accurately to body language and refining these large language models to prevent inappropriate or nonsensical responses. But with Amazon's dedication to improving AI experiences, we can expect significant advancements in these areas. Overall, Amazon's integration of generative AI into Alexa and Fire TV demonstrates their commitment to providing users with more intuitive, personalized, and conversational experiences.Hey there! Have you heard about Mark Zuckerberg's latest philanthropy project? It's got a pretty ambitious goal - to "cure all diseases". The project, called the Chan Zuckerberg Initiative (CZI), is a collaborative effort between Zuckerberg and his wife, Priscilla Chan. So here's the plan: CZI is planning to build one of the biggest GPU clusters in the world specifically for AI-driven biomedical research. They want to use large language models to dive deep into disease development at the cellular level and even predict how cells behave. And to do that, they're going to need some serious computational power - over 1,000 Nvidia's H100 GPUs! This high-performance computing system is expected to be up and running by 2024. And let me tell you, it's going to revolutionize biomedical research. From mapping out various cell types across different organisms to designing potential drugs and therapeutics, this GPU cluster will supercharge the entire process. I don't know about you, but I'm pretty excited to see what kind of breakthroughs this project will bring. Who knows, maybe we'll be living in a world where diseases are a thing of the past sooner than we think!So, let's dive into the latest AI updates from OpenAI, Microsoft, YouTube, Google, Cisco, and Anthropic. It seems like ChatGPT is back in the spotlight with an increase in usage, particularly because students are returning to school and concerns about AI cheating are on the rise. After experiencing a decline throughout the summer, ChatGPT has seen a 12% traffic increase since fall classes resumed in the US. However, it's important to note that current usage is still below the peak levels seen earlier this year. With students back in the classroom, concerns about AI-aided cheating have resurfaced. The easier access students have to AI technology raises fresh debates among schools about whether to ban, incorporate, or ignore such tools. For educators, managing responsible AI use in academics is becoming a complex balancing act. There's also some uncertainty surrounding potential revenue as ChatGPT's reliance on students could pose challenges for monetization. Moving on to other AI news, Microsoft has announced a new AI-powered feature called Microsoft Copilot. This feature, available in various Windows 11 applications, Microsoft 365, Edge, and Bing, allows users to rearrange windows, generate text, edit pictures, and more. It's like having Bing integrated into your Windows experience. YouTube is not far behind with its AI advancements. The platform has introduced three new AI-powered features specifically for Shorts creators. Dream Screen uses AI to generate background images and videos, Creator Music helps find the perfect track for Shorts, and AI Insights for Creators assists in brainstorming the next video idea. These features aim to enhance the content creation experience on YouTube. Meanwhile, Google has expanded its AI coding assistant, Studio Bot, to 170 countries. Initially launched for Android developers in the US, this assistant helps generate code, fix errors, and answer questions about Android development. It's a handy tool for developers worldwide. In the world of image creation, Microsoft's DALL-E 3 is making its way to Bing. Soon, users will be able to create images in a chat using DALL-E 3. This exciting feature will be rolled out for enterprise users in October, opening up new possibilities for visual communication. Now, let's switch gears to a significant acquisition. Cisco has announced its plan to acquire cybersecurity firm Splunk for $28 billion. This move aligns with Cisco's goal to expand its software and AI-powered data analysis capabilities. Splunk, which introduced AI features earlier this year to detect and respond to data anomalies, will play a vital role in Cisco's strategy. In the realm of responsible AI scaling, Anthropic, the company behind the Claude chatbot, has released a policy that emphasizes its commitment to responsible AI system development. The policy acknowledges the potential for AI systems to cause catastrophic risks, including thousands of deaths or immense financial damage. It's encouraging to see companies prioritizing responsible AI practices. In other tech news on September 22nd, 2023, Cisco is set to make its largest acquisition ever by acquiring Splunk for $28 billion. This move aims to boost security services and system performance troubleshooting. On a different note, NASA eagerly awaits the return of pristine asteroid Bennu samples, taken by OSIRIS-REx in 2020. The samples could unlock valuable insights into the origins of our solar system. In the legal world, lawyers who sued Tesla's board for excessive pay are seeking a jaw-dropping $10,000 an hour. The case is sure to attract attention as it unfolds. Another interesting development involves an anonymous developer who used OpenAI's ChatGPT API to program an AI that created and launched an ERC-20 token called AstroPepeX. Within just 24 hours, the token generated an astonishing $12.9 million in trading. It's a testament to the possibilities AI offers in the realm of finance and entrepreneurship. Lastly, Ilya Sutskever, one of OpenAI's renowned figures, along with machine ethicist Thomas Krendl Gilbert, have described AI development as "alchemy." This comparison underscores the unpredictable and mysterious nature of AI outcomes, sparking heated debate within the industry. And there you have it, the latest AI updates featuring ChatGPT, Microsoft, YouTube, Google, Cisco, and Anthropic. Stay tuned for more exciting advancements in the world of artificial intelligence.Hey there! If you're excited about diving deeper into the world of artificial intelligence, I've got just the thing for you! There's this amazing book called "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence." Trust me, it's a game-changer! Now, let me tell you why you should totally get your hands on this gem. "AI Unraveled" is packed with all the answers to those burning questions you may have about AI. Think of it as your ultimate AI guidebook. It's like having a knowledgeable expert right by your side, unravelling the mysteries of artificial intelligence in a way that's easy to comprehend. The best part? You can grab a copy of this must-read book at three different platforms: Apple, Google, or Amazon. So, no matter whether you're an Apple aficionado, a Google guru, or an Amazon enthusiast, there's a way for you to access this invaluable resource. So, why wait any longer? Dive into "AI Unraveled" today and expand your understanding of artificial intelligence like never before. This book is a game-changer, and it's ready to be enjoyed by curious minds like yours. Happy reading!In today's episode, we covered Microsoft's AI-powered Copilot, YouTube's new AI features for creators, evaluating large language models in industry, concerns with AI detection tools in universities, rankings of tech companies tackling misinformation, OpenAI's DALL·E 3 text-to-image model, generative AI updates from Amazon, Zuckerberg's philanthropy in AI-driven research, ChatGPT usage concerns, and other notable news - plus, don't forget to expand your AI knowledge with the essential book 'AI Unraveled'. Join us next time on AI Unraveled as we continue to demystify frequently asked questions on artificial intelligence and bring you the latest trends in AI, including ChatGPT advancements and the exciting collaboration between Google Brain and DeepMind. Stay informed, stay curious, and don't forget to subscribe for more!

# Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence," available at Apple, Google, or Amazon today today:

# AI Unraveled @ Amazon: [https://amzn.to/3ZrpkCu](https://amzn.to/3ZrpkCu)

# AI Unraveled @ Apple: [http://books.apple.com/us/book/id6445730691](http://books.apple.com/us/book/id6445730691)

# AI Unraveled @ Google: [https://play.google.com/store/books/details?id=oySuEAAAQBAJ](https://play.google.com/store/books/details?id=oySuEAAAQBAJ)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pp2h6/microsofts_copilot_puts_ai_into_everything/
-----
Title: Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT
Content: Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**AI Detection Tool Concerns**

* **False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.
* **High False Positive Rate**: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.

**ChatGPT's Rise & Challenges**

* **Popularity Among Students**: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.
* **Misidentification Issues**: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.

**OpenAI's Stance**

* **Difficulty in AI Text Detection**: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.
* **Bias Against Non-English Writers**: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

[Source (Business Insider)](https://www.businessinsider.com/universities-ditch-ai-detectors-over-fears-students-falsely-accused-cheating-2023-9?r=US&IR=T)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,700+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pahu7/some_universities_are_ditching_ai_detection/
-----
News posts saved as '2023-09-26-reddit_news_posts.md'
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pi4tp/indeeds_ceo_says_college_students_might_be/
-----
Title: Microsoft seeks nuclear reactors to power AI
Content: -Microsoft made a job posting looking for a nuclear tech expert who could help integrate small modular nuclear reactors “to power the datacenters that the Microsoft Cloud and AI reside on,"'  
-Bill Gates is chairman of the board TerraPower, a company working in the field of small modular reactors  
-Microsoft has previously publicly committed to pursuing nuclear energy

Source:
https://www.cnbc.com/2023/09/25/microsoft-is-hiring-a-nuclear-energy-expert-to-help-power-data-centers.html
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16s9aes/microsoft_seeks_nuclear_reactors_to_power_ai/
-----
Title: Microsoft’s Copilot puts AI into everything, YouTube announces 3 new AI features for creators, 4 Crucial Factors for Evaluating LLMs in Industry Applications, AI Detection Tool Concerns, Amazon brings Generative AI to Alexa and Fire TV, DALL·E 3
Content: [https://youtu.be/qe5tBvkvrf8](https://youtu.be/qe5tBvkvrf8)

# Summary:

# Microsoft’s Copilot puts AI into everything

Microsoft has announced a new AI-powered feature, Microsoft Copilot. It’ll bring AI features into various Windows 11, Microsoft 365, Edge, and Bing. Our first impressions are that it’s Bing but for Windows. You can use Copilot to rearrange windows, generate text, open apps on the web, edit pictures and more.Copilot can be accessed via an app or with a simple right-click and will be rolled out across Bing, Edge, and Microsoft 365 this fall, with the free Windows 11 update starting on September 26th.Why does this matter?While we don’t see any revolutionary use cases of Copilot as of now, it’s still a huge step towards the democratization of AI. As more users get their hands on this AI copilot, we’ll know the true extent of its effectiveness. If all goes well, Microsoft will end up grabbing an even bigger share of the AI market as it will deliver AI natively to all Windows devices.

# YouTube announces 3 new AI features for creators

In a YouTube event, the company announced 3 AI-powered features for YouTube Shorts creators.

**Dream Screen**: It allows users to create image or video backgrounds using AI. All you need to do is type what you want to see in the background and AI will create it for you.

**Creator Music**: This was a previously available feature but got an AI revamp this time around. Creators can simply type in the kind and length of the music they need and AI will find the most relevant suggestions for their needs.

**AI Insights for Creators:** This is an inspiration tool which generates video ideas based on AI’s analysis of what the audiences are already watching and prefer.Why does this matter?It seems like a strategic decision to natively introduce AI features to support users. It’s a trend we are seeing increasingly more across the landscape. For the users, it's great news since they get free AI assistance in their creative endeavors.

# Google’s innovative approach to train smaller language models

Large language models (LLMs) have enabled new capabilities in few-shot learning, but their massive size makes deployment challenging. To address this, the authors propose a new method called distilling step-by-step, which trains smaller task-specific models using less data while surpassing LLM performance.First, the key idea is to extract rationales - intermediate reasoning steps - from an LLM using few-shot chain-of-thought prompting. These rationales are then used alongside labels to train smaller models in a multi-task framework, with tasks for label prediction and rationale generation. Experiments across NLI, QA, and math datasets show this approach reduces training data needs by 75-80% compared to standard fine-tuning.Why does this matter?This new approach to train smaller models with higher accuracy has the potential to support language models that can be deployed on local devices while retaining the performance that was previously achievable only through LLMs.

# 4 Crucial Factors for Evaluating Large Language Models in Industry Applications

Based on your end goal, you might fancy one LLM over the other. For instance, some industries value privacy over anything while others might put data accuracy over everything else. In this article, Skanda Vivek shares the 4 critical factors you should always consider when picking a large language model.He mentions Quality, Economic, Latency, and Privacy to be the 4 resting pillars of your decision. He then goes into details discussing each of these parameters and how you should evaluate a given model against them.Why does this matter?The ability to make the right decision when choosing the underlying LLM for your applications is massively important. This article will provide you with valuable insights when it comes to choosing the right LLM.

# Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT

Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.AI Detection Tool Concerns

**False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.High False Positive Rate: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.ChatGPT's Rise & ChallengesPopularity Among Students: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.Misidentification Issues: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.OpenAI's StanceDifficulty in AI Text Detection: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.Bias Against Non-English Writers: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

# X ranks lowest in tackling climate misinformation, study reveals

X, formerly known as Twitter, has ranked last in a new assessment by Climate Action Against Disinformation for its management of climate misinformation.Pinterest scored the highest in terms of addressing climate change misinformation, while other platforms like YouTube, Meta, and Instagram also ranked higher than X.Changes under Elon Musk's ownership, including unclear policies on climate misinformation and a less communicative content moderation team, have contributed to X's low ranking.Google sued after Maps allegedly directed a man to drive off a collapsed bridgePhilip Paxson, a father of two, died after Google Maps directed him to a collapsed bridge, leading to a fatal car plunge, according to a lawsuit filed by his family.The family claims Google was informed of the bridge's collapse but failed to update its navigation system, making the tech company negligent in Paxson's death.Despite having received reports about the bridge's state through its 'suggest and edit' feature, Google allegedly took no further actions to correct the route information.Study finds 95% of NFTs are now worthlessAccording to a study by dappGambl, 95% of NFTs are now practically worthless, with the majority of the 73,257 NFT collections analyzed having a market cap of zero Ether.Enthusiasm for NFTs has substantially dropped and prices have plunged, with even hyped-up collections becoming virtually valueless.The future of NFTs is uncertain; they will need to prove they have inherent value, such as cultural relevance or representing actual art, to survive.

&#x200B;

# Google expands AI coding assistant to 170 countries

\- Google launched Studio Bot in 170 countries. It was previously launched in May for Android developers in the US. The assistant helps devs generate code, fix errors and answer questions about Android.

&#x200B;

# OpenAI unveils DALL·E 3

DALL·E 3 is built natively on ChatGPT, which lets you use ChatGPT to generate tailored, detailed prompts for DALL·E 3. If it’s not quite right, you can ask ChatGPT to make tweaks.

Even with the same prompt, DALL·E 3 delivers significant improvements over DALL·E 2, as shown below (Left: DALL·E 2 results, Right: DALL·E 3). The prompt: “An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.”

OpenAI has taken steps to limit DALL·E 3’s ability to generate violent, adult, or hateful content.DALL·E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can also opt their images out from training of OpenAI’s future image generation models.

DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall.Why does this matter?As OpenAI notes, modern text-to-image systems have a tendency to ignore words or descriptions, forcing users to learn prompt engineering. DALL·E 3 represents a leap forward in AI’s ability to generate images that exactly adhere to the text you provide. Will other image generators like Midjourney and Stable Diffusion keep up?

&#x200B;

# DALL-E 3 will be available in Bing chat

\- Microsoft’s recently announced DALL-E 3 will be available in Bing as Microsoft announced users will be able to create images in a chat. DALL-E 3 will be rolled out for enterprise users in October.

&#x200B;

# ChatGPT can now generate images

Our new text-to-image model, DALL·E 3, can translate nuanced requests into extremely detailed and accurate images.Coming soon to ChatGPT Plus & Enterprise, which can help you craft amazing prompts to bring your ideas to life:[https://openai.com/dall-e-3](https://openai.com/dall-e-3)

&#x200B;

# Cisco to buy Splunk in $28 billion

In its bid to expand software and AI powered data analysis, Cisco announced it will buy cybersecurity firm, Splunk, in $28 billion. Splunk has announced AI features that detect and respond to data anomalies, earlier this year.

# Anthropic releases policy on ‘catastrophic risks’

\- Anthropic, the company behind Claude chatbot, shared a policy highlighting its commitment to responsible scaling of AI systems. The policy acknowledges AI’s potential to cause “thousands of deaths or hundreds of billions of dollars in damage.”

&#x200B;

# Amazon brings Generative AI to Alexa and Fire TV

At its annual devices event, Amazon announced a few AI updates:It will soon use a new generative AI model to power improved experiences across its Echo family of devices. The new model is specifically optimized for voice and will take into account body language as well as a person’s eye contact and gestures for more powerful conversational experiences.It also introduced generative AI updates for its Fire TV voice search, which promises to bring more conversational ways to interact with Alexa and discover new content based on specifics.Why does this matter?Integrating LLMs with voice assistants is a perfect use case. But Amazon's generative AI revamp for Alexa marks a game-changer. It promises voice assistants that understand context better, carry over information from previous conversations, and become more personalized for users.

# Amazon is turning Alexa into a hands-free ChatGPT

Amazon is upgrading Alexa, its voice assistant, with the technology behind chatbots for more complex and open-ended conversation capabilities.The new feature, which is still in progress, will show more simulated personality, interpret body language with devices equipped with cameras and modulate its voice for a more natural conversation.While this advancement holds promise, challenges like responding to body language and the fact that these large language models can sometimes blur out inappropriate or nonsensical things, remains to refine.ChatGPT Usage is Rising Again as Students Return to School

# Zuckerberg's philanthropy project is building a massive GPU cluster to ‘cure all diseases

The Chan Zuckerberg Initiative (CZI), founded by Mark Zuckerberg and his wife Priscilla Chan, plans to build one of the world's largest GPU clusters for AI-driven biomedical research.The CZI aims to use large language models to understand disease development at cellular levels and predict cell behaviors, necessitating over 1,000 Nvidia's H100 GPUs for computational requirements.The high-performance computing system, expected to be operational in 2024, will accelerate biomedical research, from mapping varied cell types in different organisms to designing potential drugs and therapeutics.

# After declining over the summer, ChatGPT usage has increased, most likely as a result of students returning to class and concerns about AI cheating.

12% Traffic Increase Last Week: ChatGPT saw a sizable jump in US web traffic as fall classes resumed.Big Drop Over Summer Break: Traffic declined steadily from May through August when school was out.Still Below Early 2022 Peaks: But current usage remains below ChatGPT's peak levels earlier this year. Back to School Brings Old ProblemsCheating Fears Resurface: Easier student access with school back raises fresh concerns about AI-aided cheating.Schools Still Debating Rules: Many institutions continue deciding whether to ban, incorporate or ignore the technology.Potential Revenue Uncertainty: Reliance on students could be problematic for monetizing ChatGPT.With the new school year boosting ChatGPT traffic, managing responsible AI use in academics remains a complex balancing act for educators.

&#x200B;

# Intel’s ‘AI PC’ can run generative AI chatbots directly on laptops

Intel’s new chip, due in December, will be able to run a generative AI chatbot on a laptop rather than having to tap into cloud data centers for computing power. It is made possible by new AI data-crunching features built into Intel's forthcoming "Meteor Lake" laptop chip and from new software tools the company is releasing.Intel also demonstrated laptops that could generate a song in the style of Taylor Swift and answer questions in a conversational style, all while disconnected from the Internet. Moreover, Microsoft's Copilot AI assistant will be able to run on Intel-based PCs.Why does this matter?This will let businesses test ChatGPT-style AI models without sending sensitive data off their own computers. Intel seems to be on track to become the lead chip manufacturer again, competing with Nvidia to make powerful chips that train AI systems such as ChatGPT and Stability AI’s models.

&#x200B;

# DeepMind’s new AI can predict genetic diseases

Google DeepMind’s new system, called AlphaMissense, can tell if the letters in the DNA will produce the correct shape. If not, it is listed as potentially disease-causing.AlphaMissense can predict the likelihood of genetic diseases by analyzing genetic mutations called missense variants.AlphaMissense operates like a large language model, trained on human and primate biology, capable of identifying normal sequences of proteins and detecting changes that could suggest a disease.With 90% accuracy, AlphaMissense is more reliable than existing tools, potentially accelerating the process of identifying disease-causing genetic mutations, which previously required months of meticulous research.

Currently, genetic disease hunters have fairly limited knowledge of which areas of human DNA can lead to disease and have to search across billions of chemical building blocks that make up DNA. They have classified 0.1% of letter changes, or mutations, as either benign or disease-causing. DeepMind's new model pushed that percentage up to 89%.Why does this matter?AI is changing nearly everything we do at the moment and might revolutionize molecular biology and life sciences, too. This development is expected to speed up diagnosis and help search for better genetic disease treatments.

&#x200B;

# Google is turning its Bard AI chatbot into a personal assistant

  
Google's Bard AI now has enhanced capabilities, pulling real-time data from Google's other applications and a user's data silo to deliver more relevant chatbot responses.  
A new feature named Bard Extensions allows the AI to access user's personal Google data to provide specific answers about their daily activities, while promising not to be used for ad targeting or training the AI model.  
To increase transparency and accuracy, Google is introducing a 'Double Check' feature where Bard audits its responses and highlights contradictory or heavily referenced statements.

&#x200B;

# DeepMind’s New AI Can Predict Genetic Diseases

AlphaMissense, a new model from Google’s artificial intelligence team, analyzes the effects of DNA mutations and will accelerate research into rare diseases.  
About 10 years ago, Žiga Avsec was a PhD physics student who found himself taking a crash course in genomics via a university module on machine learning. He was soon working in a lab that studied rare diseases, on a project aiming to pin down the exact genetic mutation that caused an unusual mitochondrial disease.  
This was, Avsec says, a “needle in a haystack” problem. There were millions of potential culprits lurking in the genetic code—DNA mutations that could wreak havoc on a person’s biology. Of particular interest were so-called missense variants: single-letter changes to genetic code that result in a different amino acid being made within a protein. Amino acids are the building blocks of proteins, and proteins are the building blocks of everything else in the body, so even small changes can have large and far-reaching effects.

&#x200B;

# Podcast Detailed Transcript:

Microsoft recently announced a game-changing feature called Microsoft Copilot. This exciting new addition will infuse AI capabilities into various Windows 11, Microsoft 365, Edge, and Bing applications. Think of it as Bing, but specifically designed for Windows devices. So, what can Copilot do? Quite a lot, actually. With this tool, you can rearrange windows effortlessly, generate text, open web apps, edit pictures, and much more. It's accessible both via an app and through a simple right-click, making it convenient for users to tap into its AI-powered goodness. But when can we start using Copilot? Well, the good news is that it's just around the corner. Microsoft plans to roll out Copilot this fall, making it available across Bing, Edge, and Microsoft 365. And for Windows users, you'll get to enjoy this feature sooner than you think. The free Windows 11 update will begin on September 26th. Now, you might be wondering, why is this such a big deal? The answer lies in the democratization of AI. While we don't have any mind-blowing use cases for Copilot just yet, this step forward by Microsoft is significant. As more users get their hands on this AI copilot, we'll start to see its true capabilities. And if all goes well, Microsoft could dominate an even larger share of the AI market by delivering AI natively.YouTube just announced some exciting news for creators! They're rolling out three new AI-powered features for YouTube Shorts creators. Let me break it down for you. First up, we have Dream Screen. This feature lets you create image or video backgrounds using AI. All you have to do is type in what you want to see in the background, and AI will make it happen. How cool is that? Next, we've got Creator Music. This feature got an AI revamp, making it even better than before. Now, creators can simply type in the kind and length of the music they need, and AI will find the most relevant suggestions. It's like having your own personal music assistant. Last but not least, we have AI Insights for Creators. This is a tool that generates video ideas for creators based on AI's analysis of what audiences are already watching and preferring. So, if you're looking for some inspiration, AI has got your back. This move by YouTube seems like a smart strategic decision to integrate AI features directly into the platform.

When it comes to evaluating large language models (LLMs) for industry applications, there are four crucial factors to consider. Skanda Vivek highlights these factors, which include quality, economic aspects, latency, and privacy. Each of these factors plays a significant role in determining the suitability of a particular LLM. The quality of the LLM is of utmost importance. Depending on your end goal, you may prioritize different aspects of quality, such as data accuracy, contextual understanding, or fluency. Consider what matters most to your industry and choose an LLM that aligns with those preferences. Economic factors also come into play. It's essential to assess the cost-effectiveness of implementing a particular LLM. Does it provide value for money? Can it fit within your organization's budget? Analyzing the economic aspects ensures you make an informed decision. Latency, or the response time of the LLM, is another vital factor. Some applications require real-time or near-instantaneous responses. Evaluating an LLM's latency helps you select the model that meets your specific timing requirements. Finally, privacy is increasingly significant for many industries. Skanda Vivek emphasizes the need to consider privacy when choosing an LLM. Depending on your industry, data security and privacy regulations may be a top priority. Ensuring the chosen model aligns with your privacy needs is crucial. Choosing the right LLM is a critical decision that can significantly impact your applications. By carefully considering these four factors—quality, economic aspects, latency, and privacy—you can make an informed choice that aligns with your industry's requirements. In recent news, some universities are raising concerns about AI detection software used to catch cheating students. There are worries that students could be falsely accused of cheating when using tools like ChatGPT. As a result, some universities are opting to abandon these AI detection systems. The debate highlights the potential drawbacks and risks associated with relying entirely on AI tools for academic integrity.So, here's the thing. Some major universities have decided to ditch AI detection tools because they're worried about their accuracy. And let's face it, nobody wants to be falsely accused of cheating, right? One tool in particular, called ChatGPT, has caused quite a stir. The problem with ChatGPT is that it's gained popularity among students, and that's got educators really concerned about academic dishonesty. But it's not just about students using AI to write their essays. It's also about the tool itself misidentifying things and getting it all wrong. For example, one professor in Texas failed half of his class because of false detections by ChatGPT. Can you imagine? Talk about a nightmare scenario. And it's not just him. Other students have also been wrongly accused by anti-plagiarism software using ChatGPT. What's interesting is that even OpenAI, the company behind ChatGPT, has abandoned their own AI text detector due to its low accuracy rate. They've even warned educators about relying too heavily on AI content detectors. And here's another thing to consider: these detection tools often get it wrong when it comes to content written by non-English writers. So, yeah, there are some serious concerns here. That's why some universities, like Vanderbilt and Northwestern, have decided to say "no thanks" to these AI detection tools. It's better to be safe than sorry, right? After all, nobody wants to unfairly accuse a student of cheating.Hey there! Some interesting news for you today. According to Climate Action Against Disinformation, X, which we all know as Twitter, has ranked last when it comes to tackling climate misinformation. Quite the bummer, right? It turns out that Pinterest is leading the pack in addressing climate change misinformation, with YouTube, Meta (formerly known as Facebook), and Instagram not too far behind. But poor old X is lagging behind. So, what led to this low ranking for X? Well, it seems that since Elon Musk took over, things have changed, and not for the better. There are unclear policies on climate misinformation and a less communicative content moderation team, both of which have contributed to X's downward slide in the rankings. Maybe they need to step up their game a bit. In another news story, Google is facing a lawsuit after it allegedly directed a man, Philip Paxson, to drive off a collapsed bridge via Google Maps. Sadly, Paxson lost his life in the tragic accident. According to his family, Google was aware of the bridge's collapse but failed to update its navigation system, which they argue makes the tech giant negligent in Paxson's death. Google apparently received reports about the bridge's condition, but did nothing to fix the route information. It's a heartbreaking situation. And finally, brace yourself for this one. A study by dappGambl has found that a whopping 95% of NFTs are now practically worthless. Yep, you heard that right. NFTs, which were once all the rage, have lost their shine. Prices have plummeted, and most of the 73,257 NFT collections analyzed have a market cap of zero Ether. It's uncertain what the future holds for NFTs, but they'll need to prove their worth, whether through cultural significance or as a representation of actual art, if they want to stick around. So, that's the latest in tech and climate news. Stay tuned for more updates!OpenAI has just unveiled their latest model for text-to-image translation called DALL·E 3, and it's pretty impressive! This new version is built directly on ChatGPT, which means you can use ChatGPT to generate customized and detailed prompts for DALL·E 3. And if the results aren't exactly what you were hoping for, you can even ask ChatGPT to make some tweaks. Compared to its predecessor, DALL·E 2, DALL·E 3 delivers significant improvements in creating detailed images. OpenAI showcased this by providing a prompt for an expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula. The results from DALL·E 3 were far superior to those from DALL·E 2. OpenAI has also taken steps to ensure that DALL·E 3 doesn't generate violent, adult, or hateful content. They have designed it to decline requests for images in the style of living artists. Additionally, creators have the option to exclude their images from being used in the training of OpenAI's future image generation models, giving them more control over the use of their work. Currently, DALL·E 3 is in research preview and will be available to ChatGPT Plus and Enterprise customers in October through the API. It will later be made available in Labs for those interested. This new release is important because it addresses the limitations of previous text-to-image systems, which often ignored certain words or descriptions. With DALL·E 3, AI's ability to generate images that align precisely with the provided text takes a huge leap forward. It raises questions about how other image generators like Midjourney and Stable Diffusion will keep up. OpenAI has also prioritized safety improvements in DALL·E 3. They have implemented measures to prevent explicit content and have tools in place to identify risky words and block public figures. Furthermore, artists can now request that their work be blocked from AI copying, and DALL·E 3 won't mimic the styles of specific artists when named. OpenAI hopes that the integration with ChatGPT and the safety guards in DALL·E 3 will expand access to this technology while preventing misuse. However, there are still concerns and legal issues surrounding AI-generated art that need to be addressed.Amazon had some exciting announcements at its recent devices event. One of the standout updates is the integration of generative AI into their Echo family of devices. This new AI model is optimized for voice, taking into account not only what is said but also body language, eye contact, and gestures. This means that interactions with Alexa will become much more powerful and conversational, providing users with improved experiences. But that's not all. Amazon has also introduced generative AI updates for Fire TV's voice search. This update aims to enhance the conversational interaction between users and Alexa, allowing for a more natural and intuitive way to discover new content based on specific preferences. This development is significant because it showcases how integrating language models like Generative AI into voice assistants can revolutionize the way we interact with them. Amazon's revamp of Alexa using generative AI is a game-changer. It enables voice assistants to better understand context, seamlessly carry over information from previous conversations, and provide a more personalized experience for users. In fact, Amazon is transforming Alexa into a hands-free ChatGPT by leveraging the technology behind chatbots. This upgrade will give Alexa the ability to engage in more complex and open-ended conversations. It will also enhance its simulated personality, interpret body language (for devices with cameras), and modulate its voice for a more natural conversation. However, there are some challenges to overcome, such as responding accurately to body language and refining these large language models to prevent inappropriate or nonsensical responses. But with Amazon's dedication to improving AI experiences, we can expect significant advancements in these areas. Overall, Amazon's integration of generative AI into Alexa and Fire TV demonstrates their commitment to providing users with more intuitive, personalized, and conversational experiences.Hey there! Have you heard about Mark Zuckerberg's latest philanthropy project? It's got a pretty ambitious goal - to "cure all diseases". The project, called the Chan Zuckerberg Initiative (CZI), is a collaborative effort between Zuckerberg and his wife, Priscilla Chan. So here's the plan: CZI is planning to build one of the biggest GPU clusters in the world specifically for AI-driven biomedical research. They want to use large language models to dive deep into disease development at the cellular level and even predict how cells behave. And to do that, they're going to need some serious computational power - over 1,000 Nvidia's H100 GPUs! This high-performance computing system is expected to be up and running by 2024. And let me tell you, it's going to revolutionize biomedical research. From mapping out various cell types across different organisms to designing potential drugs and therapeutics, this GPU cluster will supercharge the entire process. I don't know about you, but I'm pretty excited to see what kind of breakthroughs this project will bring. Who knows, maybe we'll be living in a world where diseases are a thing of the past sooner than we think!So, let's dive into the latest AI updates from OpenAI, Microsoft, YouTube, Google, Cisco, and Anthropic. It seems like ChatGPT is back in the spotlight with an increase in usage, particularly because students are returning to school and concerns about AI cheating are on the rise. After experiencing a decline throughout the summer, ChatGPT has seen a 12% traffic increase since fall classes resumed in the US. However, it's important to note that current usage is still below the peak levels seen earlier this year. With students back in the classroom, concerns about AI-aided cheating have resurfaced. The easier access students have to AI technology raises fresh debates among schools about whether to ban, incorporate, or ignore such tools. For educators, managing responsible AI use in academics is becoming a complex balancing act. There's also some uncertainty surrounding potential revenue as ChatGPT's reliance on students could pose challenges for monetization. Moving on to other AI news, Microsoft has announced a new AI-powered feature called Microsoft Copilot. This feature, available in various Windows 11 applications, Microsoft 365, Edge, and Bing, allows users to rearrange windows, generate text, edit pictures, and more. It's like having Bing integrated into your Windows experience. YouTube is not far behind with its AI advancements. The platform has introduced three new AI-powered features specifically for Shorts creators. Dream Screen uses AI to generate background images and videos, Creator Music helps find the perfect track for Shorts, and AI Insights for Creators assists in brainstorming the next video idea. These features aim to enhance the content creation experience on YouTube. Meanwhile, Google has expanded its AI coding assistant, Studio Bot, to 170 countries. Initially launched for Android developers in the US, this assistant helps generate code, fix errors, and answer questions about Android development. It's a handy tool for developers worldwide. In the world of image creation, Microsoft's DALL-E 3 is making its way to Bing. Soon, users will be able to create images in a chat using DALL-E 3. This exciting feature will be rolled out for enterprise users in October, opening up new possibilities for visual communication. Now, let's switch gears to a significant acquisition. Cisco has announced its plan to acquire cybersecurity firm Splunk for $28 billion. This move aligns with Cisco's goal to expand its software and AI-powered data analysis capabilities. Splunk, which introduced AI features earlier this year to detect and respond to data anomalies, will play a vital role in Cisco's strategy. In the realm of responsible AI scaling, Anthropic, the company behind the Claude chatbot, has released a policy that emphasizes its commitment to responsible AI system development. The policy acknowledges the potential for AI systems to cause catastrophic risks, including thousands of deaths or immense financial damage. It's encouraging to see companies prioritizing responsible AI practices. In other tech news on September 22nd, 2023, Cisco is set to make its largest acquisition ever by acquiring Splunk for $28 billion. This move aims to boost security services and system performance troubleshooting. On a different note, NASA eagerly awaits the return of pristine asteroid Bennu samples, taken by OSIRIS-REx in 2020. The samples could unlock valuable insights into the origins of our solar system. In the legal world, lawyers who sued Tesla's board for excessive pay are seeking a jaw-dropping $10,000 an hour. The case is sure to attract attention as it unfolds. Another interesting development involves an anonymous developer who used OpenAI's ChatGPT API to program an AI that created and launched an ERC-20 token called AstroPepeX. Within just 24 hours, the token generated an astonishing $12.9 million in trading. It's a testament to the possibilities AI offers in the realm of finance and entrepreneurship. Lastly, Ilya Sutskever, one of OpenAI's renowned figures, along with machine ethicist Thomas Krendl Gilbert, have described AI development as "alchemy." This comparison underscores the unpredictable and mysterious nature of AI outcomes, sparking heated debate within the industry. And there you have it, the latest AI updates featuring ChatGPT, Microsoft, YouTube, Google, Cisco, and Anthropic. Stay tuned for more exciting advancements in the world of artificial intelligence.Hey there! If you're excited about diving deeper into the world of artificial intelligence, I've got just the thing for you! There's this amazing book called "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence." Trust me, it's a game-changer! Now, let me tell you why you should totally get your hands on this gem. "AI Unraveled" is packed with all the answers to those burning questions you may have about AI. Think of it as your ultimate AI guidebook. It's like having a knowledgeable expert right by your side, unravelling the mysteries of artificial intelligence in a way that's easy to comprehend. The best part? You can grab a copy of this must-read book at three different platforms: Apple, Google, or Amazon. So, no matter whether you're an Apple aficionado, a Google guru, or an Amazon enthusiast, there's a way for you to access this invaluable resource. So, why wait any longer? Dive into "AI Unraveled" today and expand your understanding of artificial intelligence like never before. This book is a game-changer, and it's ready to be enjoyed by curious minds like yours. Happy reading!In today's episode, we covered Microsoft's AI-powered Copilot, YouTube's new AI features for creators, evaluating large language models in industry, concerns with AI detection tools in universities, rankings of tech companies tackling misinformation, OpenAI's DALL·E 3 text-to-image model, generative AI updates from Amazon, Zuckerberg's philanthropy in AI-driven research, ChatGPT usage concerns, and other notable news - plus, don't forget to expand your AI knowledge with the essential book 'AI Unraveled'. Join us next time on AI Unraveled as we continue to demystify frequently asked questions on artificial intelligence and bring you the latest trends in AI, including ChatGPT advancements and the exciting collaboration between Google Brain and DeepMind. Stay informed, stay curious, and don't forget to subscribe for more!

# Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence," available at Apple, Google, or Amazon today today:

# AI Unraveled @ Amazon: [https://amzn.to/3ZrpkCu](https://amzn.to/3ZrpkCu)

# AI Unraveled @ Apple: [http://books.apple.com/us/book/id6445730691](http://books.apple.com/us/book/id6445730691)

# AI Unraveled @ Google: [https://play.google.com/store/books/details?id=oySuEAAAQBAJ](https://play.google.com/store/books/details?id=oySuEAAAQBAJ)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pp2h6/microsofts_copilot_puts_ai_into_everything/
-----
Title: Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT
Content: Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**AI Detection Tool Concerns**

* **False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.
* **High False Positive Rate**: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.

**ChatGPT's Rise & Challenges**

* **Popularity Among Students**: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.
* **Misidentification Issues**: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.

**OpenAI's Stance**

* **Difficulty in AI Text Detection**: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.
* **Bias Against Non-English Writers**: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

[Source (Business Insider)](https://www.businessinsider.com/universities-ditch-ai-detectors-over-fears-students-falsely-accused-cheating-2023-9?r=US&IR=T)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,700+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pahu7/some_universities_are_ditching_ai_detection/
-----
Title: Two-minute Daily AI Update (Date: 09/21/2023): News from OpenAI, Amazon, Google DeepMind, GitHub, Uber, and NVIDIA
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **OpenAI unveils DALL·E 3**  
\- It understands significantly more nuance and detail than its previous systems. DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall. It is built natively on ChatGPT, which lets you use ChatGPT as a brainstorming partner and refiner of your prompts.
* **Amazon brings generative AI to Alexa and Fire TV**  
\- At its annual devices event, Amazon introduced generative AI updates for its Fire TV voice search to bring more conversational ways to interact with Alexa and discover new content.  
\- It will also use a new generative AI model to power improved experiences across its Echo family of devices.
* **Google DeepMind’s ‘Language Modeling Is Compression’**  
\- This paper views the prediction problem through the lens of compression and evaluates the compression capabilities of large (foundation) models. It shows that LLMs are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning.
* **GitHub’s Copilot Chat will now be available to individual users**  
\- It is available in public beta for GitHub Copilot individual users in Visual Studio and Visual Studio Code.
* **Uber Eats to roll out AI-powered assistant**  
\- It will help users find deals and explore different food options seamlessly.
* **NVIDIA to train 50,000 Infosys employees on AI technology**  
\- Infosys will set up NVIDIA Centre of Excellence to train and certify employees on NVIDIA’s AI technologies. Also, NVIDIA’s AI Enterprise ecosystem of models, tools, runtimes, and GPU systems will be brought to Infosys’s AI-first offering Topaz.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/openai-unveils-dalle3-amazon-ai-updates-deepmind).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16oi0cn/twominute_daily_ai_update_date_09212023_news_from/
-----
News posts saved as '2023-09-28-reddit_news_posts.md'
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pi4tp/indeeds_ceo_says_college_students_might_be/
-----
Title: Microsoft seeks nuclear reactors to power AI
Content: -Microsoft made a job posting looking for a nuclear tech expert who could help integrate small modular nuclear reactors “to power the datacenters that the Microsoft Cloud and AI reside on,"'  
-Bill Gates is chairman of the board TerraPower, a company working in the field of small modular reactors  
-Microsoft has previously publicly committed to pursuing nuclear energy

Source:
https://www.cnbc.com/2023/09/25/microsoft-is-hiring-a-nuclear-energy-expert-to-help-power-data-centers.html
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16s9aes/microsoft_seeks_nuclear_reactors_to_power_ai/
-----
Title: Microsoft’s Copilot puts AI into everything, YouTube announces 3 new AI features for creators, 4 Crucial Factors for Evaluating LLMs in Industry Applications, AI Detection Tool Concerns, Amazon brings Generative AI to Alexa and Fire TV, DALL·E 3
Content: [https://youtu.be/qe5tBvkvrf8](https://youtu.be/qe5tBvkvrf8)

# Summary:

# Microsoft’s Copilot puts AI into everything

Microsoft has announced a new AI-powered feature, Microsoft Copilot. It’ll bring AI features into various Windows 11, Microsoft 365, Edge, and Bing. Our first impressions are that it’s Bing but for Windows. You can use Copilot to rearrange windows, generate text, open apps on the web, edit pictures and more.Copilot can be accessed via an app or with a simple right-click and will be rolled out across Bing, Edge, and Microsoft 365 this fall, with the free Windows 11 update starting on September 26th.Why does this matter?While we don’t see any revolutionary use cases of Copilot as of now, it’s still a huge step towards the democratization of AI. As more users get their hands on this AI copilot, we’ll know the true extent of its effectiveness. If all goes well, Microsoft will end up grabbing an even bigger share of the AI market as it will deliver AI natively to all Windows devices.

# YouTube announces 3 new AI features for creators

In a YouTube event, the company announced 3 AI-powered features for YouTube Shorts creators.

**Dream Screen**: It allows users to create image or video backgrounds using AI. All you need to do is type what you want to see in the background and AI will create it for you.

**Creator Music**: This was a previously available feature but got an AI revamp this time around. Creators can simply type in the kind and length of the music they need and AI will find the most relevant suggestions for their needs.

**AI Insights for Creators:** This is an inspiration tool which generates video ideas based on AI’s analysis of what the audiences are already watching and prefer.Why does this matter?It seems like a strategic decision to natively introduce AI features to support users. It’s a trend we are seeing increasingly more across the landscape. For the users, it's great news since they get free AI assistance in their creative endeavors.

# Google’s innovative approach to train smaller language models

Large language models (LLMs) have enabled new capabilities in few-shot learning, but their massive size makes deployment challenging. To address this, the authors propose a new method called distilling step-by-step, which trains smaller task-specific models using less data while surpassing LLM performance.First, the key idea is to extract rationales - intermediate reasoning steps - from an LLM using few-shot chain-of-thought prompting. These rationales are then used alongside labels to train smaller models in a multi-task framework, with tasks for label prediction and rationale generation. Experiments across NLI, QA, and math datasets show this approach reduces training data needs by 75-80% compared to standard fine-tuning.Why does this matter?This new approach to train smaller models with higher accuracy has the potential to support language models that can be deployed on local devices while retaining the performance that was previously achievable only through LLMs.

# 4 Crucial Factors for Evaluating Large Language Models in Industry Applications

Based on your end goal, you might fancy one LLM over the other. For instance, some industries value privacy over anything while others might put data accuracy over everything else. In this article, Skanda Vivek shares the 4 critical factors you should always consider when picking a large language model.He mentions Quality, Economic, Latency, and Privacy to be the 4 resting pillars of your decision. He then goes into details discussing each of these parameters and how you should evaluate a given model against them.Why does this matter?The ability to make the right decision when choosing the underlying LLM for your applications is massively important. This article will provide you with valuable insights when it comes to choosing the right LLM.

# Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT

Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.AI Detection Tool Concerns

**False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.High False Positive Rate: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.ChatGPT's Rise & ChallengesPopularity Among Students: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.Misidentification Issues: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.OpenAI's StanceDifficulty in AI Text Detection: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.Bias Against Non-English Writers: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

# X ranks lowest in tackling climate misinformation, study reveals

X, formerly known as Twitter, has ranked last in a new assessment by Climate Action Against Disinformation for its management of climate misinformation.Pinterest scored the highest in terms of addressing climate change misinformation, while other platforms like YouTube, Meta, and Instagram also ranked higher than X.Changes under Elon Musk's ownership, including unclear policies on climate misinformation and a less communicative content moderation team, have contributed to X's low ranking.Google sued after Maps allegedly directed a man to drive off a collapsed bridgePhilip Paxson, a father of two, died after Google Maps directed him to a collapsed bridge, leading to a fatal car plunge, according to a lawsuit filed by his family.The family claims Google was informed of the bridge's collapse but failed to update its navigation system, making the tech company negligent in Paxson's death.Despite having received reports about the bridge's state through its 'suggest and edit' feature, Google allegedly took no further actions to correct the route information.Study finds 95% of NFTs are now worthlessAccording to a study by dappGambl, 95% of NFTs are now practically worthless, with the majority of the 73,257 NFT collections analyzed having a market cap of zero Ether.Enthusiasm for NFTs has substantially dropped and prices have plunged, with even hyped-up collections becoming virtually valueless.The future of NFTs is uncertain; they will need to prove they have inherent value, such as cultural relevance or representing actual art, to survive.

&#x200B;

# Google expands AI coding assistant to 170 countries

\- Google launched Studio Bot in 170 countries. It was previously launched in May for Android developers in the US. The assistant helps devs generate code, fix errors and answer questions about Android.

&#x200B;

# OpenAI unveils DALL·E 3

DALL·E 3 is built natively on ChatGPT, which lets you use ChatGPT to generate tailored, detailed prompts for DALL·E 3. If it’s not quite right, you can ask ChatGPT to make tweaks.

Even with the same prompt, DALL·E 3 delivers significant improvements over DALL·E 2, as shown below (Left: DALL·E 2 results, Right: DALL·E 3). The prompt: “An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.”

OpenAI has taken steps to limit DALL·E 3’s ability to generate violent, adult, or hateful content.DALL·E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can also opt their images out from training of OpenAI’s future image generation models.

DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall.Why does this matter?As OpenAI notes, modern text-to-image systems have a tendency to ignore words or descriptions, forcing users to learn prompt engineering. DALL·E 3 represents a leap forward in AI’s ability to generate images that exactly adhere to the text you provide. Will other image generators like Midjourney and Stable Diffusion keep up?

&#x200B;

# DALL-E 3 will be available in Bing chat

\- Microsoft’s recently announced DALL-E 3 will be available in Bing as Microsoft announced users will be able to create images in a chat. DALL-E 3 will be rolled out for enterprise users in October.

&#x200B;

# ChatGPT can now generate images

Our new text-to-image model, DALL·E 3, can translate nuanced requests into extremely detailed and accurate images.Coming soon to ChatGPT Plus & Enterprise, which can help you craft amazing prompts to bring your ideas to life:[https://openai.com/dall-e-3](https://openai.com/dall-e-3)

&#x200B;

# Cisco to buy Splunk in $28 billion

In its bid to expand software and AI powered data analysis, Cisco announced it will buy cybersecurity firm, Splunk, in $28 billion. Splunk has announced AI features that detect and respond to data anomalies, earlier this year.

# Anthropic releases policy on ‘catastrophic risks’

\- Anthropic, the company behind Claude chatbot, shared a policy highlighting its commitment to responsible scaling of AI systems. The policy acknowledges AI’s potential to cause “thousands of deaths or hundreds of billions of dollars in damage.”

&#x200B;

# Amazon brings Generative AI to Alexa and Fire TV

At its annual devices event, Amazon announced a few AI updates:It will soon use a new generative AI model to power improved experiences across its Echo family of devices. The new model is specifically optimized for voice and will take into account body language as well as a person’s eye contact and gestures for more powerful conversational experiences.It also introduced generative AI updates for its Fire TV voice search, which promises to bring more conversational ways to interact with Alexa and discover new content based on specifics.Why does this matter?Integrating LLMs with voice assistants is a perfect use case. But Amazon's generative AI revamp for Alexa marks a game-changer. It promises voice assistants that understand context better, carry over information from previous conversations, and become more personalized for users.

# Amazon is turning Alexa into a hands-free ChatGPT

Amazon is upgrading Alexa, its voice assistant, with the technology behind chatbots for more complex and open-ended conversation capabilities.The new feature, which is still in progress, will show more simulated personality, interpret body language with devices equipped with cameras and modulate its voice for a more natural conversation.While this advancement holds promise, challenges like responding to body language and the fact that these large language models can sometimes blur out inappropriate or nonsensical things, remains to refine.ChatGPT Usage is Rising Again as Students Return to School

# Zuckerberg's philanthropy project is building a massive GPU cluster to ‘cure all diseases

The Chan Zuckerberg Initiative (CZI), founded by Mark Zuckerberg and his wife Priscilla Chan, plans to build one of the world's largest GPU clusters for AI-driven biomedical research.The CZI aims to use large language models to understand disease development at cellular levels and predict cell behaviors, necessitating over 1,000 Nvidia's H100 GPUs for computational requirements.The high-performance computing system, expected to be operational in 2024, will accelerate biomedical research, from mapping varied cell types in different organisms to designing potential drugs and therapeutics.

# After declining over the summer, ChatGPT usage has increased, most likely as a result of students returning to class and concerns about AI cheating.

12% Traffic Increase Last Week: ChatGPT saw a sizable jump in US web traffic as fall classes resumed.Big Drop Over Summer Break: Traffic declined steadily from May through August when school was out.Still Below Early 2022 Peaks: But current usage remains below ChatGPT's peak levels earlier this year. Back to School Brings Old ProblemsCheating Fears Resurface: Easier student access with school back raises fresh concerns about AI-aided cheating.Schools Still Debating Rules: Many institutions continue deciding whether to ban, incorporate or ignore the technology.Potential Revenue Uncertainty: Reliance on students could be problematic for monetizing ChatGPT.With the new school year boosting ChatGPT traffic, managing responsible AI use in academics remains a complex balancing act for educators.

&#x200B;

# Intel’s ‘AI PC’ can run generative AI chatbots directly on laptops

Intel’s new chip, due in December, will be able to run a generative AI chatbot on a laptop rather than having to tap into cloud data centers for computing power. It is made possible by new AI data-crunching features built into Intel's forthcoming "Meteor Lake" laptop chip and from new software tools the company is releasing.Intel also demonstrated laptops that could generate a song in the style of Taylor Swift and answer questions in a conversational style, all while disconnected from the Internet. Moreover, Microsoft's Copilot AI assistant will be able to run on Intel-based PCs.Why does this matter?This will let businesses test ChatGPT-style AI models without sending sensitive data off their own computers. Intel seems to be on track to become the lead chip manufacturer again, competing with Nvidia to make powerful chips that train AI systems such as ChatGPT and Stability AI’s models.

&#x200B;

# DeepMind’s new AI can predict genetic diseases

Google DeepMind’s new system, called AlphaMissense, can tell if the letters in the DNA will produce the correct shape. If not, it is listed as potentially disease-causing.AlphaMissense can predict the likelihood of genetic diseases by analyzing genetic mutations called missense variants.AlphaMissense operates like a large language model, trained on human and primate biology, capable of identifying normal sequences of proteins and detecting changes that could suggest a disease.With 90% accuracy, AlphaMissense is more reliable than existing tools, potentially accelerating the process of identifying disease-causing genetic mutations, which previously required months of meticulous research.

Currently, genetic disease hunters have fairly limited knowledge of which areas of human DNA can lead to disease and have to search across billions of chemical building blocks that make up DNA. They have classified 0.1% of letter changes, or mutations, as either benign or disease-causing. DeepMind's new model pushed that percentage up to 89%.Why does this matter?AI is changing nearly everything we do at the moment and might revolutionize molecular biology and life sciences, too. This development is expected to speed up diagnosis and help search for better genetic disease treatments.

&#x200B;

# Google is turning its Bard AI chatbot into a personal assistant

  
Google's Bard AI now has enhanced capabilities, pulling real-time data from Google's other applications and a user's data silo to deliver more relevant chatbot responses.  
A new feature named Bard Extensions allows the AI to access user's personal Google data to provide specific answers about their daily activities, while promising not to be used for ad targeting or training the AI model.  
To increase transparency and accuracy, Google is introducing a 'Double Check' feature where Bard audits its responses and highlights contradictory or heavily referenced statements.

&#x200B;

# DeepMind’s New AI Can Predict Genetic Diseases

AlphaMissense, a new model from Google’s artificial intelligence team, analyzes the effects of DNA mutations and will accelerate research into rare diseases.  
About 10 years ago, Žiga Avsec was a PhD physics student who found himself taking a crash course in genomics via a university module on machine learning. He was soon working in a lab that studied rare diseases, on a project aiming to pin down the exact genetic mutation that caused an unusual mitochondrial disease.  
This was, Avsec says, a “needle in a haystack” problem. There were millions of potential culprits lurking in the genetic code—DNA mutations that could wreak havoc on a person’s biology. Of particular interest were so-called missense variants: single-letter changes to genetic code that result in a different amino acid being made within a protein. Amino acids are the building blocks of proteins, and proteins are the building blocks of everything else in the body, so even small changes can have large and far-reaching effects.

&#x200B;

# Podcast Detailed Transcript:

Microsoft recently announced a game-changing feature called Microsoft Copilot. This exciting new addition will infuse AI capabilities into various Windows 11, Microsoft 365, Edge, and Bing applications. Think of it as Bing, but specifically designed for Windows devices. So, what can Copilot do? Quite a lot, actually. With this tool, you can rearrange windows effortlessly, generate text, open web apps, edit pictures, and much more. It's accessible both via an app and through a simple right-click, making it convenient for users to tap into its AI-powered goodness. But when can we start using Copilot? Well, the good news is that it's just around the corner. Microsoft plans to roll out Copilot this fall, making it available across Bing, Edge, and Microsoft 365. And for Windows users, you'll get to enjoy this feature sooner than you think. The free Windows 11 update will begin on September 26th. Now, you might be wondering, why is this such a big deal? The answer lies in the democratization of AI. While we don't have any mind-blowing use cases for Copilot just yet, this step forward by Microsoft is significant. As more users get their hands on this AI copilot, we'll start to see its true capabilities. And if all goes well, Microsoft could dominate an even larger share of the AI market by delivering AI natively.YouTube just announced some exciting news for creators! They're rolling out three new AI-powered features for YouTube Shorts creators. Let me break it down for you. First up, we have Dream Screen. This feature lets you create image or video backgrounds using AI. All you have to do is type in what you want to see in the background, and AI will make it happen. How cool is that? Next, we've got Creator Music. This feature got an AI revamp, making it even better than before. Now, creators can simply type in the kind and length of the music they need, and AI will find the most relevant suggestions. It's like having your own personal music assistant. Last but not least, we have AI Insights for Creators. This is a tool that generates video ideas for creators based on AI's analysis of what audiences are already watching and preferring. So, if you're looking for some inspiration, AI has got your back. This move by YouTube seems like a smart strategic decision to integrate AI features directly into the platform.

When it comes to evaluating large language models (LLMs) for industry applications, there are four crucial factors to consider. Skanda Vivek highlights these factors, which include quality, economic aspects, latency, and privacy. Each of these factors plays a significant role in determining the suitability of a particular LLM. The quality of the LLM is of utmost importance. Depending on your end goal, you may prioritize different aspects of quality, such as data accuracy, contextual understanding, or fluency. Consider what matters most to your industry and choose an LLM that aligns with those preferences. Economic factors also come into play. It's essential to assess the cost-effectiveness of implementing a particular LLM. Does it provide value for money? Can it fit within your organization's budget? Analyzing the economic aspects ensures you make an informed decision. Latency, or the response time of the LLM, is another vital factor. Some applications require real-time or near-instantaneous responses. Evaluating an LLM's latency helps you select the model that meets your specific timing requirements. Finally, privacy is increasingly significant for many industries. Skanda Vivek emphasizes the need to consider privacy when choosing an LLM. Depending on your industry, data security and privacy regulations may be a top priority. Ensuring the chosen model aligns with your privacy needs is crucial. Choosing the right LLM is a critical decision that can significantly impact your applications. By carefully considering these four factors—quality, economic aspects, latency, and privacy—you can make an informed choice that aligns with your industry's requirements. In recent news, some universities are raising concerns about AI detection software used to catch cheating students. There are worries that students could be falsely accused of cheating when using tools like ChatGPT. As a result, some universities are opting to abandon these AI detection systems. The debate highlights the potential drawbacks and risks associated with relying entirely on AI tools for academic integrity.So, here's the thing. Some major universities have decided to ditch AI detection tools because they're worried about their accuracy. And let's face it, nobody wants to be falsely accused of cheating, right? One tool in particular, called ChatGPT, has caused quite a stir. The problem with ChatGPT is that it's gained popularity among students, and that's got educators really concerned about academic dishonesty. But it's not just about students using AI to write their essays. It's also about the tool itself misidentifying things and getting it all wrong. For example, one professor in Texas failed half of his class because of false detections by ChatGPT. Can you imagine? Talk about a nightmare scenario. And it's not just him. Other students have also been wrongly accused by anti-plagiarism software using ChatGPT. What's interesting is that even OpenAI, the company behind ChatGPT, has abandoned their own AI text detector due to its low accuracy rate. They've even warned educators about relying too heavily on AI content detectors. And here's another thing to consider: these detection tools often get it wrong when it comes to content written by non-English writers. So, yeah, there are some serious concerns here. That's why some universities, like Vanderbilt and Northwestern, have decided to say "no thanks" to these AI detection tools. It's better to be safe than sorry, right? After all, nobody wants to unfairly accuse a student of cheating.Hey there! Some interesting news for you today. According to Climate Action Against Disinformation, X, which we all know as Twitter, has ranked last when it comes to tackling climate misinformation. Quite the bummer, right? It turns out that Pinterest is leading the pack in addressing climate change misinformation, with YouTube, Meta (formerly known as Facebook), and Instagram not too far behind. But poor old X is lagging behind. So, what led to this low ranking for X? Well, it seems that since Elon Musk took over, things have changed, and not for the better. There are unclear policies on climate misinformation and a less communicative content moderation team, both of which have contributed to X's downward slide in the rankings. Maybe they need to step up their game a bit. In another news story, Google is facing a lawsuit after it allegedly directed a man, Philip Paxson, to drive off a collapsed bridge via Google Maps. Sadly, Paxson lost his life in the tragic accident. According to his family, Google was aware of the bridge's collapse but failed to update its navigation system, which they argue makes the tech giant negligent in Paxson's death. Google apparently received reports about the bridge's condition, but did nothing to fix the route information. It's a heartbreaking situation. And finally, brace yourself for this one. A study by dappGambl has found that a whopping 95% of NFTs are now practically worthless. Yep, you heard that right. NFTs, which were once all the rage, have lost their shine. Prices have plummeted, and most of the 73,257 NFT collections analyzed have a market cap of zero Ether. It's uncertain what the future holds for NFTs, but they'll need to prove their worth, whether through cultural significance or as a representation of actual art, if they want to stick around. So, that's the latest in tech and climate news. Stay tuned for more updates!OpenAI has just unveiled their latest model for text-to-image translation called DALL·E 3, and it's pretty impressive! This new version is built directly on ChatGPT, which means you can use ChatGPT to generate customized and detailed prompts for DALL·E 3. And if the results aren't exactly what you were hoping for, you can even ask ChatGPT to make some tweaks. Compared to its predecessor, DALL·E 2, DALL·E 3 delivers significant improvements in creating detailed images. OpenAI showcased this by providing a prompt for an expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula. The results from DALL·E 3 were far superior to those from DALL·E 2. OpenAI has also taken steps to ensure that DALL·E 3 doesn't generate violent, adult, or hateful content. They have designed it to decline requests for images in the style of living artists. Additionally, creators have the option to exclude their images from being used in the training of OpenAI's future image generation models, giving them more control over the use of their work. Currently, DALL·E 3 is in research preview and will be available to ChatGPT Plus and Enterprise customers in October through the API. It will later be made available in Labs for those interested. This new release is important because it addresses the limitations of previous text-to-image systems, which often ignored certain words or descriptions. With DALL·E 3, AI's ability to generate images that align precisely with the provided text takes a huge leap forward. It raises questions about how other image generators like Midjourney and Stable Diffusion will keep up. OpenAI has also prioritized safety improvements in DALL·E 3. They have implemented measures to prevent explicit content and have tools in place to identify risky words and block public figures. Furthermore, artists can now request that their work be blocked from AI copying, and DALL·E 3 won't mimic the styles of specific artists when named. OpenAI hopes that the integration with ChatGPT and the safety guards in DALL·E 3 will expand access to this technology while preventing misuse. However, there are still concerns and legal issues surrounding AI-generated art that need to be addressed.Amazon had some exciting announcements at its recent devices event. One of the standout updates is the integration of generative AI into their Echo family of devices. This new AI model is optimized for voice, taking into account not only what is said but also body language, eye contact, and gestures. This means that interactions with Alexa will become much more powerful and conversational, providing users with improved experiences. But that's not all. Amazon has also introduced generative AI updates for Fire TV's voice search. This update aims to enhance the conversational interaction between users and Alexa, allowing for a more natural and intuitive way to discover new content based on specific preferences. This development is significant because it showcases how integrating language models like Generative AI into voice assistants can revolutionize the way we interact with them. Amazon's revamp of Alexa using generative AI is a game-changer. It enables voice assistants to better understand context, seamlessly carry over information from previous conversations, and provide a more personalized experience for users. In fact, Amazon is transforming Alexa into a hands-free ChatGPT by leveraging the technology behind chatbots. This upgrade will give Alexa the ability to engage in more complex and open-ended conversations. It will also enhance its simulated personality, interpret body language (for devices with cameras), and modulate its voice for a more natural conversation. However, there are some challenges to overcome, such as responding accurately to body language and refining these large language models to prevent inappropriate or nonsensical responses. But with Amazon's dedication to improving AI experiences, we can expect significant advancements in these areas. Overall, Amazon's integration of generative AI into Alexa and Fire TV demonstrates their commitment to providing users with more intuitive, personalized, and conversational experiences.Hey there! Have you heard about Mark Zuckerberg's latest philanthropy project? It's got a pretty ambitious goal - to "cure all diseases". The project, called the Chan Zuckerberg Initiative (CZI), is a collaborative effort between Zuckerberg and his wife, Priscilla Chan. So here's the plan: CZI is planning to build one of the biggest GPU clusters in the world specifically for AI-driven biomedical research. They want to use large language models to dive deep into disease development at the cellular level and even predict how cells behave. And to do that, they're going to need some serious computational power - over 1,000 Nvidia's H100 GPUs! This high-performance computing system is expected to be up and running by 2024. And let me tell you, it's going to revolutionize biomedical research. From mapping out various cell types across different organisms to designing potential drugs and therapeutics, this GPU cluster will supercharge the entire process. I don't know about you, but I'm pretty excited to see what kind of breakthroughs this project will bring. Who knows, maybe we'll be living in a world where diseases are a thing of the past sooner than we think!So, let's dive into the latest AI updates from OpenAI, Microsoft, YouTube, Google, Cisco, and Anthropic. It seems like ChatGPT is back in the spotlight with an increase in usage, particularly because students are returning to school and concerns about AI cheating are on the rise. After experiencing a decline throughout the summer, ChatGPT has seen a 12% traffic increase since fall classes resumed in the US. However, it's important to note that current usage is still below the peak levels seen earlier this year. With students back in the classroom, concerns about AI-aided cheating have resurfaced. The easier access students have to AI technology raises fresh debates among schools about whether to ban, incorporate, or ignore such tools. For educators, managing responsible AI use in academics is becoming a complex balancing act. There's also some uncertainty surrounding potential revenue as ChatGPT's reliance on students could pose challenges for monetization. Moving on to other AI news, Microsoft has announced a new AI-powered feature called Microsoft Copilot. This feature, available in various Windows 11 applications, Microsoft 365, Edge, and Bing, allows users to rearrange windows, generate text, edit pictures, and more. It's like having Bing integrated into your Windows experience. YouTube is not far behind with its AI advancements. The platform has introduced three new AI-powered features specifically for Shorts creators. Dream Screen uses AI to generate background images and videos, Creator Music helps find the perfect track for Shorts, and AI Insights for Creators assists in brainstorming the next video idea. These features aim to enhance the content creation experience on YouTube. Meanwhile, Google has expanded its AI coding assistant, Studio Bot, to 170 countries. Initially launched for Android developers in the US, this assistant helps generate code, fix errors, and answer questions about Android development. It's a handy tool for developers worldwide. In the world of image creation, Microsoft's DALL-E 3 is making its way to Bing. Soon, users will be able to create images in a chat using DALL-E 3. This exciting feature will be rolled out for enterprise users in October, opening up new possibilities for visual communication. Now, let's switch gears to a significant acquisition. Cisco has announced its plan to acquire cybersecurity firm Splunk for $28 billion. This move aligns with Cisco's goal to expand its software and AI-powered data analysis capabilities. Splunk, which introduced AI features earlier this year to detect and respond to data anomalies, will play a vital role in Cisco's strategy. In the realm of responsible AI scaling, Anthropic, the company behind the Claude chatbot, has released a policy that emphasizes its commitment to responsible AI system development. The policy acknowledges the potential for AI systems to cause catastrophic risks, including thousands of deaths or immense financial damage. It's encouraging to see companies prioritizing responsible AI practices. In other tech news on September 22nd, 2023, Cisco is set to make its largest acquisition ever by acquiring Splunk for $28 billion. This move aims to boost security services and system performance troubleshooting. On a different note, NASA eagerly awaits the return of pristine asteroid Bennu samples, taken by OSIRIS-REx in 2020. The samples could unlock valuable insights into the origins of our solar system. In the legal world, lawyers who sued Tesla's board for excessive pay are seeking a jaw-dropping $10,000 an hour. The case is sure to attract attention as it unfolds. Another interesting development involves an anonymous developer who used OpenAI's ChatGPT API to program an AI that created and launched an ERC-20 token called AstroPepeX. Within just 24 hours, the token generated an astonishing $12.9 million in trading. It's a testament to the possibilities AI offers in the realm of finance and entrepreneurship. Lastly, Ilya Sutskever, one of OpenAI's renowned figures, along with machine ethicist Thomas Krendl Gilbert, have described AI development as "alchemy." This comparison underscores the unpredictable and mysterious nature of AI outcomes, sparking heated debate within the industry. And there you have it, the latest AI updates featuring ChatGPT, Microsoft, YouTube, Google, Cisco, and Anthropic. Stay tuned for more exciting advancements in the world of artificial intelligence.Hey there! If you're excited about diving deeper into the world of artificial intelligence, I've got just the thing for you! There's this amazing book called "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence." Trust me, it's a game-changer! Now, let me tell you why you should totally get your hands on this gem. "AI Unraveled" is packed with all the answers to those burning questions you may have about AI. Think of it as your ultimate AI guidebook. It's like having a knowledgeable expert right by your side, unravelling the mysteries of artificial intelligence in a way that's easy to comprehend. The best part? You can grab a copy of this must-read book at three different platforms: Apple, Google, or Amazon. So, no matter whether you're an Apple aficionado, a Google guru, or an Amazon enthusiast, there's a way for you to access this invaluable resource. So, why wait any longer? Dive into "AI Unraveled" today and expand your understanding of artificial intelligence like never before. This book is a game-changer, and it's ready to be enjoyed by curious minds like yours. Happy reading!In today's episode, we covered Microsoft's AI-powered Copilot, YouTube's new AI features for creators, evaluating large language models in industry, concerns with AI detection tools in universities, rankings of tech companies tackling misinformation, OpenAI's DALL·E 3 text-to-image model, generative AI updates from Amazon, Zuckerberg's philanthropy in AI-driven research, ChatGPT usage concerns, and other notable news - plus, don't forget to expand your AI knowledge with the essential book 'AI Unraveled'. Join us next time on AI Unraveled as we continue to demystify frequently asked questions on artificial intelligence and bring you the latest trends in AI, including ChatGPT advancements and the exciting collaboration between Google Brain and DeepMind. Stay informed, stay curious, and don't forget to subscribe for more!

# Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence," available at Apple, Google, or Amazon today today:

# AI Unraveled @ Amazon: [https://amzn.to/3ZrpkCu](https://amzn.to/3ZrpkCu)

# AI Unraveled @ Apple: [http://books.apple.com/us/book/id6445730691](http://books.apple.com/us/book/id6445730691)

# AI Unraveled @ Google: [https://play.google.com/store/books/details?id=oySuEAAAQBAJ](https://play.google.com/store/books/details?id=oySuEAAAQBAJ)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pp2h6/microsofts_copilot_puts_ai_into_everything/
-----
Title: Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT
Content: Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**AI Detection Tool Concerns**

* **False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.
* **High False Positive Rate**: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.

**ChatGPT's Rise & Challenges**

* **Popularity Among Students**: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.
* **Misidentification Issues**: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.

**OpenAI's Stance**

* **Difficulty in AI Text Detection**: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.
* **Bias Against Non-English Writers**: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

[Source (Business Insider)](https://www.businessinsider.com/universities-ditch-ai-detectors-over-fears-students-falsely-accused-cheating-2023-9?r=US&IR=T)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,700+** **professionals** from **OpenAI, Google, Meta**…
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pahu7/some_universities_are_ditching_ai_detection/
-----
Title: Two-minute Daily AI Update (Date: 09/25/2023): News from Amazon, Anthropic, Meta’s, Microsoft, Google, ElevenLabs, and Salesforce
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **Amazon to invest up to $4 billion in Anthropic, expanding access to safer AI**  
\- It is part of a broader collaboration to develop the most reliable and high-performing foundation models. Anthropic’s frontier safety research and products, together with AWS’s expertise in running secure, reliable infrastructure, will make Anthropic’s safe and steerable AI widely accessible to AWS customers.  

* **Meta’s AI chatbot plan includes a ‘sassy robot’ for younger users**  
\- Meta has plans to develop dozens of chatbot personas geared towards engaging young users with more colorful behavior. It also includes ones for celebrities to interact with their fans and some more geared towards productivity, such as to help with coding and other tasks.
* **LongLoRA: Efficient fine-tuning of long-context LLMs**  
\- New research has introduced LongLoRA, an efficient fine-tuning method designed to extend the context sizes of pre-trained LLMs without a huge computation cost. In practical terms, LongLoRA performed strongly on various tasks using LLaMA-2 models ranging from 7B/13B to 70B. Notably, it extended LLaMA-2 7B from 4k context to 100k and LLaMA-2 70B to 32k on a single 8x A100 machine, all while keeping the original model architectures intact.
* **Microsoft’s mobile keyboard app SwiftKey gains new AI-powered features**  
\- It will now include AI camera lenses, AI stickers, an AI-powered editor, and the ability to create AI images from the app.
* **Google Pixel 8’s latest leak shows off big AI camera updates**  
\- AI photo editing with Magic Editor will enable you to remake any picture you take. DSLR-style manual camera controls will let you tweak the shutter speed and ISO of an image and a focus slider.
* **A drinks company in Poland appoints AI robot as 'experimental’ CEO**  
\- Dictador, best known for its rums, has appointed the robot to oversee the company’s growth into one-off collectables, communication, or even strategy planning. It is named Mika.
* **ElevenLabs launches free book classics narrated by high-quality AI voices**  
\- It presents six classic stories told by compelling AI voices in multiple languages, including "Winnie the Pooh" and "The Picture of Dorian Gray." The entire recording process took only one day.
* **Salesforce to acquire Airkit.ai, a low-code platform for building AI customer service agents**  
\- The GPT-4-based platform allows e-commerce companies to build specialized customer service chatbots that can deal with queries around order status, refunds, product information, and more.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/amazon-to-invest-4b-dollars-in-anthropic).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16rrw19/twominute_daily_ai_update_date_09252023_news_from/
-----
News posts saved as '2023-09-29-reddit_news_posts.md'
Title: Microsoft seeks nuclear reactors to power AI
Content: -Microsoft made a job posting looking for a nuclear tech expert who could help integrate small modular nuclear reactors “to power the datacenters that the Microsoft Cloud and AI reside on,"'  
-Bill Gates is chairman of the board TerraPower, a company working in the field of small modular reactors  
-Microsoft has previously publicly committed to pursuing nuclear energy

Source:
https://www.cnbc.com/2023/09/25/microsoft-is-hiring-a-nuclear-energy-expert-to-help-power-data-centers.html
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16s9aes/microsoft_seeks_nuclear_reactors_to_power_ai/
-----
Title: Microsoft’s Copilot puts AI into everything, YouTube announces 3 new AI features for creators, 4 Crucial Factors for Evaluating LLMs in Industry Applications, AI Detection Tool Concerns, Amazon brings Generative AI to Alexa and Fire TV, DALL·E 3
Content: [https://youtu.be/qe5tBvkvrf8](https://youtu.be/qe5tBvkvrf8)

# Summary:

# Microsoft’s Copilot puts AI into everything

Microsoft has announced a new AI-powered feature, Microsoft Copilot. It’ll bring AI features into various Windows 11, Microsoft 365, Edge, and Bing. Our first impressions are that it’s Bing but for Windows. You can use Copilot to rearrange windows, generate text, open apps on the web, edit pictures and more.Copilot can be accessed via an app or with a simple right-click and will be rolled out across Bing, Edge, and Microsoft 365 this fall, with the free Windows 11 update starting on September 26th.Why does this matter?While we don’t see any revolutionary use cases of Copilot as of now, it’s still a huge step towards the democratization of AI. As more users get their hands on this AI copilot, we’ll know the true extent of its effectiveness. If all goes well, Microsoft will end up grabbing an even bigger share of the AI market as it will deliver AI natively to all Windows devices.

# YouTube announces 3 new AI features for creators

In a YouTube event, the company announced 3 AI-powered features for YouTube Shorts creators.

**Dream Screen**: It allows users to create image or video backgrounds using AI. All you need to do is type what you want to see in the background and AI will create it for you.

**Creator Music**: This was a previously available feature but got an AI revamp this time around. Creators can simply type in the kind and length of the music they need and AI will find the most relevant suggestions for their needs.

**AI Insights for Creators:** This is an inspiration tool which generates video ideas based on AI’s analysis of what the audiences are already watching and prefer.Why does this matter?It seems like a strategic decision to natively introduce AI features to support users. It’s a trend we are seeing increasingly more across the landscape. For the users, it's great news since they get free AI assistance in their creative endeavors.

# Google’s innovative approach to train smaller language models

Large language models (LLMs) have enabled new capabilities in few-shot learning, but their massive size makes deployment challenging. To address this, the authors propose a new method called distilling step-by-step, which trains smaller task-specific models using less data while surpassing LLM performance.First, the key idea is to extract rationales - intermediate reasoning steps - from an LLM using few-shot chain-of-thought prompting. These rationales are then used alongside labels to train smaller models in a multi-task framework, with tasks for label prediction and rationale generation. Experiments across NLI, QA, and math datasets show this approach reduces training data needs by 75-80% compared to standard fine-tuning.Why does this matter?This new approach to train smaller models with higher accuracy has the potential to support language models that can be deployed on local devices while retaining the performance that was previously achievable only through LLMs.

# 4 Crucial Factors for Evaluating Large Language Models in Industry Applications

Based on your end goal, you might fancy one LLM over the other. For instance, some industries value privacy over anything while others might put data accuracy over everything else. In this article, Skanda Vivek shares the 4 critical factors you should always consider when picking a large language model.He mentions Quality, Economic, Latency, and Privacy to be the 4 resting pillars of your decision. He then goes into details discussing each of these parameters and how you should evaluate a given model against them.Why does this matter?The ability to make the right decision when choosing the underlying LLM for your applications is massively important. This article will provide you with valuable insights when it comes to choosing the right LLM.

# Some universities are ditching AI detection software amid fears students could be falsely accused of cheating by using ChatGPT

Major universities have discontinued the use of AI detection tools due to concerns about their accuracy, potentially falsely accusing students of cheating with the aid of AI tools like ChatGPT.AI Detection Tool Concerns

**False Accusations of Cheating**: Many universities, including Vanderbilt and Northwestern, have stopped using Turnitin's AI detection tools over worries they might wrongly accuse students of using AI to write essays.High False Positive Rate: Vanderbilt University highlighted a 1% false positive rate, potentially mislabeling 750 out of 75,000 papers. Similarly, Northwestern University and the University of Texas expressed accuracy concerns, opting not to use the tool.ChatGPT's Rise & ChallengesPopularity Among Students: The growing use of ChatGPT by students has educators worried about a surge in academic dishonesty.Misidentification Issues: A Texas professor mistakenly failed half his class because of false detections by ChatGPT, while other students faced wrongful accusations by anti-plagiarism software.OpenAI's StanceDifficulty in AI Text Detection: OpenAI abandoned its AI text detector due to its low accuracy rate. They've also cautioned educators about the unreliability of AI content detectors.Bias Against Non-English Writers: Many detection tools wrongly labeled content by non-English writers as AI-generated, causing additional concerns.

# X ranks lowest in tackling climate misinformation, study reveals

X, formerly known as Twitter, has ranked last in a new assessment by Climate Action Against Disinformation for its management of climate misinformation.Pinterest scored the highest in terms of addressing climate change misinformation, while other platforms like YouTube, Meta, and Instagram also ranked higher than X.Changes under Elon Musk's ownership, including unclear policies on climate misinformation and a less communicative content moderation team, have contributed to X's low ranking.Google sued after Maps allegedly directed a man to drive off a collapsed bridgePhilip Paxson, a father of two, died after Google Maps directed him to a collapsed bridge, leading to a fatal car plunge, according to a lawsuit filed by his family.The family claims Google was informed of the bridge's collapse but failed to update its navigation system, making the tech company negligent in Paxson's death.Despite having received reports about the bridge's state through its 'suggest and edit' feature, Google allegedly took no further actions to correct the route information.Study finds 95% of NFTs are now worthlessAccording to a study by dappGambl, 95% of NFTs are now practically worthless, with the majority of the 73,257 NFT collections analyzed having a market cap of zero Ether.Enthusiasm for NFTs has substantially dropped and prices have plunged, with even hyped-up collections becoming virtually valueless.The future of NFTs is uncertain; they will need to prove they have inherent value, such as cultural relevance or representing actual art, to survive.

&#x200B;

# Google expands AI coding assistant to 170 countries

\- Google launched Studio Bot in 170 countries. It was previously launched in May for Android developers in the US. The assistant helps devs generate code, fix errors and answer questions about Android.

&#x200B;

# OpenAI unveils DALL·E 3

DALL·E 3 is built natively on ChatGPT, which lets you use ChatGPT to generate tailored, detailed prompts for DALL·E 3. If it’s not quite right, you can ask ChatGPT to make tweaks.

Even with the same prompt, DALL·E 3 delivers significant improvements over DALL·E 2, as shown below (Left: DALL·E 2 results, Right: DALL·E 3). The prompt: “An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.”

OpenAI has taken steps to limit DALL·E 3’s ability to generate violent, adult, or hateful content.DALL·E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can also opt their images out from training of OpenAI’s future image generation models.

DALL·E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall.Why does this matter?As OpenAI notes, modern text-to-image systems have a tendency to ignore words or descriptions, forcing users to learn prompt engineering. DALL·E 3 represents a leap forward in AI’s ability to generate images that exactly adhere to the text you provide. Will other image generators like Midjourney and Stable Diffusion keep up?

&#x200B;

# DALL-E 3 will be available in Bing chat

\- Microsoft’s recently announced DALL-E 3 will be available in Bing as Microsoft announced users will be able to create images in a chat. DALL-E 3 will be rolled out for enterprise users in October.

&#x200B;

# ChatGPT can now generate images

Our new text-to-image model, DALL·E 3, can translate nuanced requests into extremely detailed and accurate images.Coming soon to ChatGPT Plus & Enterprise, which can help you craft amazing prompts to bring your ideas to life:[https://openai.com/dall-e-3](https://openai.com/dall-e-3)

&#x200B;

# Cisco to buy Splunk in $28 billion

In its bid to expand software and AI powered data analysis, Cisco announced it will buy cybersecurity firm, Splunk, in $28 billion. Splunk has announced AI features that detect and respond to data anomalies, earlier this year.

# Anthropic releases policy on ‘catastrophic risks’

\- Anthropic, the company behind Claude chatbot, shared a policy highlighting its commitment to responsible scaling of AI systems. The policy acknowledges AI’s potential to cause “thousands of deaths or hundreds of billions of dollars in damage.”

&#x200B;

# Amazon brings Generative AI to Alexa and Fire TV

At its annual devices event, Amazon announced a few AI updates:It will soon use a new generative AI model to power improved experiences across its Echo family of devices. The new model is specifically optimized for voice and will take into account body language as well as a person’s eye contact and gestures for more powerful conversational experiences.It also introduced generative AI updates for its Fire TV voice search, which promises to bring more conversational ways to interact with Alexa and discover new content based on specifics.Why does this matter?Integrating LLMs with voice assistants is a perfect use case. But Amazon's generative AI revamp for Alexa marks a game-changer. It promises voice assistants that understand context better, carry over information from previous conversations, and become more personalized for users.

# Amazon is turning Alexa into a hands-free ChatGPT

Amazon is upgrading Alexa, its voice assistant, with the technology behind chatbots for more complex and open-ended conversation capabilities.The new feature, which is still in progress, will show more simulated personality, interpret body language with devices equipped with cameras and modulate its voice for a more natural conversation.While this advancement holds promise, challenges like responding to body language and the fact that these large language models can sometimes blur out inappropriate or nonsensical things, remains to refine.ChatGPT Usage is Rising Again as Students Return to School

# Zuckerberg's philanthropy project is building a massive GPU cluster to ‘cure all diseases

The Chan Zuckerberg Initiative (CZI), founded by Mark Zuckerberg and his wife Priscilla Chan, plans to build one of the world's largest GPU clusters for AI-driven biomedical research.The CZI aims to use large language models to understand disease development at cellular levels and predict cell behaviors, necessitating over 1,000 Nvidia's H100 GPUs for computational requirements.The high-performance computing system, expected to be operational in 2024, will accelerate biomedical research, from mapping varied cell types in different organisms to designing potential drugs and therapeutics.

# After declining over the summer, ChatGPT usage has increased, most likely as a result of students returning to class and concerns about AI cheating.

12% Traffic Increase Last Week: ChatGPT saw a sizable jump in US web traffic as fall classes resumed.Big Drop Over Summer Break: Traffic declined steadily from May through August when school was out.Still Below Early 2022 Peaks: But current usage remains below ChatGPT's peak levels earlier this year. Back to School Brings Old ProblemsCheating Fears Resurface: Easier student access with school back raises fresh concerns about AI-aided cheating.Schools Still Debating Rules: Many institutions continue deciding whether to ban, incorporate or ignore the technology.Potential Revenue Uncertainty: Reliance on students could be problematic for monetizing ChatGPT.With the new school year boosting ChatGPT traffic, managing responsible AI use in academics remains a complex balancing act for educators.

&#x200B;

# Intel’s ‘AI PC’ can run generative AI chatbots directly on laptops

Intel’s new chip, due in December, will be able to run a generative AI chatbot on a laptop rather than having to tap into cloud data centers for computing power. It is made possible by new AI data-crunching features built into Intel's forthcoming "Meteor Lake" laptop chip and from new software tools the company is releasing.Intel also demonstrated laptops that could generate a song in the style of Taylor Swift and answer questions in a conversational style, all while disconnected from the Internet. Moreover, Microsoft's Copilot AI assistant will be able to run on Intel-based PCs.Why does this matter?This will let businesses test ChatGPT-style AI models without sending sensitive data off their own computers. Intel seems to be on track to become the lead chip manufacturer again, competing with Nvidia to make powerful chips that train AI systems such as ChatGPT and Stability AI’s models.

&#x200B;

# DeepMind’s new AI can predict genetic diseases

Google DeepMind’s new system, called AlphaMissense, can tell if the letters in the DNA will produce the correct shape. If not, it is listed as potentially disease-causing.AlphaMissense can predict the likelihood of genetic diseases by analyzing genetic mutations called missense variants.AlphaMissense operates like a large language model, trained on human and primate biology, capable of identifying normal sequences of proteins and detecting changes that could suggest a disease.With 90% accuracy, AlphaMissense is more reliable than existing tools, potentially accelerating the process of identifying disease-causing genetic mutations, which previously required months of meticulous research.

Currently, genetic disease hunters have fairly limited knowledge of which areas of human DNA can lead to disease and have to search across billions of chemical building blocks that make up DNA. They have classified 0.1% of letter changes, or mutations, as either benign or disease-causing. DeepMind's new model pushed that percentage up to 89%.Why does this matter?AI is changing nearly everything we do at the moment and might revolutionize molecular biology and life sciences, too. This development is expected to speed up diagnosis and help search for better genetic disease treatments.

&#x200B;

# Google is turning its Bard AI chatbot into a personal assistant

  
Google's Bard AI now has enhanced capabilities, pulling real-time data from Google's other applications and a user's data silo to deliver more relevant chatbot responses.  
A new feature named Bard Extensions allows the AI to access user's personal Google data to provide specific answers about their daily activities, while promising not to be used for ad targeting or training the AI model.  
To increase transparency and accuracy, Google is introducing a 'Double Check' feature where Bard audits its responses and highlights contradictory or heavily referenced statements.

&#x200B;

# DeepMind’s New AI Can Predict Genetic Diseases

AlphaMissense, a new model from Google’s artificial intelligence team, analyzes the effects of DNA mutations and will accelerate research into rare diseases.  
About 10 years ago, Žiga Avsec was a PhD physics student who found himself taking a crash course in genomics via a university module on machine learning. He was soon working in a lab that studied rare diseases, on a project aiming to pin down the exact genetic mutation that caused an unusual mitochondrial disease.  
This was, Avsec says, a “needle in a haystack” problem. There were millions of potential culprits lurking in the genetic code—DNA mutations that could wreak havoc on a person’s biology. Of particular interest were so-called missense variants: single-letter changes to genetic code that result in a different amino acid being made within a protein. Amino acids are the building blocks of proteins, and proteins are the building blocks of everything else in the body, so even small changes can have large and far-reaching effects.

&#x200B;

# Podcast Detailed Transcript:

Microsoft recently announced a game-changing feature called Microsoft Copilot. This exciting new addition will infuse AI capabilities into various Windows 11, Microsoft 365, Edge, and Bing applications. Think of it as Bing, but specifically designed for Windows devices. So, what can Copilot do? Quite a lot, actually. With this tool, you can rearrange windows effortlessly, generate text, open web apps, edit pictures, and much more. It's accessible both via an app and through a simple right-click, making it convenient for users to tap into its AI-powered goodness. But when can we start using Copilot? Well, the good news is that it's just around the corner. Microsoft plans to roll out Copilot this fall, making it available across Bing, Edge, and Microsoft 365. And for Windows users, you'll get to enjoy this feature sooner than you think. The free Windows 11 update will begin on September 26th. Now, you might be wondering, why is this such a big deal? The answer lies in the democratization of AI. While we don't have any mind-blowing use cases for Copilot just yet, this step forward by Microsoft is significant. As more users get their hands on this AI copilot, we'll start to see its true capabilities. And if all goes well, Microsoft could dominate an even larger share of the AI market by delivering AI natively.YouTube just announced some exciting news for creators! They're rolling out three new AI-powered features for YouTube Shorts creators. Let me break it down for you. First up, we have Dream Screen. This feature lets you create image or video backgrounds using AI. All you have to do is type in what you want to see in the background, and AI will make it happen. How cool is that? Next, we've got Creator Music. This feature got an AI revamp, making it even better than before. Now, creators can simply type in the kind and length of the music they need, and AI will find the most relevant suggestions. It's like having your own personal music assistant. Last but not least, we have AI Insights for Creators. This is a tool that generates video ideas for creators based on AI's analysis of what audiences are already watching and preferring. So, if you're looking for some inspiration, AI has got your back. This move by YouTube seems like a smart strategic decision to integrate AI features directly into the platform.

When it comes to evaluating large language models (LLMs) for industry applications, there are four crucial factors to consider. Skanda Vivek highlights these factors, which include quality, economic aspects, latency, and privacy. Each of these factors plays a significant role in determining the suitability of a particular LLM. The quality of the LLM is of utmost importance. Depending on your end goal, you may prioritize different aspects of quality, such as data accuracy, contextual understanding, or fluency. Consider what matters most to your industry and choose an LLM that aligns with those preferences. Economic factors also come into play. It's essential to assess the cost-effectiveness of implementing a particular LLM. Does it provide value for money? Can it fit within your organization's budget? Analyzing the economic aspects ensures you make an informed decision. Latency, or the response time of the LLM, is another vital factor. Some applications require real-time or near-instantaneous responses. Evaluating an LLM's latency helps you select the model that meets your specific timing requirements. Finally, privacy is increasingly significant for many industries. Skanda Vivek emphasizes the need to consider privacy when choosing an LLM. Depending on your industry, data security and privacy regulations may be a top priority. Ensuring the chosen model aligns with your privacy needs is crucial. Choosing the right LLM is a critical decision that can significantly impact your applications. By carefully considering these four factors—quality, economic aspects, latency, and privacy—you can make an informed choice that aligns with your industry's requirements. In recent news, some universities are raising concerns about AI detection software used to catch cheating students. There are worries that students could be falsely accused of cheating when using tools like ChatGPT. As a result, some universities are opting to abandon these AI detection systems. The debate highlights the potential drawbacks and risks associated with relying entirely on AI tools for academic integrity.So, here's the thing. Some major universities have decided to ditch AI detection tools because they're worried about their accuracy. And let's face it, nobody wants to be falsely accused of cheating, right? One tool in particular, called ChatGPT, has caused quite a stir. The problem with ChatGPT is that it's gained popularity among students, and that's got educators really concerned about academic dishonesty. But it's not just about students using AI to write their essays. It's also about the tool itself misidentifying things and getting it all wrong. For example, one professor in Texas failed half of his class because of false detections by ChatGPT. Can you imagine? Talk about a nightmare scenario. And it's not just him. Other students have also been wrongly accused by anti-plagiarism software using ChatGPT. What's interesting is that even OpenAI, the company behind ChatGPT, has abandoned their own AI text detector due to its low accuracy rate. They've even warned educators about relying too heavily on AI content detectors. And here's another thing to consider: these detection tools often get it wrong when it comes to content written by non-English writers. So, yeah, there are some serious concerns here. That's why some universities, like Vanderbilt and Northwestern, have decided to say "no thanks" to these AI detection tools. It's better to be safe than sorry, right? After all, nobody wants to unfairly accuse a student of cheating.Hey there! Some interesting news for you today. According to Climate Action Against Disinformation, X, which we all know as Twitter, has ranked last when it comes to tackling climate misinformation. Quite the bummer, right? It turns out that Pinterest is leading the pack in addressing climate change misinformation, with YouTube, Meta (formerly known as Facebook), and Instagram not too far behind. But poor old X is lagging behind. So, what led to this low ranking for X? Well, it seems that since Elon Musk took over, things have changed, and not for the better. There are unclear policies on climate misinformation and a less communicative content moderation team, both of which have contributed to X's downward slide in the rankings. Maybe they need to step up their game a bit. In another news story, Google is facing a lawsuit after it allegedly directed a man, Philip Paxson, to drive off a collapsed bridge via Google Maps. Sadly, Paxson lost his life in the tragic accident. According to his family, Google was aware of the bridge's collapse but failed to update its navigation system, which they argue makes the tech giant negligent in Paxson's death. Google apparently received reports about the bridge's condition, but did nothing to fix the route information. It's a heartbreaking situation. And finally, brace yourself for this one. A study by dappGambl has found that a whopping 95% of NFTs are now practically worthless. Yep, you heard that right. NFTs, which were once all the rage, have lost their shine. Prices have plummeted, and most of the 73,257 NFT collections analyzed have a market cap of zero Ether. It's uncertain what the future holds for NFTs, but they'll need to prove their worth, whether through cultural significance or as a representation of actual art, if they want to stick around. So, that's the latest in tech and climate news. Stay tuned for more updates!OpenAI has just unveiled their latest model for text-to-image translation called DALL·E 3, and it's pretty impressive! This new version is built directly on ChatGPT, which means you can use ChatGPT to generate customized and detailed prompts for DALL·E 3. And if the results aren't exactly what you were hoping for, you can even ask ChatGPT to make some tweaks. Compared to its predecessor, DALL·E 2, DALL·E 3 delivers significant improvements in creating detailed images. OpenAI showcased this by providing a prompt for an expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula. The results from DALL·E 3 were far superior to those from DALL·E 2. OpenAI has also taken steps to ensure that DALL·E 3 doesn't generate violent, adult, or hateful content. They have designed it to decline requests for images in the style of living artists. Additionally, creators have the option to exclude their images from being used in the training of OpenAI's future image generation models, giving them more control over the use of their work. Currently, DALL·E 3 is in research preview and will be available to ChatGPT Plus and Enterprise customers in October through the API. It will later be made available in Labs for those interested. This new release is important because it addresses the limitations of previous text-to-image systems, which often ignored certain words or descriptions. With DALL·E 3, AI's ability to generate images that align precisely with the provided text takes a huge leap forward. It raises questions about how other image generators like Midjourney and Stable Diffusion will keep up. OpenAI has also prioritized safety improvements in DALL·E 3. They have implemented measures to prevent explicit content and have tools in place to identify risky words and block public figures. Furthermore, artists can now request that their work be blocked from AI copying, and DALL·E 3 won't mimic the styles of specific artists when named. OpenAI hopes that the integration with ChatGPT and the safety guards in DALL·E 3 will expand access to this technology while preventing misuse. However, there are still concerns and legal issues surrounding AI-generated art that need to be addressed.Amazon had some exciting announcements at its recent devices event. One of the standout updates is the integration of generative AI into their Echo family of devices. This new AI model is optimized for voice, taking into account not only what is said but also body language, eye contact, and gestures. This means that interactions with Alexa will become much more powerful and conversational, providing users with improved experiences. But that's not all. Amazon has also introduced generative AI updates for Fire TV's voice search. This update aims to enhance the conversational interaction between users and Alexa, allowing for a more natural and intuitive way to discover new content based on specific preferences. This development is significant because it showcases how integrating language models like Generative AI into voice assistants can revolutionize the way we interact with them. Amazon's revamp of Alexa using generative AI is a game-changer. It enables voice assistants to better understand context, seamlessly carry over information from previous conversations, and provide a more personalized experience for users. In fact, Amazon is transforming Alexa into a hands-free ChatGPT by leveraging the technology behind chatbots. This upgrade will give Alexa the ability to engage in more complex and open-ended conversations. It will also enhance its simulated personality, interpret body language (for devices with cameras), and modulate its voice for a more natural conversation. However, there are some challenges to overcome, such as responding accurately to body language and refining these large language models to prevent inappropriate or nonsensical responses. But with Amazon's dedication to improving AI experiences, we can expect significant advancements in these areas. Overall, Amazon's integration of generative AI into Alexa and Fire TV demonstrates their commitment to providing users with more intuitive, personalized, and conversational experiences.Hey there! Have you heard about Mark Zuckerberg's latest philanthropy project? It's got a pretty ambitious goal - to "cure all diseases". The project, called the Chan Zuckerberg Initiative (CZI), is a collaborative effort between Zuckerberg and his wife, Priscilla Chan. So here's the plan: CZI is planning to build one of the biggest GPU clusters in the world specifically for AI-driven biomedical research. They want to use large language models to dive deep into disease development at the cellular level and even predict how cells behave. And to do that, they're going to need some serious computational power - over 1,000 Nvidia's H100 GPUs! This high-performance computing system is expected to be up and running by 2024. And let me tell you, it's going to revolutionize biomedical research. From mapping out various cell types across different organisms to designing potential drugs and therapeutics, this GPU cluster will supercharge the entire process. I don't know about you, but I'm pretty excited to see what kind of breakthroughs this project will bring. Who knows, maybe we'll be living in a world where diseases are a thing of the past sooner than we think!So, let's dive into the latest AI updates from OpenAI, Microsoft, YouTube, Google, Cisco, and Anthropic. It seems like ChatGPT is back in the spotlight with an increase in usage, particularly because students are returning to school and concerns about AI cheating are on the rise. After experiencing a decline throughout the summer, ChatGPT has seen a 12% traffic increase since fall classes resumed in the US. However, it's important to note that current usage is still below the peak levels seen earlier this year. With students back in the classroom, concerns about AI-aided cheating have resurfaced. The easier access students have to AI technology raises fresh debates among schools about whether to ban, incorporate, or ignore such tools. For educators, managing responsible AI use in academics is becoming a complex balancing act. There's also some uncertainty surrounding potential revenue as ChatGPT's reliance on students could pose challenges for monetization. Moving on to other AI news, Microsoft has announced a new AI-powered feature called Microsoft Copilot. This feature, available in various Windows 11 applications, Microsoft 365, Edge, and Bing, allows users to rearrange windows, generate text, edit pictures, and more. It's like having Bing integrated into your Windows experience. YouTube is not far behind with its AI advancements. The platform has introduced three new AI-powered features specifically for Shorts creators. Dream Screen uses AI to generate background images and videos, Creator Music helps find the perfect track for Shorts, and AI Insights for Creators assists in brainstorming the next video idea. These features aim to enhance the content creation experience on YouTube. Meanwhile, Google has expanded its AI coding assistant, Studio Bot, to 170 countries. Initially launched for Android developers in the US, this assistant helps generate code, fix errors, and answer questions about Android development. It's a handy tool for developers worldwide. In the world of image creation, Microsoft's DALL-E 3 is making its way to Bing. Soon, users will be able to create images in a chat using DALL-E 3. This exciting feature will be rolled out for enterprise users in October, opening up new possibilities for visual communication. Now, let's switch gears to a significant acquisition. Cisco has announced its plan to acquire cybersecurity firm Splunk for $28 billion. This move aligns with Cisco's goal to expand its software and AI-powered data analysis capabilities. Splunk, which introduced AI features earlier this year to detect and respond to data anomalies, will play a vital role in Cisco's strategy. In the realm of responsible AI scaling, Anthropic, the company behind the Claude chatbot, has released a policy that emphasizes its commitment to responsible AI system development. The policy acknowledges the potential for AI systems to cause catastrophic risks, including thousands of deaths or immense financial damage. It's encouraging to see companies prioritizing responsible AI practices. In other tech news on September 22nd, 2023, Cisco is set to make its largest acquisition ever by acquiring Splunk for $28 billion. This move aims to boost security services and system performance troubleshooting. On a different note, NASA eagerly awaits the return of pristine asteroid Bennu samples, taken by OSIRIS-REx in 2020. The samples could unlock valuable insights into the origins of our solar system. In the legal world, lawyers who sued Tesla's board for excessive pay are seeking a jaw-dropping $10,000 an hour. The case is sure to attract attention as it unfolds. Another interesting development involves an anonymous developer who used OpenAI's ChatGPT API to program an AI that created and launched an ERC-20 token called AstroPepeX. Within just 24 hours, the token generated an astonishing $12.9 million in trading. It's a testament to the possibilities AI offers in the realm of finance and entrepreneurship. Lastly, Ilya Sutskever, one of OpenAI's renowned figures, along with machine ethicist Thomas Krendl Gilbert, have described AI development as "alchemy." This comparison underscores the unpredictable and mysterious nature of AI outcomes, sparking heated debate within the industry. And there you have it, the latest AI updates featuring ChatGPT, Microsoft, YouTube, Google, Cisco, and Anthropic. Stay tuned for more exciting advancements in the world of artificial intelligence.Hey there! If you're excited about diving deeper into the world of artificial intelligence, I've got just the thing for you! There's this amazing book called "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence." Trust me, it's a game-changer! Now, let me tell you why you should totally get your hands on this gem. "AI Unraveled" is packed with all the answers to those burning questions you may have about AI. Think of it as your ultimate AI guidebook. It's like having a knowledgeable expert right by your side, unravelling the mysteries of artificial intelligence in a way that's easy to comprehend. The best part? You can grab a copy of this must-read book at three different platforms: Apple, Google, or Amazon. So, no matter whether you're an Apple aficionado, a Google guru, or an Amazon enthusiast, there's a way for you to access this invaluable resource. So, why wait any longer? Dive into "AI Unraveled" today and expand your understanding of artificial intelligence like never before. This book is a game-changer, and it's ready to be enjoyed by curious minds like yours. Happy reading!In today's episode, we covered Microsoft's AI-powered Copilot, YouTube's new AI features for creators, evaluating large language models in industry, concerns with AI detection tools in universities, rankings of tech companies tackling misinformation, OpenAI's DALL·E 3 text-to-image model, generative AI updates from Amazon, Zuckerberg's philanthropy in AI-driven research, ChatGPT usage concerns, and other notable news - plus, don't forget to expand your AI knowledge with the essential book 'AI Unraveled'. Join us next time on AI Unraveled as we continue to demystify frequently asked questions on artificial intelligence and bring you the latest trends in AI, including ChatGPT advancements and the exciting collaboration between Google Brain and DeepMind. Stay informed, stay curious, and don't forget to subscribe for more!

# Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book "AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence," available at Apple, Google, or Amazon today today:

# AI Unraveled @ Amazon: [https://amzn.to/3ZrpkCu](https://amzn.to/3ZrpkCu)

# AI Unraveled @ Apple: [http://books.apple.com/us/book/id6445730691](http://books.apple.com/us/book/id6445730691)

# AI Unraveled @ Google: [https://play.google.com/store/books/details?id=oySuEAAAQBAJ](https://play.google.com/store/books/details?id=oySuEAAAQBAJ)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16pp2h6/microsofts_copilot_puts_ai_into_everything/
-----
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16ushyy/indeeds_ceo_says_college_students_might_be/
-----
Title: Two-minute Daily AI Update (Date: 09/25/2023): News from Amazon, Anthropic, Meta’s, Microsoft, Google, ElevenLabs, and Salesforce
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **Amazon to invest up to $4 billion in Anthropic, expanding access to safer AI**  
\- It is part of a broader collaboration to develop the most reliable and high-performing foundation models. Anthropic’s frontier safety research and products, together with AWS’s expertise in running secure, reliable infrastructure, will make Anthropic’s safe and steerable AI widely accessible to AWS customers.  

* **Meta’s AI chatbot plan includes a ‘sassy robot’ for younger users**  
\- Meta has plans to develop dozens of chatbot personas geared towards engaging young users with more colorful behavior. It also includes ones for celebrities to interact with their fans and some more geared towards productivity, such as to help with coding and other tasks.
* **LongLoRA: Efficient fine-tuning of long-context LLMs**  
\- New research has introduced LongLoRA, an efficient fine-tuning method designed to extend the context sizes of pre-trained LLMs without a huge computation cost. In practical terms, LongLoRA performed strongly on various tasks using LLaMA-2 models ranging from 7B/13B to 70B. Notably, it extended LLaMA-2 7B from 4k context to 100k and LLaMA-2 70B to 32k on a single 8x A100 machine, all while keeping the original model architectures intact.
* **Microsoft’s mobile keyboard app SwiftKey gains new AI-powered features**  
\- It will now include AI camera lenses, AI stickers, an AI-powered editor, and the ability to create AI images from the app.
* **Google Pixel 8’s latest leak shows off big AI camera updates**  
\- AI photo editing with Magic Editor will enable you to remake any picture you take. DSLR-style manual camera controls will let you tweak the shutter speed and ISO of an image and a focus slider.
* **A drinks company in Poland appoints AI robot as 'experimental’ CEO**  
\- Dictador, best known for its rums, has appointed the robot to oversee the company’s growth into one-off collectables, communication, or even strategy planning. It is named Mika.
* **ElevenLabs launches free book classics narrated by high-quality AI voices**  
\- It presents six classic stories told by compelling AI voices in multiple languages, including "Winnie the Pooh" and "The Picture of Dorian Gray." The entire recording process took only one day.
* **Salesforce to acquire Airkit.ai, a low-code platform for building AI customer service agents**  
\- The GPT-4-based platform allows e-commerce companies to build specialized customer service chatbots that can deal with queries around order status, refunds, product information, and more.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/amazon-to-invest-4b-dollars-in-anthropic).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16rrw19/twominute_daily_ai_update_date_09252023_news_from/
-----
Title: Amazon’s $4bn Gamble: Taking AI to the Next Level with Anthropic
Content: Imagine the implications when a tech giant like Amazon doubles down on AI tech. According to recent reports, Amazon plans to infuse a staggering $4bn into AI startup, Anthropic. This could mark a significant shift in the AI sphere.

Anthropic, known for its revolutionary models, will not only get a financial boost but also access to Amazon’s massive computing power. This investment elevates Amazon to a minority stakeholder level in Anthropic.

Part of Amazon’s long-term strategy, Anthropic's role bolsters Amazon Web Services (AWS) standing, promising advancements in their cloud technology. 

However, what's really captivating is how this investment could disrupt NVIDIA Corporation's stronghold in the AI applications market.

This partnership might prove to be a game-changer and I would love to hear your thoughts on:

* What further implications could this deal have?
* How could this shake up the AI industry?

Read more:

[Article Link](https://medium.com/@branstiong/amazons-groundbreaking-4bn-bet-on-ai-startup-anthropic-363725b4fdaa)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16rn574/amazons_4bn_gamble_taking_ai_to_the_next_level/
-----
News posts saved as '2023-09-30-reddit_news_posts.md'
Title: Microsoft seeks nuclear reactors to power AI
Content: -Microsoft made a job posting looking for a nuclear tech expert who could help integrate small modular nuclear reactors “to power the datacenters that the Microsoft Cloud and AI reside on,"'  
-Bill Gates is chairman of the board TerraPower, a company working in the field of small modular reactors  
-Microsoft has previously publicly committed to pursuing nuclear energy

Source:
https://www.cnbc.com/2023/09/25/microsoft-is-hiring-a-nuclear-energy-expert-to-help-power-data-centers.html
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16s9aes/microsoft_seeks_nuclear_reactors_to_power_ai/
-----
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16ushyy/indeeds_ceo_says_college_students_might_be/
-----
Title: Two-minute Daily AI Update (Date: 09/25/2023): News from Amazon, Anthropic, Meta’s, Microsoft, Google, ElevenLabs, and Salesforce
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **Amazon to invest up to $4 billion in Anthropic, expanding access to safer AI**  
\- It is part of a broader collaboration to develop the most reliable and high-performing foundation models. Anthropic’s frontier safety research and products, together with AWS’s expertise in running secure, reliable infrastructure, will make Anthropic’s safe and steerable AI widely accessible to AWS customers.  

* **Meta’s AI chatbot plan includes a ‘sassy robot’ for younger users**  
\- Meta has plans to develop dozens of chatbot personas geared towards engaging young users with more colorful behavior. It also includes ones for celebrities to interact with their fans and some more geared towards productivity, such as to help with coding and other tasks.
* **LongLoRA: Efficient fine-tuning of long-context LLMs**  
\- New research has introduced LongLoRA, an efficient fine-tuning method designed to extend the context sizes of pre-trained LLMs without a huge computation cost. In practical terms, LongLoRA performed strongly on various tasks using LLaMA-2 models ranging from 7B/13B to 70B. Notably, it extended LLaMA-2 7B from 4k context to 100k and LLaMA-2 70B to 32k on a single 8x A100 machine, all while keeping the original model architectures intact.
* **Microsoft’s mobile keyboard app SwiftKey gains new AI-powered features**  
\- It will now include AI camera lenses, AI stickers, an AI-powered editor, and the ability to create AI images from the app.
* **Google Pixel 8’s latest leak shows off big AI camera updates**  
\- AI photo editing with Magic Editor will enable you to remake any picture you take. DSLR-style manual camera controls will let you tweak the shutter speed and ISO of an image and a focus slider.
* **A drinks company in Poland appoints AI robot as 'experimental’ CEO**  
\- Dictador, best known for its rums, has appointed the robot to oversee the company’s growth into one-off collectables, communication, or even strategy planning. It is named Mika.
* **ElevenLabs launches free book classics narrated by high-quality AI voices**  
\- It presents six classic stories told by compelling AI voices in multiple languages, including "Winnie the Pooh" and "The Picture of Dorian Gray." The entire recording process took only one day.
* **Salesforce to acquire Airkit.ai, a low-code platform for building AI customer service agents**  
\- The GPT-4-based platform allows e-commerce companies to build specialized customer service chatbots that can deal with queries around order status, refunds, product information, and more.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/amazon-to-invest-4b-dollars-in-anthropic).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16rrw19/twominute_daily_ai_update_date_09252023_news_from/
-----
Title: Amazon’s $4bn Gamble: Taking AI to the Next Level with Anthropic
Content: Imagine the implications when a tech giant like Amazon doubles down on AI tech. According to recent reports, Amazon plans to infuse a staggering $4bn into AI startup, Anthropic. This could mark a significant shift in the AI sphere.

Anthropic, known for its revolutionary models, will not only get a financial boost but also access to Amazon’s massive computing power. This investment elevates Amazon to a minority stakeholder level in Anthropic.

Part of Amazon’s long-term strategy, Anthropic's role bolsters Amazon Web Services (AWS) standing, promising advancements in their cloud technology. 

However, what's really captivating is how this investment could disrupt NVIDIA Corporation's stronghold in the AI applications market.

This partnership might prove to be a game-changer and I would love to hear your thoughts on:

* What further implications could this deal have?
* How could this shake up the AI industry?

Read more:

[Article Link](https://medium.com/@branstiong/amazons-groundbreaking-4bn-bet-on-ai-startup-anthropic-363725b4fdaa)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16rn574/amazons_4bn_gamble_taking_ai_to_the_next_level/
-----
Title: Two-minute Daily AI Update (Date: 09/26/2023): News from OpenAI, NVIDIA, Getty Images, Colossal-AI, Tesla, SnapChat, Microsoft, Spotify, and Google AI
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **ChatGPT is getting major update, It can now see, hear, and speak**  
\- OpenAI is introducing voice and image capabilities in ChatGPT, allowing users to have voice conversations and show images to ChatGPT.   
\- Users can have live conversations about landmarks, get recipe suggestions by showing pictures of their fridge, and even receive math problem hints by sharing a photo.   
\- The voice and image capabilities will be rolled out to Plus and Enterprise users over the next two weeks, with voice available on iOS and Android and images available on all platforms. 
* **Getty Images introduced an art tool called Generative AI, powered by Nvidia**   
\- It will render images from text descriptions. The tool is designed to be "commercially safer" than rival solutions, with safeguards in place to prevent disinformation and copyright infringement.   
\- Getty Images will compensate contributors whose works are used to train the AI generator and share revenues generated from the tool.   
\- The tool can be accessed on Getty's website or integrated into apps and websites through an API, with pricing based on prompt volume.
* **Colossal-AI released Colossal-LLaMA-2, an open-source and commercial-free domain-specific LLM**  
\- It uses a relatively small amount of data and training time, resulting in lower costs.   
\- Includes improvements such as vocabulary expansion, data cleaning system, and a multi-stage pre-training scheme to enhance both Chinese and English abilities.   
\- Allows for cost-effective training of lightweight domain-specific LLMs, enabling fine-tuning for specific business applications. 
* **Tesla’s humanoid robot Optimus can now sort objects autonomously**  
\- Using its end-to-end trained neural network. The robot is able to calibrate itself using joint position encoders and vision to locate its limbs precisely. It can then sort colored blocks into their respective trays, even adapting to dynamic changes in the environment. - The robot also uses corrective action to turn blocks right-side-up if they are placed on their side.
* **Snapchat has partnered with Microsoft to insert ads into its AI chatbot feature, My AI**  
\- The chatbot, introduced earlier this year, offers link suggestions related to user conversations. For example, if a user asks for dinner recommendations, the chatbot could reply with a link sponsored by a local restaurant.   
\- The partnership is a win for Microsoft's ads business and could position Snapchat as a platform for Gen Z users to search for products and services through AI chats.
* **Spotify is testing a voice translation feature for podcasts, using AI to translate content into different languages**  
\- By offering translated podcasts from popular hosts like Dax Shepard and Lex Fridman, Spotify hopes to expand its global reach and cater to a wider audience.
* **Google's AI tool, Bard, has now new capabilities to help travelers plan their vacations**  
\- By connecting with various Google applications like Gmail, Google Flights, and Google Maps, Bard can provide personalized assistance throughout the trip.   
\- Users can ask Bard to find flight and hotel information, get directions, watch YouTube videos, and even check dates that work for everyone involved.   
\- Additionally, recent updates to Google Flights offer tools to predict the best time to find cheap airline deals. 
* **Correcto has raised $7M in seed funding to expand its language writing tool for Spanish speakers**  
\- While AI tools like ChatGPT can generate text in Spanish, Correcto believes its tool offers better quality and provides opportunities for individual learning. The company plans to target enterprise customers while also offering a freemium version for individual users.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/biggest-boom-in-ai-chatgpt-nvidia-tesla-elonmusk).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16sqlkp/twominute_daily_ai_update_date_09262023_news_from/
-----
News posts saved as '2023-10-02-reddit_news_posts.md'
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16ushyy/indeeds_ceo_says_college_students_might_be/
-----
Title: Two-minute Daily AI Update (Date: 10/02/2023): News from Apple, Humane, OpenAI, Google Pixel, Google Bard, Wikipedia and Walmart
Content: Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the world of AI.  


* **CEO of Apple Tim Cook confirms, Apple is working on ChatGPT-style AI + more**  
\- The company is also expecting to hire more AI staff in the UK. AI is already integrated into Apple products, such as the Apple Watch's Fall Detection and Crash Detection features.   
\- Apple is planning to upgrade its search engine in the App Store and potentially develop a Google competitor "Pegasus". Its being integrated into iOS and macOS, with the possibility of using gen AI tools to enhance it further.   
\- Apple's Spotlight search feature already allows users to search for web results, app details, and documents. 
* **Humane Inc has unveiled its first AI device, ‘Humane Ai Pin’**  
\-  The device uses sensors for natural and intuitive interactions. It does not need to be paired with a smartphone and features AI-powered optical recognition and a laser-projected display.   
\- The full capabilities of the Humane Ai Pin will be revealed on November 9. 
* **OpenAI’s DALL-E 3 is now publicly available on Bing for free**  
\- The previous technology preview of DALL-E lacked protections against malicious use, but DALL-E 3 has implemented guardrails. Paid customers of OpenAI's ChatGPT Plus and Enterprise products are expected to get access first.
* **Google focuses more on AI in Pixel 8 phone**  
\- A leaked Google ad showcases new AI features: Best Take, a feature that allows users to swap faces into images from other pictures.   
\- The Pixel 8 event is set to take place on October 4th, but there have already been numerous leaks about the phone.   
\- The ad also highlights the process of transferring data to a Pixel 8 and mentions other AI features like Magic Eraser.
* **Google's Bard is set to introduce a new feature called "Memory"**   
\- It will allow it to remember important details about users and personalize its responses. Currently, each conversation with Bard starts from scratch, but with Memory, the AI will be able to account for specific details shared by users and use them to improve future results. 
* **Wikipedia testing an AI-powered ChatGPT Plus plugin**  
\- To improve knowledge access on the platform. The plugin searches and summarizes Wikipedia information for user queries, aiming to enhance user engagement and content quality.  
\- The foundation hopes to gauge user engagement, potential contributors, and AI content quality through this initiative. This effort is part of its Annual Plan to enhance access to free knowledge on Wikipedia by facilitating the connection between readers and editors.
* **Walmart helping shoppers with AI**  
\- AI can help customers visualize products in their homes or on their bodies, as well as provide recommendations for products. It also help in creating three-dimensional objects from still photos, saving time and money in the creation process. Walmart is open to using different AI technologies and aims to be neutral in its approach. The company has been using chatbots for customer service and transactions since 2020.

More detailed breakdown of these news and innovations in the [daily newsletter](https://theaiedge.substack.com/p/apple-chatgpt-ai-bing-googlepixel8-googlebard).
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16xwbex/twominute_daily_ai_update_date_10022023_news_from/
-----
Title: Google is expanding its AI-powered search experience to teenagers
Content: Google's AI-driven search experience, Search Generative Experience (SGE), is now accessible to teenagers between 13-17 in America. Entailments include a conversational mode for searches, which Google believes can help youngsters pose atypical questions to dig deeper.

For the latest advancements in AI, [look here first](https://www.superchargedai.co/subscribe?utm_campaign=campaign&utm_medium=google-sge&utm_source=reddit).

**Teen-friendly AI search**

- SGE introduces a conversational mode to Google Search, allowing users to ask questions and follow-ups in a more natural language.
- To prevent harmful content from surfacing, Google has placed guardrails, providing stronger protections related to illegal and age-gated substances, or bullying.

**Features and improving AI accuracy**

- Google is rolling out "About this result" to provide users with more context about the displayed content.
- Google acknowledges and addresses any validation of false or offensive claims by the AI-powered response, ensuring to provide higher quality and more accurate responses.
- It’s also using large language models to self-critique and rewrite draft responses on sensitive topics based on quality and safety principles.

**SGE's popularity and future plans**

- Since SGE's introduction, it has found popularity, especially among younger users who prefer a conversational approach.
- Google plans to expand SGE outside the U.S. to India and Japan and improve its services with support for videos, images, local info, and more.
- It's also experimenting with ads positioned next to the AI-generated responses.

[(source)](https://techcrunch.com/2023/09/28/google-opening-up-generative-ai-search-experience-teenagers/)

**P.S. If you like this kind of analysis,** I write [a free newsletter](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&utm_medium=google-sge&utm_campaign=campaign) that tracks the most relevant news and research in AI and tech. Professionals from Google, Meta, and OpenAI are already reading it.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16uzzmc/google_is_expanding_its_aipowered_search/
-----
Title: Meta's Llama 2 Long outperforms GPT 3.5 and Claude 2
Content: Meta Platforms recently introduced Llama 2 Long, a revolutionary AI model outperforming top competitors with its ability to generate accurate responses to long user queries.

For the latest advancements in AI, [look here first](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&utm_medium=llama2long&utm_campaign=campaign).

**Meta's new AI model**

- As an enhancement of the original Llama 2, Llama 2 Long deals with larger data containing longer texts and is modified to handle lengthier information sequences.
- Its stellar performance outshines other models such as OpenAI's GPT-3.5 Turbo and Claude 2.

**How Llama 2 Long works**

- Meta built different versions of Llama 2, ranging from 7 billion to 70 billion parameters, which refines its learning from data.
- Llama 2 Long employs Rotary Positional Embedding (RoPE) technique, refining the way it encodes the position of each token, allowing fewer data and memory to produce precise responses.
- The model further fine-tunes its performance using reinforcement learning from human feedback (RLHF), and synthetic data generated by Llama 2 chat itself.

**Impressive feats and future aspirations**

- Llama 2 Long can create high-quality responses to user prompts up to 200,000 characters long, which is approximately 40 pages of text.
- Its ability to generate responses to queries on diverse topics such as history, science, literature, and sports indicates its potential to cater to complex and various user needs.
- The researchers see Llama 2 Long as a step towards broader, more adaptable AI models, and advocate for more research and dialogue to harness these models responsibly and beneficially.

[(source)](https://interestingengineering.com/innovation/llama-2-long-outperforms-other-ai-models-in-long-queries)

**P.S. If you like this kind of analysis,** I write [a free newsletter](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&utm_medium=llama2long&utm_campaign=campaign) that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16xmmd7/metas_llama_2_long_outperforms_gpt_35_and_claude_2/
-----
Title: AI World Day...
Content: October 1, 1950 saw the publication of "Computing Machinery and Intelligence" by a certain A. M. Turing.

Maybe a good date for an AI World Day... 🤔

https://academic.oup.com/mind/article/LIX/236/433/986238
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16wumqe/ai_world_day/
-----
News posts saved as '2023-10-04-reddit_news_posts.md'
Title: Gen Z Trusts AI, while Boomers are Skeptical
Content: Recent Salesforce research suggests Gen Z is eagerly adopting AI tools like ChatGPT while older generations remain skeptical. ([Source](https://www.businessinsider.com/trust-chatgpt-gen-z-x-baby-boomers-ai-budgeting-2023-10))

If you want the latest AI updates before anyone else, [look here first](https://www.theedge.so/subscribe)

**Gen Z All In**

* 70% of ChatGPT users are Gen Z, using it to automate work and boost creativity.
* Many are interested in AI for career and financial planning.
* Gen Z sees huge potential in mastering and applying new AI tech.

**Boomers and Gen X Wary**

* 68% of non-users are Gen X and boomers, uncertain about AI impacts.
* 88% of non-users over 57 don't understand how it would affect their lives.
* Older adults lack familiarity with capabilities of new generative AI.

**An Age Disconnect**

* Some boomers doubt they are tech-savvy enough to use AI tools.
* But AI chatbots could provide companionship and emotional support.
* Adoption gap highlights challenges in keeping older generations connected.

**PS:** Get the latest **AI developments, tools, and use cases** by joining one of the fastest-growing AI newsletters. Join [5000+ professionals getting smarter in AI.](https://www.theedge.so/subscribe)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16zcj5s/gen_z_trusts_ai_while_boomers_are_skeptical/
-----
Title: ChatGPT can now 'see,' and it's a game-changer.
Content: From revolutionizing education by breaking down complex diagrams to simplifying corporate jargon in PowerPoint slides, this AI is your new 24/7 consultant.

  
📚 Educators: Imagine an AI tutor that personalizes learning by interpreting educational materials in real-time.  
👔 Businesses: Say goodbye to convoluted presentations; ChatGPT will make them straightforward and actionable.  
🏠 Architects: Struggling to label a unique design? ChatGPT can name it for you.  
👩‍💻 Developers: Turn your whiteboard scribbles into foundational code effortlessly.  
📈 Marketers: Decode the secret sauce behind viral memes for better brand engagement.  
🎬 Film Buffs: Identify any movie scene and even get the dialogue!  
🚗 City Dwellers: Confused by parking signs? ChatGPT clarifies them in a snap.  
🌐 This isn't just tech advancement; it's a lifestyle revolution. From students to professionals, there's something for everyone. The future of AI isn't just promising; it's already here.

  
👉 Dive deeper into how ChatGPT's vision is shaping the future: [https://www.godofprompt.ai/blog/chatgpt-unleashes-image-recognition-mind-blowing-ways-people-can-use-it?fbclid=IwAR3Kq7\_2neLmYGMDftY6L5-eBnj5E2Ha0PTKwURC-wFwDMNtK7iU\_VyGdy0](https://www.godofprompt.ai/blog/chatgpt-unleashes-image-recognition-mind-blowing-ways-people-can-use-it?fbclid=IwAR3Kq7_2neLmYGMDftY6L5-eBnj5E2Ha0PTKwURC-wFwDMNtK7iU_VyGdy0) 
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16xso8m/chatgpt_can_now_see_and_its_a_gamechanger/
-----
Title: AI is replacing customer service jobs across the globe
Content: The rise of AI chatbots like ChatGPT is automating call center and customer service roles in India, the Philippines, and beyond, sparking workforce concerns. ([Source](https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/))

If you want the latest AI updates before anyone else, [look here first](https://www.theedge.so/subscribe)

**AI Rising in Customer Support**

* Startups and big brands adopting AI bots to cut costs and improve service.
* 80% of companies say conversational AI is now essential capability.
* AI handles routine issues, leaves complex problems to humans.

**Economic Impacts in Outsourcing Hubs**

* Automation could threaten over 1 million Philippine jobs by 2028.
* In India, AI already replacing roles and reshaping workforce.
* But new tech may also boost productivity if used to assist.

**Worker and Societal Impacts**

* AI takes over simple issues, leaving humans with only tough problems.
* Could enable hiring less experienced, lower cost workers.
* But also potential to augment human capabilities.

**PS:** Get the latest **AI developments, tools, and use cases** by joining one of the fastest-growing AI newsletters. Join [5000+ professionals getting smarter in AI.](https://www.theedge.so/subscribe)
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16ztjjp/ai_is_replacing_customer_service_jobs_across_the/
-----
Title: GPT-4 outperforms its rivals in new AI benchmark suite GPT-Fathom
Content: ByteDance and the University of Illinois researchers have developed an improved benchmark suite with consistent parameters, called GPT-Fathom, that indicates GPT-4, the engine behind the paid version of ChatGPT, significantly outperforms leading LLMs, including its biggest competitor, Claude 2.

For the latest advancements in AI, [look here first](https://www.superchargedai.co/subscribe?utm_campaign=campaign&utm_medium=gpt-4-benchmarking&utm_source=reddit).

**GPT-Fathom's breakthrough**

- The new benchmark suite, GPT-Fathom, addresses consistent settings issues and prompt sensitivity, attempting to reduce inconsistencies in LLM evaluation.
- In a comparison using GPT-Fathom, GPT-4 outperformed over ten leading LLMs, crushing the competition in most benchmarks, and showing significant performance leaps from GPT-3 to its successors.

**Performance specifics**

- The gap in performance was especially pronounced against Claude 2, ChatGPT's biggest rival.
- GPT-4's Advanced Data Analysis model exhibited superior performance in coding, giving it an edge as compared to LuckLlama 2, the current best-performing open-source model.
- Llama 2-70B showed comparable or better performance than gpt-3.5-turbo-0613 in safety and comprehension but displayed worse performance in "Mathematics", "Coding", and "Multilingualism".

**The seesaw effect**

- The research team noted a 'seesaw effect' where an improvement in one area can lead to degradation in another.
- For instance, GPT-4 saw a performance drop on the Mathematical Geometry Simple Math (MGSM) benchmark, despite improving its performance significantly on text comprehension benchmark DROP.

[(source)](https://the-decoder.com/gpt-4-crushes-other-llms-according-to-new-benchmark-suite/)

**P.S. If you like this kind of analysis,** I write [a free newsletter](https://www.superchargedai.co/subscribe?utm_campaign=campaign&utm_medium=gpt-4-benchmarking&utm_source=reddit) that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16yxfsk/gpt4_outperforms_its_rivals_in_new_ai_benchmark/
-----
Title: Indeed's CEO says college students might be learning skills that could go 'obsolete' once they graduate
Content: The CEO of job site Indeed warns that the pace of AI advancement means graduates may find their newly acquired skills outdated by the time they finish school. ([Source](https://www.businessinsider.com/indeed-ceo-ai-chatgpt-could-make-college-skills-obsolete-2023-9))

**AI's Accelerating Impact**

* Compares current pace to the rapid disruption of past tech revolutions.
* Believes AI could master white-collar skills faster than students can learn them.
* Research shows software developer roles are most exposed to generative AI.

**Cause for Concern**

* College may not provide the skills to compete as AI evolves.
* Degrees could become outdated in the 4 years it takes to earn them.
* Echoes fears that AI could automate many current jobs.

**Balancing Innovation and Risks**

* Notes AI like Indeed's helps people find jobs now.
* But it warns that its job-replacing potential requires urgent attention.
* Says we must focus on addressing AI's downsides.

**TL;DR:** The CEO of Indeed warns that the pace of AI threatens to make college degrees obsolete before students even graduate, underscoring concerns about AI's potential impact.

**PS:** Get the **latest AI developments, tools, and use cases** by joining one of the [fastest growing AI newsletters.](https://www.theedge.so/subscribe) Join 5000+ professionals getting smarter in AI.
URL: https://www.reddit.com/r/ArtificialInteligence/comments/16ushyy/indeeds_ceo_says_college_students_might_be/
-----
News posts saved as '2023-10-06-reddit_news_posts.md'
