
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about",
    "title": "Mediumish Template for Jekyll",
    "body": "This website is built with Jekyll and Mediumish template for Jekyll. It's for demonstration purposes, no real content can be found. Mediumish template for Jekyll is compatible with Github pages, in fact even this demo is created with Github Pages and hosted with Github.  Documentation: Please, read the docs here. Questions or bug reports?: Head over to our Github repository! Buy me a coffeeThank you for your support! Your donation helps me to maintain and improve Mediumish . Buy me a coffee Documentation"
    }, {
    "id": 2,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                     All Stories:                                                                                                     Introduction to BentoML              :       BentoML 등장 배경 BentoML is designed for teams working to bring machine learning (ML) models into production in a reliable, scalable, and cost-efficient way. In particular, AI application developers can. . . :                                                                               Seungki                08 Jul 2023                                                                                                                                     Introduction to MLflow              :       MLFlow로 해결할 Pain Point 실험 추적이 어렵다 코드 재현이 어렵다 모델 패키징 및 배포가 어렵다 모델을 관리하기 위한 중앙 저장소가 없다:                                                                               Seungki                07 Jul 2023                                                                                                                                     Introduction to Apache Airflow              :       Apache Airflow의 등장 배경Batch Processing 예약된 시간에 실행되는 프로세스 일회성 실행, 주기적인 실행 전부 가능     월요일날 7:00시에 한번 실행, 매주 월요일 7:00에 실행   :                                                                               Seungki                06 Jul 2023                                                                                                                                     Logging              :       Logging 사용자 로그 데이터, 이벤트 로그 데이터 . .  머신러닝 인퍼런스 요청 로그, 인퍼런스 결과 등을 저장해야 함:                                                                               Seungki                05 Jul 2023                                                                                                                                     FastAPI - 2              :       Event Handler 이벤트가 발생했을 때, 그 처리를 담당하는 함수 FastAPI 에선 Application을 실행, 종료할 때 특정 함수를 실행할 수 있음:                                                                               Seungki                04 Jul 2023                                                                                                                                     FastAPI - 1              :       FastAPI 최근 떠오르는 Python Web Framework API document 작성을 자동으로 해주는 Swagger 간결한 코드 작성 빠른 속도:                                                                               Seungki                04 Jul 2023                                               &laquo; Prev       1        2        3      Next &raquo; "
    }, {
    "id": 4,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "http://localhost:4000/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "http://localhost:4000/BentoML-1/",
    "title": "Introduction to BentoML",
    "body": "2023/07/08 - BentoML 등장 배경:  BentoML is designed for teams working to bring machine learning (ML) models into production in a reliable, scalable, and cost-efficient way. In particular, AI application developers can leverage BentoML to easily integrate state-of-the-art pre-trained models into their applications. By seamlessly bridging the gap between model creation and production deployment, BentoML promotes collaboration between developers and in-house data science teams. 항상 많은 라이브러리들이 새롭게 등장하고, 보통 이 라이브러리들은 해결하려고 하는 핵심 문제가 존재 함. BentoML이 해결하려는 문제:    Model Serving Infra의 어려움          Serving을 위해 다양한 라이브러리, artifact, asset 등. . 사이즈가 큰 파일을 패키징 해야함           Cloud service에 지속적으로 배포하기 위해 많은 작업이 필요함     -&gt; BentoML은 CLI로 이 문제의 복잡도를 낮추려고 함(CLI 명령어로 모두 진행 가능)          Online Serving의 Monitoring 및 Error Handling      Online Serving으로 API 형태로 생성   Error 처리, Logging을 추가로 구현해야 함   BentoML은 Python Logging Module을 사용해 Access Log, Prediction Log를 기본으로 제공   Config를 수정해 Logging도 커스텀할 수 있고, Prometheus 같은 Metric 수집 서버에 전송할 수 있음      Online Serving의 포퍼먼스 튜닝의 어려움      Adaptive Micro Batch 방식을 채택해 동시에 많은 요청이 들어와도 높은 처리량을 보여줌   BentoML 특징: Serving에 특화된 가벼운 라이브러리로 볼 수 있음  쉬운 사용성 Online/Offline Serving 지원 Tensorflow, PyTorch, Keras, XGBoost 등 메이저 프레임워크 지원 Docker, Kubernetes, AWS, Azure 등의 배포 환경 지원 및 가이드 제공 Flask 대비 100배의 처리량 모델 저장소(Yatai) 웹 대시보드 지원 데이터 사이언스와 데브옵스 사이의 간격을 좁혀주고, 높은 성능의 serving 지원 출처 - https://towardsdatascience. com/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d BentoML 사용하기: 1. BentoML 설치:  BentoML은 python 3. 6 이상만 지원 pyenv 등으로 파이썬 버전을 설정해서 진행 가상환경 virtualenv 또는 poetry로 설정pip install bentoml 2. BentoML Flow:  모델 학습 코드 생성 Prediction Service Class 생성 Prediction Service에 모델 저장 Serving Docker Image Build(컨테이너화) Serving 배포Prediction Service Class 생성: 12345678910111213141516171819202122# bento_service. pyimport pandas as pdfrom bentoml import env, artifacts, api, BentoServicefrom bentoml. adapters import DataframeInputfrom bentoml. frameworks. sklearn import SklearnModelArtifact@env(infer_pip_packages=True)@artifacts([SklearnModelArtifact('model')])class IrisClassifier(BentoService):       A minimum prediction service exposing a Scikit-learn model       @api(input=DataframeInput(), batch=True)  def predict(self, df: pd. DataFrame):           An inference API named `predict` with Dataframe input adapter, which codifies    how HTTP requests or CSV files are converted to a pandas Dataframe object as the    inference API function input           return self. artifacts. model. predict(df) BentoService를 활용해 Prediction Service Class 생성 예측할 때 사용하는 API를 위한 Class12@env(infer_pip_packages=True)@artifacts([SklearnModelArtifact('model')]) @env : 파이썬 패키지, install script 등 서비스에 필요한 의존성을 정의 @artifacts : 서비스에서 사용할 artifact 정의 -&gt; Sklearn, XGboost, Pytorch 등 . . 12345678910111213class IrisClassifier(BentoService):       A minimum prediction service exposing a Scikit-learn model       @api(input=DataframeInput(), batch=True)  def predict(self, df: pd. DataFrame):           An inference API named `predict` with Dataframe input adapter, which codifies    how HTTP requests or CSV files are converted to a pandas Dataframe object as the    inference API function input           return self. artifacts. model. predict(df) BentoService를 상속하면 해당 서비스를 Yatai(모델 이미지 레지스터리)에 저장 @api : API 생성     Input과 Output을 원하는 형태(Dataframe, Tensor, JSON 등. . )으로 선택할 수 있음   Doc string으로 Swagger에 들어갈 내용을 추가할 수 있음    @artifacts에 사용한 이름을 토대로 self. artifacts. model로 접근Prediction Service에 저장(Pack): 123456789101112131415161718192021# bento_packer. py# 모델 학습from sklearn import svmfrom sklearn import datasetsclf = svm. SVC(gamma='scale')iris = datasets. load_iris()X, y = iris. data, iris. targetclf. fit(X, y)# bento_service. py에서 정의한 IrisClassifierfrom bento_service import IrisClassifier# IrisClassifier 인스턴스 생성iris_classifier_service = IrisClassifier()# Model Artifact를 Packiris_classifier_service. pack('model', clf)# Model Serving을 위한 서비스를 Disk에 저장saved_path = iris_classifier_service. save() Model Artifact를 주입   BentoML Bundle : Prediction Service를 실행할 때 필요한 모든 코드, 구성이 포함된 폴더, 모델 제공을 위한 바이너리   CLI에서 python bento_packer. py 실행 -&gt; Saved to ~ 경로가 보일 것임 BentoML에 저장된 Prediction Service 확인     bentoml list    BentoML에 저장된 Prediction Service 폴더로 이동 후 파일 확인     tree 명령어로 디렉토리 구조 확인 (tree -L 4)    bentoml. yml에 모델의 메타 정보, 패키지 환경, API input/output, Docs 등을 확인 할 수 있음Serving: Yatai Service 실행:  bentoml yatai-service-start localhost:3000Docker Image Build:  bentoml containerize IrisClassifier:latest -t iris-classifier docker images로 빌드된 이미지 확인-&gt; docker 명령이나 FastAPI를 사용하지 않고 웹 서버를 띄우고, 이미지 빌드! Bentoml Component:  BentoService Service Environment Model Artifact Model Artifact Metadata Model Management &amp; Yatai API Function and Adapters Model Serving Labels Retrieving BentoServices Web UIBentoService:  bentoml. BentoService는 예측 서비스를 만들기 위한 베이스 클래스 @bentoml. artifacts : 여러 머신러닝 모델 포함할 수 있음 @bentoml. api: Input/Output 정의     API 함수 코드에서 ```self. artifacts. {ARTIFACT_NAME}으로 접근 가능    파이썬 코드와 관련된 종속성 저장Service Enviroment:  파이썬 관련 환경, Docker 등을 설정 가능 @bentoml. env(infer_pip_packages=True) : import를 기반으로 필요한 라이브러리 추론 requirements_txt_file을 명시할 수 있음 pip_packages=[]를 사용해 버전을 명시할 수 있음 docker_base_image를 사용해 Base image를 지정 가능 setup_sh를 지정해 Docker Build 과정을 커스텀할 수 있음Model Artifact Metadata: Metadata 접근 방법    CLI      bentoml get model:version      REST API      bentoml serve 후, /metadata로 접근      python          123from bentoml import loadsvc = load('path_to_bento_service')print(svc. artifacts['model']. metadata)          Model Serving: BentoService가 Bento로 저장되면 여러 방법으로 배포할 수 있음!  Online Serving     클라이언트가 REST API Endpoint로 근 실시간으로 예측 요청    Offline Batch Serving     예측을 계산 후, Storage에 저장    Edge Serving     모바일, IoT device에 배포   Web UI:  @bentoml. web_static_content를 사용해 웹프론트엔드에 추가할 수 있음 참고:  https://github. com/zzsza Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://docs. bentoml. org/en/latest/overview/what-is-bentoml. html"
    }, {
    "id": 8,
    "url": "http://localhost:4000/MLFlow-1/",
    "title": "Introduction to MLflow",
    "body": "2023/07/07 - MLFlow로 해결할 Pain Point:  실험 추적이 어렵다 코드 재현이 어렵다 모델 패키징 및 배포가 어렵다 모델을 관리하기 위한 중앙 저장소가 없다그럼 MLFlow란?:  머신러닝 실험, 배포를 쉽게 관리할 수 있는 오픈 소스 CLI, GUI(웹 인터페이스) 지원Example: 123456789101112131415161718from sklearn import svm, datasetsfrom sklearn. model_selection import GridSearchCVimport mlflowdef main():  mlflow. sklearn. autolog()  iris = datasets. load_iris()  parameters = { kernel : ( linear ,  rbf ),  C : [1, 10]}  svc = svm. SVC()  clf = GridSearchCV(svc, parameters)  with mlflow. start_run() as run:    clf. fit(iris. data, iris. target)if __name__ ==  __main__ :  main()MLFlow의 핵심 기능:  Experiment Management &amp; Tracking     머신러닝 관련 실험들을 관리하고, 각 실험의 내용 기록         여러 사람이 하나의 mlflow 서버 위에서 각자 자기 실험을 만들고 공유 할 수 있음          실험을 정의하고 실험을 실행 할 수 있음, 실행은 머신러닝 훈련코드를 실행한 기록         각 실행에 사용한 소스코드, 하이퍼 파라미터, metric, 부산물(artifact, image. . ) 등을 저장           Model Registry     MLflow로 실행한 머신러닝 모델을 Model registry(모델 저장소)에 등록 가능   모델 저장소에 모델이 저장될 때마다 해당 모델에 버전이 자동으로 올라감   모델 저장소에 등록된 모델은 다른 사람들에게 쉽게 공유 가능    Model Serving     Model Registry에 등록한 모델을 REST API형태의 서버로 serving 가능   Input == 모델의 Input   Output == 모델의 Output   직접 도커 이미지를 만들지 않아도 생성 가능   MLflow Component:  MLflow Tracking     머신러닝 코드 실행, 로깅을 위한 api, ui   MLflow Tracking을 사용해 결과를 local, server에 기록해 여러 실행과 비교 가능   팀에선 다른 사용자의 결과와 비교하며 협업가능    MLflow Project     머신러닝 프로젝트 코드를 패키징하기 위한 표준   Project         간단하게 소스 코드가 저장된 폴더     Git repo     의존성과 어떻게 실행해야 하는지 저장          MLflow Tracking API를 사용하면 MLflow는 프로젝트 버전을 모든 파라미터와 자동으로 로깅    MLflow Model     모델은 모델 파일과 코드로 저장   다양한 플랫폼에 배포할 수 있는 여러 도구 제공   MLflow Tracking API를 사용하면 MLflow는 자동으로 해당 프로젝트에 대한 내용을 사용함    MLflow Registry     MLflow Model의 전체 lifecycle에서 사용할 수 있는 중앙 모델 저장소   MLflow 사용하기: pip install mlflow 1. Experiment 생성:  하나의 Experiment는 진행하고 있는 머신러닝 프로젝트 단위로 구성     개/고양이 분류 실험, 수요량 예측 실험 . .     정해진 Metric으로 모델 평가     RMSE, MSE, MAE, Accuracy. .     하나의 실험 여러개의 runmlflow experiments create --experiment-name my-first-experiment : Experiment 생성 ls -al로 mlruns 폴더 확인 mlflow experiments search : 생성한 experiments 목록 확인 (list는 현재 deprecated) pip install numpy sklearn : 모델에 필요한 라이브러리 설치 (상황 마다 바뀜) mkdir logistic_regression : 폴더 생성 vi logistic_regression/train. py : 머신러닝 코드 생성 train. py: 123456789101112131415161718192021222324import numpy as npfrom sklearn. linear_model import LogisticRegressionimport mlflowimport mlflow. sklearnif __name__ ==  __main__ :  X = np. array([-2, -1, 0, 1, 2, 1]). reshape(-1, 1)  y = np. array([0, 0, 1, 1, 1, 0])  penalty =  elasticnet   l1_ratio = 0. 1  lr = LogisticRegression(penalty=penalty, l1_ratio=l1_ratio, solver= saga )  lr. fit(X, y)  score = lr. score(X, y)  print( Score: %s  % score)   # auto 나오기 전에는 이렇게 사용했음  mlflow. log_param( penalty , penalty)  mlflow. log_param( l1_ratio , l1_ratio)  mlflow. log_metric( score , score)  mlflow. sklearn. log_model(lr,  model )2. MLProject:  Mlflow를 사용한 코드의 프로젝트 메타 정보 저장 프로젝트를 어떤 환경에서 어떻게 실행시킬지 정의 패키지 모듈의 상단에 위치 이름은 MLProject 라는 이름을 꼭 사용해야함vi logistic_regression/MLProject: MLProject 생성 #### MLProject 12345name: tutorialentry_points:  main:    command:  python train. py 3. Run:  하나의 Run은 코드를 1번 실행한 것을 의미 보통 Run은 모델 학습 코드를 실행 한번의 코드 실행 == 하나의 Run 생성 Run을 하면 여러가지 내용이 기록됨     source : 실행한 project의 이름   version : 실행 Hash   start &amp; end time   parameters : 모든 파라미터   metrics : 모델의 평가 지표, metric 시각화   tags   artifacts : 실행과정에서 생기는 다양한 파일들(이미지, 모델 피클 . . )   mlflow run logistic_regression --experiment-name my-first-experiment --env-manager {환경} : Run으로 실행 mlflow ui : UI 실헹 MLflow Autolog:  Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements.  파라미터를 매번 명시하는게 귀찮음 자동으로 로깅을 해줌 모든 프레임 워크에서 사용가능한 것은 아님!     pytorch. nn. Module 지원 x, pytorch lightning은 지원 . .    MLflow 배포하기: MLflow Architecture:  Python Code(with MLflow package)     모델을 만들고 학습하는 코드   MLflow run으로 실행    Tracking Server     파이썬 코드가 실행되는 동안 parameter, metric, model 등 메타 정보 저장   파일 혹은 DB에 저장         Tracking server는 결국 DB를 바라봄           Artifact Store     파이썬 코드가 실행되는 동안 생기는 model file, image 등의 아티팩트를 저장   파일 혹은 스토리지에 저장         Artifact Store는 결국 storage를 바라봄          mlflow server --backend-store-uri {uri} --default-artifact-root {} : mlflow server 명령어로 Backend Store URI 지정가능 MLflow 실제 Use Case: MLflow Tracking Server는 하나로 통합 운영  Tracking Server를 하나 배포하고, 팀 내 모든 리서처가 이 Tracking Server에 실험 기록     배포할 때는 Docker Image, Kubernetes 등에 진행(회사 인프라에 따라 다름)    로그나 모델이 한 곳에 저장되므로 팀 내 모든 실험을 공유 가능 Artifact Storage는 GCS나 S3 같은 스토리지 사용 DB는 CloudSQL이나 Aurora RDS 같은 DB 사용 두 저장소는 Tracking Server에 의해 관리 참고:  https://github. com/zzsza Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://mlflow. org/docs/latest/tracking. html"
    }, {
    "id": 9,
    "url": "http://localhost:4000/ApacheAirflow-1/",
    "title": "Introduction to Apache Airflow",
    "body": "2023/07/06 - Apache Airflow의 등장 배경: Batch Processing:  예약된 시간에 실행되는 프로세스 일회성 실행, 주기적인 실행 전부 가능     월요일날 7:00시에 한번 실행, 매주 월요일 7:00에 실행   ML, AI 엔지니어 관점에서의 Batch Processing:  모델을 주기적으로 학습시키는 경우(continuous training) 주기적인 Batch Serving을 하는 경우 그 외 개발에서 필요한 배치성 작업Airflow 등장 전의 Batch Process:  Linux Crontab으로 Batch Process 구축하는 경우 크론 표현식은 Batcj Process의 스케쥴링을 정의한 표현식     이 표현식은 다른 Batch Process 도구에서도 자주 사용됨    출처 - https://docs. aws. amazon. com/elemental-cl3/latest/apireference/channel-scheduling-cron-syntax-summary. html  ***** - Every minute 0**** - Every hour 00*** - Every day at 12:00 AM 00**FRI - At 12:00 AM, only on Friday   001** - At 12:00 AM, on day 1 of the month   https://crontab. cronhub. io/ http://www. cronmaker. com/ https://crontab. guru/Linux Crontab의 한계:  재실행 및 알람     파일을 실행하다 오류가 생긴 경우, 크론탭이 별도의 처리를 하지 않음    실패할 경우, retry 하거나 실패했다는 알람을 보내주는 기능이 필요 과거 실행 이력 및 실행 로그를 보기 어려움 여러 파일을 실행하거나, 복잡한 파이프라인을 만들기 어려움-&gt; 더 정교한 스케쥴링 및 워크플로우 도구가 필요함! 스케쥴링 도구들의 등장:  Luigi argo Apache Airflow Prefect MetaFlowApache Airflow 소개: 현재 스케쥴링, 워크플로우 도구의 표준  업데이트 주기 빠름 스케쥴링 도구로 무거울 수 있지만, 거의 모든 기능을 제공하고, 확장성이 넓어 일반적으로 스케쥴링과 파이프라인 작성 도구로 많이 사용 데이터 엔지니어링 팀에서 많이 사용Airflow의 기능:  파이썬을 사용해 스케쥴링 및 파이프라인 작성 실패 시 알람 실패 시 재실행 시도 동시 실행 워커 수 설정 및 변수 값 분리Airflow 사용해보기:  가상환경 설정12python -m venv . venvsource . venv/bin/activate Airflow 설치12pip install pip --upgradepip install 'apache-airflow==2. 2. 0' Airflow 기본 디렉토리 경로 지정export AIRFLOW_HOME=.  Airflow에서 사용할 DB 초기화airflow db init  DB를 초기화하면 기본 파일이 생성 ls -al로 확인 Airflow에서 사용할 어드민 계정 생성airflow users create --username admin --password 1234 --firstname seungki --lastname kim --role Admin --email {email}  Airflow Webserver 실행airflow webserver --port 8080  WebUI Dashboard 등장     스케쥴러가 실행중이지 않다는 에러가 보임    별도의 터미널을 띄워서 Airflow Scheduler 실행airflow scheduler  Web UI에서 관련 에러가 없어진 것을 확인할 수 있음DAG: Batch Scheduling을 위한 DAG 생성:  Airflow에서는 스케줄링할 작업을 DAG이라고 부름 DAG은 Directed Acyclic Graph의 약자로 Airflow에 한정된 개념이 아닌 소프트웨어 자료구조에서 일반적으로 다루는 개념 DAG은 이름 그대로 순환하지 않는 방향이 존재하는 그래프를 의미Airflow는 Crontab처럼 단순히 하나의 파일을 실행하는 것이 아닌, 여러 작업의 조합도 가능함  DAG 1개 : 1개의 파이프라인 Task : DAG 내에서 실행할 작업하나의 DAG에 여러 Task의 조합으로 구성 출처 - https://www. qubole. com/tech-blog/apache-airflow-tutorial-dags-tasks-operators-sensors-hooks-xcom example) tutorial_etl_dag라는 DAG은 3가지 Task로 구성  extract transform load -&gt; tutorial_etl_dag라는 DAG을 실행하면 이 3가지 Task을 순차적으로 실행함Task가 꼭 순차적으로 진행하지 않게 할 수도 있음 tutorial DAG  print_data Task 이후, sleep, templated Task 동시(병렬) 실행DAG 작성하기: DAG 작성:  DAG을 담을 디렉토리 생성(이름은 무조건 dags)mkdir dags  dags 폴더 내에 hello_world. py 생성hello_world. py 123456789101112131415161718192021222324252627282930313233343536373839404142434445# hello_world. pyfrom datetime import timedeltafrom airflow import DAGfrom airflow. utils. dates import days_agofrom airflow. operators. bash import BashOperatorfrom airflow. operators. python import PythonOperatordef print_world() -&gt; None:  print( world )# with 구문으로 DAG 정의를 시작합니다. with DAG(  dag_id= hello_world , # DAG의 식별자용 아이디입니다.   description= My First DAG , # DAG에 대해 설명합니다.   start_date=days_ago(2), # DAG 정의 기준 2일 전부터 시작합니다.   schedule_interval= 0 6 * * * , # 매일 06:00에 실행합니다.   tags=[ my_dags ], # 태그 목록을 정의합니다. 추후에 DAG을 검색하는데 용이합니다. ) as dag:  # 테스크를 정의합니다.   # bash 커맨드로 echo hello 를 실행합니다.   t1 = BashOperator(    task_id= print_hello ,    bash_command= echo Hello ,    owner= heumsi , # 이 작업의 오너입니다. 보통 작업을 담당하는 사람 이름을 넣습니다.     retries=3, # 이 테스크가 실패한 경우, 3번 재시도 합니다.     retry_delay=timedelta(minutes=5), # 재시도하는 시간 간격은 5분입니다.   )  # 테스크를 정의합니다.   # python 함수인 print_world를 실행합니다.   t2 = PythonOperator(    task_id= print_world ,    python_callable=print_world,    depends_on_past=True,    owner= heumsi ,    retries=3,    retry_delay=timedelta(minutes=5),  )  # 테스크 순서를 정합니다.   # t1 실행 후 t2를 실행합니다.   t1 &gt;&gt; t2 DAG 정의(이름, 태그)     언제부터 스케쥴링 할지   스케쥴링 간격은 어떻게 할 지    DAG 내 Task 정의     Task 정의는 Airflow의 Operator 클래스 사용   Airflow에는 다양한 Operator 클래스가 존재하며, 뒤에서 살펴봄         첫 번째 Task는 bash 커맨드 실행             Airflow에서 제공하는 BashOperator 사용       bash_command 파라미터에 bash로 실행할 커맨드 전달                두 번째 Tasksms Python 함수 실행             Airflow에서 제공하는 PythonOperator 사용       python_callable 파라미터에 실행할 파이썬 함수 전달                      Dag 내 Task간 순서 정하기     순서는 &gt;&gt;와 같은 형태로 표현   t1 (BashOperator) 실행 후, t2 (PythonOperator)를 실행   실행결과 확인:  파일을 저장하고, UI를 확인해보면 새로 생성한 DAG 보임   DAG 상세 페이지에서 DAG을 ON 상태로 변경   DAG Run의 첫 번째 Task 사각형을 눌러서 Log 버튼을 클릭해서 Log 확인 가능 특정 DAG Run의 기록을 지우고 다시 실행시키고 싶으면 Clear 실행Operator들 소개:  Airflow에서는 다양한 Operator를 제공 PythonOperator     파이썬 함수를 실행   함수 뿐 아니라, Callable한 객체를 파라미터로 넘겨 실행 가능   실행할 파이썬 로직을 함수로 생성한 후, PythonOperator로 실행    BashOperator     Bash 커맨드를 실행   실행해야할 프로세스가 파이썬이 아닌 경우에도 BashOperator로 실행 가능         shell script, scala file . .            DummyOperator     아무것도 실행하지 않음   DAG내에서 Task를 구성할 때, 여러 개의 Task의 Success를 기다려야 하는 복잡한 Task 구성에서 사용    SimpleHttpOperator     특정 호스트로 HTTP 요청을 보내고 Response로 반환   파이썬 함수에서 requests 모듈로 사용한 뒤 PythonOperator로 실행시켜도 무방    그 외     KubernetesOperator   OckerOperator   CustomOperator   등. .     클라우드 기능을 추상화한 Operator도 존재함(AWS, GCP . . )     provider packages   Third Party와 연동해 사용하는 Operator의 경우 Airflow 설치 시에 다음처럼 extra package를 설치해야 함   추가적으로 학습 할 내용:  Variable Connections &amp; Hooks Sensor Marker XComsAirflow Architecture: https://airflow. apache. org/docs/apache-airflow/stable/core-concepts/overview. html DAG Directory:  DAG 파일들을 저장 DAG_FOLDER Scheduler에 의해 . py 파일은 모두 탐색되고 DAG에 파싱Scheduler:  각종 메타 정보의 기록을 담당 DAG들의 스케쥴링 관리 실행 진행 상황과 결과를 DB에 저장 Executer를 통해 실제로 스케쥴링된 DAG을 실행 Airflow의 가장 핵심적인 componentScheduler - Executer:    스케쥴링된 DAG을 실행하는 객체, 크게 2개로 나뉨   Local Executer     DAG Run을 프로세스 단위로 실행하며, 다음 처럼 나뉨         Local             하나의 DAG Run을 프로세스로 띄워서 실행       최대로 생성할 프로세스 수를 정해야 함       Airflow를 간단하게 운영할 때 적합                Sequential             하나의 프로세스에서 모든 DAG Run들을 처리       Airflow 기본 Executer, 별도 설정이 없으면 이것을 사용       테스트용으로 잠시 운영할 때 적합                      Remote Executer     DAG을 외부 프로세스로 실행         Celery             DAG Run을 Celery Work Process로 실행       보통 Redis를 중간에 두고 같이 사용       Local Executer를 사용하다 Airflow 운영 규모가 좀 더 커지면 Celery Executor로 전환                Kubernetes             쿠버네티스 상에서 Airflow를 운영할 때 사용       DAG Run 하나가 하나의 Pod(컨테이너 같은 개념)       운영 규모가 큰 팀에서 사용                     Workers:  DAG을 실제로 실행 Scheduler에 의해 생기고 실행 Executer에 따라 워커의 형태가 다름     Celery, Local Executer의 경우 Worker는 Process   Kubernetes의 경우 Worker는 Pod    Dag Run을 실행하는 과정에서 생기는 로그를 저장Metadata Database:  메타 정보를 저장 Scheduler에 메타 정보가 쌓임 보토 MySQL이나 Postgres를 사용 파싱한 DAG 정보, DAG Run 상태와 실행 내용, Task 정보 등을 저장 User와 Role(RBAC)에 대한 정보 저장 Scheduler와 더불어서 핵심 컴포넌트 트러블 슈팅 시, 디버깅을 위해 직접 DB에 연결해서 데이터를 확인하기도 함 실제 운영 환경에서는 GCP Cloud SQL이나 AWS Aurora DB 등. . 외부 DB 인스턴스를 사용WebServer:  WebUI를 담당 Metadata DB와 통신하며 유저에게 필요한 메타정보를 웹 브라우저에 보여주고 시각화 보통 Airflow 사용자들은 이 웹서버를 이용하여 DAG을 ON/OFF 하면서, 현 상황 파악 REST API도 제공하기 때문에, Web UI를 통해서 통신하지 않아도 괜찮음 웹서버가 당장 작동하지 않아도 Airflow에 큰 장애가 발생하는 것은 아님실제 Airflow 구축 및 활용: Airflow를 구축하는 방법은 보통 3가지 방법을 사용함  Managed Airflow (GCP Composer, AWS MWAA)     클라우드 서비스 형태로 Airflow를 사용하는 방법   장점         설치와 구축을 클릭 몇번으로 클라우드 서비스가 진행     유조는 DAG 파일을 스토리지(업로드) 형태로 관리          단점         비용     자유도가 적음, 제약이 많음           VM + Docker Compose     직접 VM 위에서 Docker Compose로 Airflow를 배포하는 방법   Airflow 구축에 필요한 컴포넌트(Scheduler, Webserver, Database. . )를 Docker 컨테이너 형태로 배포   장점         Managed Service 보다는 조금 복잡하지만, 어려운 난이도는 아님     Docker Compose에 익숙하면 금방 익힐 수 있음     하나의 VM만을 이용하기 때문에 단순          단점         각 Docker 컨테이너 별로 환경이 다르기 때문에, 관리 포인트가 늘어남           Kubernetes + Helm     Helm 차트로 Airflow를 배포하는 방법   Kubernetes는 여러 개의 VM을 동적으로 운영하는 일종의 분산환경, 리소스 사용이 매우 유연함(Scalability가 좋음)   특정 시간에 배치 프로세스를 실행시키는 Airflow와 궁합이 매우 잘 맞음   Airflow DAG 수가 몇 백개로 늘어나도 노드 오토 스케일링으로 모든 프로세스를 잘 처리할 수 있음   쿠버네티스 자체가 난이도가 있음 -&gt; 구축, 운영이 어려움    출처 - https://tech. socarcorp. kr/data/2021/06/01/data-engineering-with-airflow. html MLOps 관점에서의 Airflow: 데이터 엔지니어링에서 많이 쓰이지만, MLOps에서도 활용가능  주기적인 실행이 필요한 경우     Batch Training : 1주일 단위로 모델 학습   Batch Serving(Batch Inference) : 30분 단위로 인퍼런스   인퍼런스 겨로가를 기반으로 일자별, 주차별 모델 퍼포먼스 Report 생성   MySQL에 저장된 메타 데이터를 데이터 웨어하우스로 1시간 단위로 옮기기   S3, GCS 등 Object Storage   Feature Store를 만들기 위해 Batch ETL 실행    참고:  https://github. com/zzsza Naver Connection AI Tech 5th - Product Serving(변성윤)"
    }, {
    "id": 10,
    "url": "http://localhost:4000/Logging/",
    "title": "Logging",
    "body": "2023/07/05 - Logging:  사용자 로그 데이터, 이벤트 로그 데이터 . .  머신러닝 인퍼런스 요청 로그, 인퍼런스 결과 등을 저장해야 함데이터의 종류: 데이터베이스 데이터(서비스 로그):  Database에 저장되는 데이터 서비스가 운영되기 위해 필요한 데이터     고객 가입일, 물건 구입 내역 등. .    사용자 행동 데이터(유저 행동 로그):  Object storage, Data Warehouse에 주로 저장 유저 로그라고 지칭하면 보통 사용자 행동 데이터를 의미 서비스에 반드시 필요한 내용은 아니지만, 더 좋은 제품을 만들기 위해 또는 데이터 분석시 필요한 데이터 앱이나 웹에서 유저가 어떤 행동을 하는지 나타내는 데이터 UX와 관련해서 인터랙션이 이루어지는 관점에 발생하는 데이터     click, view, swipe . .    인프라 데이터(Metric):  백엔드 웹 서버가 제대로 동작하고 있는지 확인하는 데이터 request 수, response 수 DB 부하 트래픽Metric, Log, Trace:  Metric     값을 측정할 때 사용   cpu, memory 사용량    Log     운영 관점에서 알아야하는 데이터를 남길 때 사용   함수의 호출, 예외 처리 등. .     Trace     개발 관점에서 알아야하는 것   예외 trace   데이터 적재 방식: Database(RDBMS):  데이터가 다시 웹, 앱 서비스에서 사용되는 경우 활용 실제 서비스용 DB구체적으로 들어가면  관계형 데이터베이스(relational) 행과 열로 구성 데이터의 관계를 정의하고, 데이터 모델링 진행 비즈니스와 연관된 중요한 정보     고객 정보, 주문 요청, 내역 . .     영구적으로 저장해야 하는 것은 데이터베이스에 저장 데이터 추출시 SQL 사용 MySQL, PostgreSQL . . https://www. stechies. com/differences-between-dbms-rdbms/ Naver Boostcamp AI Tech 5th - Product Serving Database(NoSQL):  Elasticsearch, Logstash or Fluent, Kibana에서 활용하는 경우구체적으로 들어가면  스키마가 strict한 RDBMS와 다르게 스키마가 없거나 느슨함 Not Only SQL 데이터가 많아지며 RDBMS로 트래픽을 감당하기 어려워서 개발됨 일반적으로 RDBMS에 비해 쓰기와 읽기 성능이 빠름 Key Value store, document, column family, graph . .  json 형태와 비슷하며 xml 등도 활용됨 MongoDBSQL vs NoSQL: https://expeed. com/when-to-use-sql-databases-vs-nosql-databases-making-the-right-decision/ Object Storage:  S3, Cloud Storage에 파일 형태로 저장 csv, parquet, json . .  별도로 DB나 warehouse로 옮기는 작업이 필요함구체적으로 들어가면  어떤 형태의 파일이여도 저장할 수 있는 저장소 특정 시스템에 발생하는 로그를 xxx. log에 저장한 후, object storage에 저장하는 형태 비즈니스에서 사용되지 않는 분석을 위한 데이터 이미지, 음성 등을 저장Data Warehouse:    데이터 분석시 활용하는 데이터 웨어하우스로 바로 저장   여러 공간에 저장된 데이터를 한곳으로 저장 데이터 창고 같은 느낌으로 알면 편함 RDBMS, NoSQL, Object Storage 등에서 저장한 데이터를 한 곳으로 옮겨서 처리 RDBMS와 같은 SQL을 사용하지만 성능이 더 좋은 편 AWS Redshift, GCP BigQuery, Snowflake . . Print vs Logging:  print는 콘솔에만 output을 출력하는 경우로 생각하자 logging은 file, web socket 등 파이썬이 다룰 수 있는 모든 포맷으로 output 출력 가능     언제 어디서 해당 output의 발생을 알 수 있음    심각도에 따른 분류를 할 수 있음     develop 환경에서는 debug로그 까지, production 환경에서는 info 로그만   12345678910111213141516171819202122232425262728#### 1. logging module 써보기import logginglogger = logging. getLogger( example ) # root loggerlogger. info( hello world ) # 아무런 로그도 출력되지 않습니다. #### 1. 1 logging module config 추가하기import logging. configlogger_config = {   version : 1, # required   disable_existing_loggers : True, # 다른 Logger를 overriding 합니다   formatters : {     simple : { format :  %(asctime)s | %(levelname)s - %(message)s },  },   handlers : {     console : {       level :  DEBUG ,       class :  logging. StreamHandler ,       formatter :  simple ,    }  },   loggers : { example : { level :  INFO ,  handlers : [ console ]}},}logging. config. dictConfig(logger_config)logger_with_config = logging. getLogger( example )logger_with_config. info( 이제는 보이죠? ) Config 설정을 해야 output 출력 지정한 로그 포맷 형태로 로그 출력  format :  %(asctime)s | %(levelname)s - %(message)s  https://docs. python. org/3/library/logging. htmlPython Logging Component: Logger:  로그를 생성하는 method 제공(logger. info(), . . ) 로그 level과 logger에 적용된 filter를 기반으로 처리해야 하는 로그인지 판단 handler에게 logrecord 인스턴스 전달 logging. getLogger(name)으로 Logger Object 사용     name이 주어지면 해당 name의 logger 사용   name이 없으면 root logger 사용   마침표로 구분되는 계층 구조         logging. getLogger('foo. bar') -&gt; logging. getLogger('foo')의 자식 logger 반환           logging. setLevel() : Logger에서 사용할 level 지정Handler:  Logger에서 만들어진 log를 적절한 위치로 전송(파일 또는 콘솔 출력. . ) level과 formatter를 각각 설정해서 필터링 할 수 있음 StreamHandler, FileHandler, HTTPHandler . .  https://www. toptal. com/python/in-depth-python-logging  Formatter     최종적으로 log에 출력될 포맷 설정   시간, logger 이름, 심각도, output, 함수 이름, line 정보, 메세지 . .    Logging Flow:  https://docs. python. org/ko/3/howto/logging. html Online Serving Logging (BigQuery): BigQuery에 Online Serving Input과 Output 로그를 적재하는 과정  빅쿼리 테이블을 세팅 빅쿼리에 적재하기 쉽게 json 형태로 로그를 정제 -&gt; pythonjsonlogger 사용 Python logging 모듈을 사용해서 빅쿼리에 실시간으로 로그 적재(file과 console에도 남을 수 있도록 handle 지정)BigQuery Data Structure:  https://jayendrapatil. com/google-cloud-bigquery/  GCP의 project 내부에 BigQuery 리소스가 존재 Dataset 안에 Table, Views . . 참고:  https://github. com/zzsza Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤)"
    }, {
    "id": 11,
    "url": "http://localhost:4000/FastAPI-2/",
    "title": "FastAPI - 2",
    "body": "2023/07/04 - Event Handler:  이벤트가 발생했을 때, 그 처리를 담당하는 함수 FastAPI 에선 Application을 실행, 종료할 때 특정 함수를 실행할 수 있음``` @app. on_event( shutdown )```* startup 할 때 머신러닝 모델 load* shutdown 할 때 로그 저장```pythonfrom fastapi import FastAPIimport uvicornapp = FastAPI()items = {}@app. on_event( startup )def startup_event():  print( Start Up Event )  items[ foo ] = { name :  Fighters }  items[ bar ] = { name :  Tenders }@app. on_event( shutdown )def shutdown_event():  print( Shutdown Event! )  with open( log. txt , mode= a ) as log:    log. write( Application shutdown )@app. get( /items/{item_id} )def read_items(item_id: str):  return items[item_id]API Router:  API router는 더큰 애플리케이션들에서 많이 사용되는 기능 API endpoint를 정의 Python subpackage 모듈   API router는 mini FastAPI로 여러 API를 연결해서 사용   기존에 사용하던 @app. get @app. post를 사용하지 않고, router 파일을 따로 설정하고 app에 import 해서 사용함123456789101112131415161718192021222324252627282930313233343536from fastapi import FastAPI, APIRouterimport uvicornuser_router = APIRouter(prefix= /users )order_router = APIRouter(prefix= /orders )@user_router. get( / , tags=[ users ])def read_users():  return [{ username :  Rick }, { username :  Morty }]@user_router. get( /me , tags=[ users ])def read_user_me():  return { username :  fakecurrentuser }@user_router. get( /{username} , tags=[ users ])def read_user(username: str):  return { username : username}@order_router. get( / , tags=[ orders ])def read_orders():  return [{ order :  Taco }, { order :  Burritto }]@order_router. get( /me , tags=[ orders ])def read_order_me():  return { my_order :  taco }@order_router. get( /{order_id} , tags=[ orders ])def read_order_id(order_id: str):  return { order_id : order_id}app = FastAPI()if __name__ == '__main__':  app. include_router(user_router)  app. include_router(order_router)  uvicorn. run(app, host= 0. 0. 0. 0 , port=8000) user router, order router 2개 생성 app에 연결 - include_router 실제 활용한다면 하나의 파일에 저장하지 않고 각각 저장해서 사용     user. py, order. py   프로젝트 구조 예제: Error Handling:  웹 서버를 안정적으로 운영하기 위해 반드시 필요한 주제 서버에서 Error가 발생한 경우, 어떤 Error가 발생했는지 알아야하고, 해당 클라이언트에 해당 정보를 전달해 대응할 수 있어야 함 서버 개발자는 모니터링 도구를 사용해 Error Log 수집 발생하고 있는 오류를 빠르게 수정할 수 있도록 예외 처리를 잘 만들 필요가 있음12345678910111213141516171819202122from fastapi import FastAPI, HTTPExceptionimport uvicornapp = FastAPI()items = {  1:  Boostcamp ,  2:  AI ,  3:  Tech }@app. get( /v1/{item_id} )async def find_by_id(item_id: int):  return items[item_id]@app. get( /v2/{item_id} )async def find_by_id(item_id: int):  try:    item = items[item_id]  except KeyError:    raise HTTPException(status_code=404, detail=f 아이템을 찾을 수 없습니다 [id: {item_id}] )  return item item_id가 1~3 까진 정상 4이상의 숫자가 들어올 경우 key error가 발생   Internal Server Error, 500 return   클라이언트는 어떤 에러가 난 것인지 정보를 모름 자세한 에러를 보려면 서버에 직접 접근해서 로그를 확인해야 함   에러 핸들링을 위해서는 에러 메세지와 에러의 이유 등을 클라이언트에 전달하도록 코드를 잘 작성해야 함   FastAPI의 HTTPException은 Error response를 더 쉽게 봴 수 있도록 하는 클래스 HTTPException을 이용해서 클라이언트에게 더 자세한 에러 메세지를 보내는 코드 작성Background Task:  FastAPI는 Starlett이라는 비동기 프레임워크를 래핑해서 사용   Background Task 기능은 오래 걸리는 작업들을 background에서 실행 함   CPU 사용이 많은 작업들을 background로 실행하면, 클라이언트는 작업 완료를 기다리지 않고 즉시 response를 받아볼 수 있음     Example) 특정 작업 후 이메일 전송   123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110# 1. simple long-running tasksimport contextlibimport jsonimport threadingimport timefrom datetime import datetimefrom time import sleepfrom typing import Listimport requestsimport uvicornfrom fastapi import FastAPI, BackgroundTasksfrom pydantic import BaseModel, Fieldclass Server(uvicorn. Server):  def install_signal_handlers(self):    pass  @contextlib. contextmanager  def run_in_thread(self):    thread = threading. Thread(target=self. run)    thread. start()    try:      while not self. started:        time. sleep(1e-3)      yield    finally:      self. should_exit = True      thread. join()def run_tasks_in_fastapi(app: FastAPI, tasks: List):       FastAPI Client를 실행하고, task를 요청합니다  Returns:    List: responses       config = uvicorn. Config(app, host= 127. 0. 0. 1 , port=5000, log_level= error )  server = Server(config=config)  with server. run_in_thread():    responses = []    for task in tasks:      response = requests. post( http://127. 0. 0. 1:5000/task , data=json. dumps(task))      if not response. ok:        continue      responses. append(response. json())  return responsesapp_1 = FastAPI()def cpu_bound_task(wait_time: int):  sleep(wait_time)  return f task done after {wait_time} class TaskInput(BaseModel):  wait_time: int = Field(default=1, le=10, ge=1)@app_1. post( /task )def create_task(task_input: TaskInput):  return cpu_bound_task(task_input. wait_time)tasks = [{ wait_time : i} for i in range(1, 10)]start_time = datetime. now()run_tasks_in_fastapi(app_1, tasks)end_time = datetime. now()print(f Simple Tasks: Took {(end_time - start_time). seconds} )# 2. background tasksapp_2 = FastAPI()@app_2. post( /task ,      status_code=202) # 비동기 작업이 등록됐을 때, HTTP Response 202 (Accepted)를 보통 리턴합니다. https://developer. mozilla. org/en-US/docs/Web/HTTP/Status/202async def create_task_in_background(task_input: TaskInput, background_tasks: BackgroundTasks):  background_tasks. add_task(cpu_bound_task, task_input. wait_time)  return  ok start_time = datetime. now()run_tasks_in_fastapi(app_2, tasks)end_time = datetime. now()print(f Background Tasks: Took {(end_time - start_time). seconds} )# 3. background tasks with in-memory task repofrom uuid import UUID, uuid4app_3 = FastAPI()class TaskInput2(BaseModel):  id_: UUID = Field(default_factory=uuid4)  wait_time: inttask_repo = {}def cpu_bound_task_2(id_: UUID, wait_time: int):  sleep(wait_time)  result = f task done after {wait_time}   task_repo[id_] = result@app_3. post( /task , status_code=202)async def create_task_in_background_2(task_input: TaskInput2, background_tasks: BackgroundTasks):  background_tasks. add_task(cpu_bound_task_2, id_=task_input. id_, wait_time=task_input. wait_time)  return task_input. id_@app_3. get( /task/{task_id} )def get_task_result(task_id: UUID):  try:    return task_repo[task_id]  except KeyError:    return None Background Task를 사용하지 않은 작업들은 작업 시간 만틈 응답을 기다려야 함 작업 결과물을 조회할 때는 task를 어딘가에 저장해두고, GET 요청을 통해 task가 완료됐는지 확인     GET을 통해 리소스가 있는 확인   FastAPI 학습: 프로젝트 구조:  Cookiecutter 프로젝트 구조에 대한 템플릿 공유 https://github. com/cookiecutter/cookiecutter CLI 형태로 프로젝트 생성 과정을 도와줌   개인용 템플릿을 만들어보는 것도 좋은 방법(개인 설정 템플릿화)   처음 진행은 스크래치 부터 작성해서 익숙해지기 익숙해지고 다른 프로젝트 구조 참고 클린 아키텍쳐 관련 책 보면서 고민하기객체 지향:  현재 가지고 있는 코드를 Class로 변경해보기 pydantic Use Case 찾아보기Trial and Error:  코드 작성 -&gt; 수정 -&gt; 코드 작성 반복 작은 규모의 프로젝트부터 하나씩 만들어보기     기능 정의 후 하나씩 구현   명확한 목표    참고:  https://github. com/zzsza Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://fastapi. tiangolo. com/ko/"
    }, {
    "id": 12,
    "url": "http://localhost:4000/FastAPI-1/",
    "title": "FastAPI - 1",
    "body": "2023/07/04 -  FastAPI:  최근 떠오르는 Python Web Framework API document 작성을 자동으로 해주는 Swagger 간결한 코드 작성 빠른 속도 출처 - https://quintagroup. com/services/python/fastapi Path Parameter, Query Parameter:  웹에서 get method를 사용해 데이터를 전송할 수 있음 ID가 402인 사용자 정보를 가져오고 싶은 경우Path Parameter 방식:  /users/402  서버에 402라는 값을 전달하고 변수로 사용Query Parameter 방식:  /users?id=402  Query String API뒤에 입력 데이터를 함께 제공하는 방식으로 사용 Query String은 Key, Value의 쌍으로 이루어지며 &amp;로 연결해 여러 데이터를 넘길 수 있음Path vs Query:  언제 어떤 방식을 사용해야 할까? 상황마다 다름Example1):  어떤 리소스를 식별하고 싶은 경우(그러나 kyle이라는 유저가 없음) Path : /users/Kyle     경로에 존재하는 내용이 없으면 404 에러 발생    Query : /users?name=kyle     데이터가 없는 경우 빈 리스트 -&gt; 추가적인 에러 핸들링   보편적인 경우  리소스 식별 : Path parameter가 적합 정렬, 필터링 : Query parameter가 적합 Path Parameter:  GET method : 정보를 Read하기 위해 사용 유저 정보에 접근하는 API12345678from fastapi import FastAPIimport uvicornapp = FastAPI()@app. get( /users/{user_id} )def get_user(user_id):  return { user_id : user_id} FastAPI는 데코레이터로 GET, POST 표시 @app. get, @app. post GET method의 인자로 있는 {user_id}가 함수의 값으로 인풋 Query Parameter:  URL뒤에 ? 붙이고 Key, Value 형태로 연결 Localhost:8000/items/?skip=0&amp;limit=10uvicorn main:app --reload 1234567891011from fastapi import FastAPIimport uvicornapp = FastAPI()# DB 같은 느낌으로 사용fake_items_db =[{ item_name :  Foo }, { item_name :  Bar }, { item_name :  Baz }]@app. get( /items/ )def read_items(skip: int = 0, limit: int = 10):  return fake_items_db[skip:skip+limit]Optional Path:  특정 파라미터는 선택적으로 사용하고 싶은 경우 Typing 모듈의 Optional 사용 Optional을 이용해 이 파라미터는 Optional 임을 명시Request Body:  클라이언트에서 API에 데이터를 보낼 때 request body 사용     client -&gt; API : request body   API response -&gt; client : response body    Request body에 데이터가 항상 포함되어야 하는 것은 아님 Request body에 데이터를 보내고 싶다면 POST Method 사용     GET Method는 URL, Request header로 데이터 전달    POST Method는 Request body에 데이터를 넣어 보냄 Body의 데이터를 설명하는 content-type Header field 존재, 데이터 타입 명시 해야함     Application/x-www-form-urlencoded: BODY에 Key, Value 사용   Text/plain : 단순 txt 파일   Multipartform-data : 데이터를 바이너리 데이터로 전송   1234567891011121314151617from typing import Optionalfrom fastapi import FastAPIimport uvicornfrom pydantic import BaseModelclass Item(BaseModel):  name: str  description: Optional[str] = None  price: float  tax: Optional[float] = None  app = FastAPI()@app. post( /items/ )def create_item(item: Item):  return item POST 요청으로 item을 생성하는 예제 pydantic으로 request body 데이터 정의 Type hinting에 위에서 생성한 클래스 주입 request body 데이터를 validationResponse Body:  API response -&gt; client : response body 데코레이터의 response_model 인자로 주입 가능12345678910111213141516171819202122from typing import Optionalfrom fastapi import FastAPIimport uvicornfrom pydantic import BaseModelclass ItemIn(BaseModel):  name: str  description: Optional[str] = None  price: float  tax: Optional[float] = None  class ItemOut(BaseModel):  name: str  price: float  tax: Optional[float] = None  app = FastAPI()@app. post( items/ , response_model=ItemOut)def create_item(item: ItemIn):  return item Output 데이터를 해당 정의에 맞게 변형 데이터 validation response에 대한 JSON Schema 추가 자동으로 문서화Form:  Form 입력 형태로 데이터를 받고 싶은 경우 Form을 사용하려면 pip install python-multipart 으로 설치     +간단한 프론트를 위한 pip install Jinja2   123456789from fastapi import FastAPI, Formimport uvicornapp = FastAPI()@app. post( /login )# Form에서 입력된 값을 가져와서 사용한다def login(username: str = Form(. . . ), password: str = Form(. . . )):  return { username : username} Form 클래스를 사용하면 request의 form data에서 값을 가져옴 Localhost:8000/login/ 으로 이동     login으로 접근해서 GET method가 요청됨   123456789101112131415from fastapi import FastAPI, Form, Requestfrom fastapi. templating import Jinja2Templatesimport uvicornapp = FastAPI()template = Jinja2Templates(directory= . / )@app. get( /login/ )def get_login_form(request: Request):  # login_form. html for frontend login page  return template. TemplateResponse( login_form. html , context={ request : request})@app. post( /login/ )def login(username: str = Form(. . . ), password: str = Form(. . . )):  return { username : username} login_form. html 로 login 페이지 구성 제출을 누르면 login 함수 실행(POST 요청) Form(…) -&gt; Python ellipsis, 필수적인 요소를 의미     FastAPI 웹 서버 실행 후 Swagger로 이동하면 required를 볼 수 있음   File:  File 업로드의 경우 Python-multipart 설치 필요1234567891011121314151617181920212223242526272829303132from typing import Listfrom fastapi import FastAPI, File, UploadFilefrom fastapi. responses import HTMLResponseimport uvicornapp = FastAPI()@app. post('/files/')def create_files(files: List(Bytes) = File(. . . )):  return {'file_sizes': [len(file) for file in files]}@app. post('/uploadfiles/')def create_upload_files(files: List(UploadFile) = File(. . . )):  return {'filenames': [file. filename for file in files]}@app. get('/')def main():  content =    &lt;body&gt;&lt;form action= /files/  method= post  enctype= multipart/form-data &gt;&lt;input type= file  name= files  multiple&gt;&lt;input type= submit &gt;&lt;/form&gt;&lt;form action= /uploadfiles/  method= post  enctype= multipart/form-data &gt;&lt;input type= file  name= files  multiple&gt;&lt;input type= submit &gt;&lt;/form&gt;&lt;/body&gt;     return HTMLResponse(content) ”/”로 접근할 때 보여줄 HTML 코드 HTML에서 action으로 넘김 파일을 bytes로 표현 여러 파일은 List에 설정Pydantic:  FastAPI에서 Class를 사용할 때 Data validation / Setting management 라이브러리 Type Hint를 런타임에서 강제해 안전하게 데이터 핸들링 파이썬 기본 타입(str, int . . ) + List, Dict, Tuple 에 대한 validtation 지원 기존 validation 라이브러리 보다 빠름 config를 효과적으로 관리 머신러닝 feature data validation으로도 활용 가능Validation: Machine learning model의 input을 validation 하는 경우 Online serving에서 input 데이터에 대한 validation    여러가지 validation을 하는 로직이 있을 수 있음     사용할 수 있는 방법은 Python class, Dataclass, Pydantic  Pydantic Config:  Validation 처럼 pydantic은 BaseSettings를 상속한 클래스에서 Type Hint로 주입된 설정 데이터를 검증할 수 있음 Field 클래스의 env 인자로, 환경 변수로 부터 해당 필드를 오버라이딩 가능 yaml, ini 파일들을 추가적으로 만들지 않고, . env 파일들을 환경변수로 만들어 두거나, 실행 환경에서 유연하게 오버라이딩 할 수 있음 참고:  https://github. com/zzsza Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤)"
    }, {
    "id": 13,
    "url": "http://localhost:4000/Backend/",
    "title": "Introduction to Backend",
    "body": "2023/07/03 - 서버 구성 Use Case:  앱/웹 서비스의 서버 머신러닝 서버 하나의 큰 서버가 사용 영역 별로 분할 되어 사용되는 경우 서비스 서버에서 머신러닝 서버로 예측 요청하며 통신하는 경우서버의 형태: 모놀로식 아키텍쳐(Monolothic Architecture):  하나의 큰 서버 모든 것을 하나의 큰 서버에서 처리 전체 서버를 배포해야해서 배포가 느림 마이크로 서비스 아키텍쳐(Micro Service Architecture - MSA):  개별의 서버로 구성하고 서로 통신하도록 하는 경우Rest API:  REST API는 정보를 주고 받을 때 널리 사용되는 형식으로 생각하면 된다 REST라는 형식의 API     각 요청이 어떤 동작이나 정보를 위한 것을 요청 모습 자체로 추론 할 수 있음   기본적인 데아터 처리 CRUD : Create, Read, Update, Delete    Representational State Transfer의 약자     Resource, Method, Representation of Resource로 구성    클라이언트 : 요청을 하는 플랫폼     브라우저 같은 웹   앱   우리가 파이썬을 사용해 요청하는 것도 클라이언트    Resource : Unique한 ID를 가지는 리소스, URI Method : 서버에 요청을 보내기 위한 방식 : GET, POST, PUT, PATCH, DELETEURI, URL:  URL : Uniform Resource Locator, 인터넷 상 자원의 위치 URI : Uniform Resource Identifier, 인터넷 상의 자원을 식별하기 위한 문자열의 구성 URI는 URL을 포함, URI &gt; URLHTTP Method: GET vs POST:  GET : 정보 요청을 위해 사용(Read)     어떤 정보를 가져와서 조회하기 위해 사용되는 방식   URL에 변수(데이터)를 포함시켜서 요청함   데이터를 헤더에 포함하여 전송함   URL에 데이터가 노출되어 보안에 취약   캐싱할 수 있음(다른 방법과 비교해서 빠를 수 있음)      POST : 정보를 입력하기 위해 사용(Create)      데이터를 서버로 제출해 추가 또는 수정하기 위해 사용하는 방식   URL에 변수(데이터)를 노출하지 않고 요청   데이터를 Body에 포함   URL에 데이터가 노출되지 않아 기본 보안은 되어 있음   캐싱 불가능(그 안에 아키텍쳐로 캐싱은 가능함)    출처 - https://stackoverflow. com/questions/43934585/which-http-method-get-or-post-i-should-use-for-creating-php-restfull-login-api PUT, PATCH, DELETE:  PUT : 정보를 업데이트하기 위해 사용(Update) PATCH : 정보를 업데이트하기 위해 사용(Update) DELETE : 정보를 삭제하기 위해 사용(Delete)Header, Body:  Http 통신은 Request를 하고, Response를 받을 때 정보를 Packet(패킷)에 저장   Packet 구조: Header/Body   Header : 보내는 주소, 받는 주소, 시간 Body : 실제 전달하려는 내용 Status Code:    클라이언트의 요청에 따라 서버가 어떻게 반응하는지 알려주는 코드   1xx : 요청을 받았고, 프로세스를 진행함 2xx : 요청을 성공적으로 받았고 실행함 3xx : 요청 완료를 위한 추가 작업 필요 4xx : 요청 문법이 잘못되었거나 요청을 처리할 수 없음 5xx : 서버가 요청에 대해 실패함동기와 비동기(Sync, Async): 동기(Sync):  서버에서 요청을 보냈을 때, 응답이 돌아와야 다음 동작을 수행 할 수 있음. A 작업이 모두 완료될 때까지 B 작업은 대기비동기(Async):  요청을 보낼 때 응답 상태와 상관없이 다음 동작을 수행함. A 작업과 B 작업이 동시에 실행됨상황에 따라 동기적, 비동기적으로 구현할건지 정하면 됨 IP:  네트워크에 연결된 특정 PC주소를 나타내는 체계 Internet Protocol 4그룹의 숫자로 구성된 IP 주소 체계를 IPv4라고 함 각 그룹마다 0~255로 나타낼 수 있음용도가 정해진 경우:  localhost, 127. 0. 0. 1 : 현재 사용중인 local PC 0. 0. 0. 0, 255. 255. 255. 255 : broadcast address, 로컬 네트워크에 접속된 모든 장치와 소통하는 주소 개인 PC보급으로 누구나 PC를 사용해 IPv4로 할당할 수 있는 한계점을 진입해서 IPv6 등장Port(포트):  IP주소 뒤에서 나오는 숫자 PC에 접속할 수 있는 통로(채널) 사용중인 포트는 중복 불가 Example) 주피터 노트북은 8888 포트는 0~65535까지 존재 0~1024는 통신을 위한 규약에 정해짐 Example)     22 : SSH   80 : HTTP   443 : HTTPS    참고:  https://github. com/zzsza Naver Connection AI Tech 5th - Product Serving(변성윤) https://geekflare. com/backend-solutions-for-web-and-mobile-apps/"
    }, {
    "id": 14,
    "url": "http://localhost:4000/CICD/",
    "title": "CI/CD Basic - 1",
    "body": "2023/07/02 -  개발 환경: Local:  각자의 컴퓨터에서 개발 각 환경을 통일 시키기 위해 docker 또는 pyenv, venv 사용Development:  Local에서 개발한 기능을 테스트 하는 환경 테스트 서버Staging:  Production 환경에 배포하기 전에 운영하거나 보안, 성능을 측정하는 환경 Staging 서버Production:  실제 서비스를 운영하는 환경 운영 서버개발 환경을 나누는 것은 실제 운영중인 서비스에 장애가 생기는 것을 방지하기 위함. 만약에 dev, staging, production 환경이 동일하다면 소스 코드를 저장하는 즉시 반영이 된다고 생각하면 됨.  CI/CD란?: Continuous Integration(지속적 통합):  새로 작성한 코드 변경 사항이 Build, Test를 진행한 후 Test Case를 통과하는지 확인 지속적으로 코드 품질 관리Continuous Delivery, Deployment(지속적 배포):  작성한 코드가 신뢰 가능한 상태가 되면(CI를 통과하면) 자동으로 배포될 수 있도록 하는 과정 CI 이후 CD development, staging, main 브랜치에 merge 되는 경우 코드가 자동으로 서버에 배포간단하게 요약하자면    CI : 빌드, 테스트의 자동화     CD : 배포 자동화  CI/CD Solutions:  Jenkins, Travis CI, AWS CodeDeploy, Github Action etc. . 출처 - https://www. simform. com/blog/scalable-ci-cd-pipeline-examples/  Github Action:  Github에서 출시한 기능으로, 소프트웨어 workflow 자동화를 도와주는 도구 Test code, Deployment, Shell script Github tag, release 자동 설정 새로운 브랜치 생성시 특정 작업 실행   다양한 Workflow template이 존재 https://github. com/sdras/awesome-actions   Private repo는 유료     유료와 무료 사이의 제한이나 제약 조건, 과금에 대한 내용 찾아봐서 사용    Github Action 사용 방식:  코드 작업 작업 후, Github Action으로 무엇을 할 것인지 생각 사용할 Workflow 정의 Workflow 정의 후 정상 작동하는지 확인 Github Action Workflow: Workflow:  여러 Job으로 구성, Event로 Trigger되는 자동화된 프로세스 Workflow 파일은 YAML로 작성, 레포지토리의 . /github/workflows에 저장Event:  Workflow를 trigger하는 특정 행동, 규칙 Example     특정 브랜치로 Push   특정 브랜치로 Pull Request   특정 시간대에 반복   Jobs:  Runner에서 실행되는 Steps들의 조합 여러 Jobs이 있는 경우 병렬로 실행, 순차적 실행도 가능     다른 Job에 의존 관계를 가질 수 있음   Example) Job A Success -&gt; Run Job B   Steps:  Job에서 실행되는 개별 작업 Action을 실행하거나 쉘 커맨드 실행 하나의 Job에서 데이터를 공유할 수 있음Actions:  Workflow에서 제일 작은 단위 Job을 생성하기 위해 여러 step을 묶은 개념 재사용 가능한 componentRunner:  Github Action도 일종의 서버에서 실행되는 개념 Runner -&gt; Workflow가 실행될 서버     Github-hosted runner   Self-hosted runner    참고:  https://github. com/zzsza Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤)"
    }, {
    "id": 15,
    "url": "http://localhost:4000/Cloud/",
    "title": "Cloud Computing",
    "body": "2023/06/30 -  클라우드를 사용하는 이유: What is Cloud?: Google Cloud에서 정의하는 Cloud Computing은 다음과 같다  클라우드 컴퓨팅은 컴퓨팅 리소스를 인터넷을 통해 서비스로 사용할 수 있는 주문형 서비스이다. 기업에서 직접 리소스를 조달하거나 구성, 관리할 필요가 없으며 사용한 만큼만 비용을 지불하면 된다. Why use Cloud?:    기존의 전통적인 서버실(Internet Data Center)를 운영하려면, 물리적 공간과 확장성(scalability)까지 고려를 해야 함          Example1) 트래픽이 몰리는 경우 컴퓨터 10대를 더 추가 설치하기 어려움           Example2) 트래픽이 적어지면 컴퓨터 10대를 없애야 하나?        클라우드 서비스가 점점 발전함에 따라, 개발자가 직접 설정해야 했던 작업을 클라우드에서 쉽게하는 방향으로 발전(cloud managed service) Apache Spark를 쉽게 운영할 수 있도록 AWS EMR, GCP Dataproc 활용(직접 하둡, 등을 설치 할 필요 없이 이미 설치되어 있음) 여러가지 환경을 미리 설치해두고 사용하는 것이 편함(tensorflow, CUDA) Cloud의 다양한 서비스: 다음은 Google Cloud에서 정의하는 PaaS, IaaS, SaaS이다.  SaaS(Software as a Service)     SaaS(Software as a service)는 전체 애플리케이션 스택을 제공하여 고객이 액세스하고 사용할 수 있는 전체 클라우드 기반 애플리케이션을 제공   SaaS 제품은 서비스 제공업체에서 모든 업데이트, 버그 수정, 전반적인 유지관리 등을 전적으로 관리하며 즉시 사용할 수 있다   대부분의 SaaS 애플리케이션은 웹브라우저를 통해 직접 액세스할 수 있으므로 고객이 기기에 아무것도 다운로드하거나 설치할 필요가 없다    PaaS(Platform as a Service)     PaaS(Platform as a Service)는 클라우드를 통해 애플리케이션을 개발하는 데 필요한 모든 하드웨어 및 소프트웨어 리소스를 제공하고 관리한다   개발자와 IT 운영팀은 인프라 또는 플랫폼을 자체적으로 빌드하고 유지관리할 필요 없이 PaaS를 사용하여 애플리케이션을 개발, 실행, 관리할 수 있다   고객은 여전히 코드를 작성하고 데이터와 애플리케이션을 관리해야 하지만, 클라우드 서비스 제공업체에서 앱을 빌드하고 배포하는 환경을 관리하고 유지관리한다    IaaS(Infrastructure as a Service)     IaaS(Infrastructure as a Service)는 클라우드를 통해 컴퓨팅, 스토리지, 네트워킹, 가상화와 같은 주문형 인프라 리소스를 조직에 제공한다   고객이 자체 데이터 센터 인프라를 관리, 유지관리 또는 업데이트할 필요는 없지만 운영체제, 미들웨어, 가상 머신, 앱 또는 데이터를 책임진다    출처 : https://www. stackscale. com/blog/cloud-service-models/  출처 : https://cloud. google. com/learn/paas-vs-iaas-vs-saas?hl=ko Cloud 서비스 기업:  AWS, Google Cloud, Azure, Naver Cloud Platform Cloud 제품:  Computing Service(Server)     연산을 수행하는 서비스   가상 컴퓨터, 서버, VM(virtual machine), Instance(인스턴스)   가장 많이 사용하는 제품   회사별로 월 무료 사용량이 존재      Serverless Computing          computing service와 유사하지만, 서버 관리를 클라우드쪽에 진행           코드를 클라우드에 제출하면, 그 코드를 가지고 서버를 실행해주는 형태           요청 부하에 따른 자동확장 가능(auto scaling)           Micro Service로 많이 활용          Stateless Container          Docker를 사용한 컨테이너 기반으로 서버를 실행하는 구조           Docker image를 업로드하면 해당 이미지 기반으로 서버를 실행해주는 형태          Object Storage          다양한 오브젝트를 저장할 수 있는 저장소           다양한 형태의 데이터를 저장 가능, API를 사용해 데이터에 접근 가능           머신러닝 모델의 pkl, csv 파일, 실험 로그 등을 저장할 수 있음          Database(RDB)          웹, 앱서비스와 데이터베이스가 연결되어 있는 경우가 많으며, 대표적으로 MySQL, PosgreSQL 등을 사용할 수 있음           보통 사용자 로그 데이터는 데이터베이스에 저장하지만, 저장된 데이터를 어떻게 사용하냐에 따라 Database에 저장할지, Object Storage에 저장할지 결정          Data Warehouse          데이터베이스, 스토리지에 있는 데이터 등을 모두 모아서 웨어하우스에 저장           데이터 분석에 특화된 데이터베이스           퍼포먼스 빠름       참고:  https://github. com/zzsza https://cloud. google. com/learn/paas-vs-iaas-vs-saas?hl=ko Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤)"
    }, {
    "id": 16,
    "url": "http://localhost:4000/Debugging/",
    "title": "Debugging",
    "body": "2023/05/01 -  Debugging: 디버깅이란?: 오류나 버그를 찾고 수정하는 과정. 이런 디버깅은은 보통 바라는 상황과 실제 상황이 차이가 나는 경우 행해야 하는 경우가 많다.  버그가 발생하는 이유:  휴먼 에러(실수)     개발 과정 중 문법, 로직 오류    실행 환경     OS, 가상 환경, 컨테이너, 하드웨어, 네트워크 상태 등    의존성     라이브러리에서 사용하는 다른 라이브러리의 버그로 인한 이슈    복잡성     소프트웨어가 복잡해질수록 버그 가능성이 높아질 수 있음    잘못된 커뮤니케이션     요구 사항에 대한 misunderstanding    Debugging Process: 문제 발생, 문제 인식, 해결책 찾기, 버그 기록, 버그 재현 등의 과정으로 진행할 수 있다.  출처 - https://www. javatpoint. com/debugging  꼭 기록하는 습관을 가지자 답을 찾더라도 항상 교차 검증하자 항상 목적이 뭔지 상기하면서 해결책을 찾자 Server Management:  대부분 AI, ML 모델들은 서버에서 동작한다 서버의 관리를 배울 필요성이 있다 서버 관리의 목적:  서버를 안정적으로 운영해서 장애를 발생하지 않기 위함 서버에서 작업을 원활하게 진행하기 위함 알아야할 지식:  쉘 커맨드 파일 시스템 네트워크 패키지 관리 성능 모니터링 컨테이너, 오커스트레이팅 Linux 파일 시스템:  리눅스는 파일, 폴더 구조를 일관된 방식으로 제공한다. 시스템 구성, 로그 등을 별도로 저장하며 소프트웨어를 설치하는 공간도 따로 제공한다. 출처 - https://linuxconcept. com/linux-file-system-hierarchy/  파일 공간이 부족할 때 사용하지 않는 파일들을 지워준다. 그러나 한방에 전부 날리는 일은 피하도록 하자. (sudo 명령어로 실수해서 시스템 날려먹는 일 하지말자!) 파일 시스템의 Case Study: 경로나 호스트 머신의 디스크 문제를 인식하기 전에 서버가 어떤 환경에서 실행 중인지 확인하자.  On Premise 환경, IDC와 같은 물리적으로 접근 가능한 서버 환경인지 클라우드 환경인지 Docker/Kubernetes 같은 컨테이너 환경의 여부 네트워크:    IP, DNS, port, 방화벽 등에 대한 개념을 공부하자     ping : 서버가 연결되어 있는지, 얼마자 빠른 속도로 데이터가 전송되는 테스트     nslookup : 특정 도메인을 찾을 수 있는지, DNS 서버에 연결 가능한지     netstat : 포트 개방 확인(TCP connection), 특정 포트만 확인하고 할 때 grep 활용,   ex. netstat -tnlp | grep 3000  참고:  https://www. geeksforgeeks. org/software-engineering-debugging/ Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤)"
    }, {
    "id": 17,
    "url": "http://localhost:4000/Docker-Basic-1/",
    "title": "Docker Basic - 1",
    "body": "2023/04/28 -  Virtualization: 가상화란 무엇인가: 가상화는 서버, 스토리지, 네트워크 및 기타 물리적 시스템에 대한 가상 표현을 생성하는데 사용할 수 있는 기술이다. 가상 소프트웨어는 물리적 하드웨어 기능을 모방하여 하나의 물리적 머신에서 여러 가상 시스템을 동시에 실행할 수 있다. 가상화는 간단하게 말하자면 Local이나 Production 서버에서의 환경을 위한 일종의 템플릿이라고 생각할 수 있다.  개발과 운영 서버의 환경 불일치를 해소할 수 있고, 어느 조건에서나 동일한 환경으로 프로그램을 실행 할 수 있게 된다.  Virtual Machine vs Docker: VM(Virtual Machine): 도커의 등장 전에는 주로 VM(Virtual Machine)을 사용했다. VM은 호스트 머신이라고 하는 실제 물리적인 컴퓨터 위에 OS를 포함한 가상화 소프트웨어를 두는 방식이라고 이해하면 된다. 그러나 이러한 방식은 OS 위에 OS를 하나 더 실행시킨다는 점에서 굉장히 많은 리소스를 사용하게 된다(무겁다).  Container: 컨테이너는 어떤 환경에서나 실행하기 위해 필요한 모든 요소를 포함하는 소프트웨어 패키지같은 형태이다. 컨테이너의 정의를 찾아보면,  소프트웨어 서비스를 실행하는 데 필요한 특정 버전의 프로그래밍 언어 런타임 및 라이브러리와 같은 종속 항목과 애플리케이션 코드를 함께 포함하는 경량 패키지이다. 으로 정의된다.  출처 - https://www. weave. works/blog/a-practical-guide-to-choosing-between-docker-containers-and-vms VM의 경우 host OS 위에 다시 guest OS가 존재하는 형태인 반면에, 컨테이너는 OS 하나 위에서 OS에 상관없이 컨테이너를 띄우는 것을 볼 수 있다.  Docker: 도커 소개: 도커는 이런 컨테이너에 기반한 개발과 운영을 매우 빠르게 확장 할 수 있는 오픈소스 프로젝트이다. 도커에 대해 간단히 설명하자면, 도커의 이미지를 만들어두면 재부팅 할 경우 도커의 이미지 상태로 다시 실행이 된다고 보면 된다.  출처 - https://medium. com/swlh/understand-dockerfile-dd11746ed183  Docker Image : 컨테이너를 실행할 때 사용할 수 있는 Template (Read only) Docker Container : Docker Image를 활용해 실행된 인스턴스 (Write allowed) 도커로 할 수 있는 일: 다른 사람이 만든 소프트웨어를 가져와서 바로 사용 할 수 있음  MySQL을 도커로 실행 Jupyter Notebook을 도커로 실행이 때 다른 사람이 만든 소프트웨어를 Docker Image라고 이해하면 되고, OS를 포함한 실행 환경이 저장되어 있다.  Linux, Windows 등 어디서나 동일하게 실행할 수 있다.  도커로 MySQL 실행 해보기: 도커 실행:    docker명령어로 도커 동작 확인     docker pull mysql:8로 mysql 8 버전의 이미지를 다운     docker images로 다운 받은 이미지 확인     docker run --name mysql-tutorial -e MYSQL_ROOT_PASSWORD=0000 -d -p 3306:3306 mysql:8          다운 받은 MySQL 이미지 기반으로 docker container를 만들고 실행           --name mysql-tutorial : 컨테이너의 이름을 mysql-tutorial 로 정하겠다는 것. 설정 하지 않으면 랜덤으로 생성 됨           -e MYSQL_ROOT_PASSWORD=0000 : 환경변수 설정을 하는 부분. 사용하는 이미지에 따라 설정이 다르지만, 현재 하고 있는 MySQL의 경우 환경변수를 통해 root 계정의 비밀번호를 설정하고 있음.           -d : 데몬(백그라운드) 모드. 컨테이너를 백그라운드 상태로 실행. 이 설정을 하지 않을 경우, 현재 실행하는 셸 위에서 컨테이너가 실행되고 컨테이너의 로그를 바로 볼 수 있지만, 컨테이너를 나갈 경우 실행이 종료 됨.           -p 3306:3306 : 포트 지정. -p {localhost port}:{container port} 형태로, 현재의 경우 로컬 포트 3306으로 접근 시 컨테이너 포트 3306으로 연결되도록 설정. MySQL은 기본적으로 3306 포트로 통신함.          docker ps 로 실행한 컨테이너와 정보를 확인 할 수 있음     docker exec -it mysql-tutorial /bin/bash MySQL이 실행되고 있는지 확인하기 위해 컨테이너로 진입 할 수 있다. Compute engine에서 SSH와 접속하는 것과 유사하다.      docker exec -it {container name or ID} /bin/bash      mysql -u root -p MySQL 프로세스로 들어가면 MySQL 쉘 화면이 보인다.     docker stop {container name or ID} 실행 중인 컨테이너를 멈출 수 있다.     docker ps -a로 작동을 멈춘 컨테이너를 확인 할 수 있다. docker ps의 경우 실행중인 컨테이너 목록만 보여줌.     docker rm {container name or ID} 으로 멈춘 컨테이너 삭제 가능      docker rm {container name or ID} -f 로 실행중인 컨테이너도 삭제 가능    Volume mount:    Docker run 할 때 파일이 자동으로 공유가 되는 것이 아님. 호스트와 컨테이너를 연결(sync) 해주는 것이 volume mount.     docker container는 특별한 설정이 없으면 컨테이너를 삭제할 때 파일이 사라짐     Host와 container는 처음부터 파일 공유가 되지 않음     파일을 유지하고 싶을 경우 host와 container의 저장소를 공유해야 함     Volume mount를 진행하면 host와 container의 폴더가 공유됨     -v 옵션을 사용하며 port 처럼 사용함. -v host_folder:container_folder     ex. docker run -it -p 8888:8888 -v /some/host/folder/for/work : /home/workspace/jupyter/note  DockerHub: 필요한 이미지가 있을 경우, 공개된 모든 이미지를 다운받을 수 있다.  Docker Image 만들기: pytorch example 코드를 실행하는 docker image 생성 해보기 Dockerfile 생성:  vi Dockerfile 로 만들든 gui로 만들든 Dockerfile을 생성해서 필요한 내용을 작성한다. 1From pytorch/pytorch:1. 13. 1-cuda11. 6-cudnn8-runtime From {image name}:{tag} 형식은 이미지 빌드에 사용할 베이스 이미지를 지정하는 것이다. 보통 공개된 이미지 기반으로 새로운 설정을 추가하는 방법으로 사용. 1copy . /app   copy {로컬 디렉토리(파일)} {컨테니어 내 디렉토리(파일)} 컨테이너는 자체적인 파일 시스템을 가짐. copy명령어는 dockerfile이 존재하는 경로 기준 로컬 디렉토리를 컨테이너 내부의 디렉토리로 복사한다.     해당 코드의 경우 프로젝트 최상위에 존재하는 모든 파일을 컨테이너 내부 /app 디렉토리로 복사한다.     파일을 컨테이너에서 사용하고 싶으면 반드시 copy를 써서 복사해야 함.  1WORKDIR /app WORKDIR {컨테이너 내 디렉토리} dockerfile의 RUN , CMD, ENTRYPOINT 등의 명령어를 실행할 컨테이너 경로를 지정한다. 아래 라인에 등장하는 RUN, CMD는 컨테이너 내부의 /app에서 실행한다. 12ENV PYTHONPATH=/appENV PYTHONBUFFERED=1 ENV {환경변수 이름=값} 컨테이너 내의 환경변수를 지정한다. 파이썬 애플리케이션의 경우 보통 위의 두 값을 지정한다. 1234RUN pip install pip==23. 0. 1 &amp;&amp; \	pip install poetry==1. 2. 1 &amp;&amp; \	poetry export -o requirements. txt &amp;&amp; \	pip install -r requirements. txt RUN은 컨테이너 내에서 리눅스 명령어를 실행한다. 한번에 실행할 명령어가 여러 대인 경우 &amp;&amp; \로 이어준다. 이전 라인에서 COPY 와 WORKDIR이 실행 되었기 때문에 requirements. txt가 존재하고, 이를 pip install -r 명령어로 실행할 수 있다. 1CMD [ python ,  main. py ] CMD [ 실행할 명령어 ,  인자 , . . ] docker run으로 이미지를 기반으로 컨테이너를 만들 때, 실행할 명령어의 이미지는 실행되는 즉시 python main. py를 실행한다. CMD는 띄어쓰기를 사용하지 않는다. Docker Image Build: 1docker build -t {빌드할 이미지 이름:태그 이름} {Dockerfile이 위치한 경로}1docker build -t 02-docker:latest .  이미지 생성 아래 이미지에서 . 는 현태 폴더에 Dockerfile이 있음을 의미 -t {빌드할 이미지 이름:태그 이름} 옵션으로 이미지 이름과 태그 지정 태그 미지정시 “latest”로 채워짐  빌드를 마치면 docker images명령어로 방금 빌드한 이미지를 확인 할 수 있다. 1docker images | grep 02-docker Docker Image 실행: 1docker run {image name:tag} 빌드한 이미지를 실행 할 수 있음 태그가 latest인 경우 생략 가능1docker run 02-docker:latest Dockerfile 기타:    EXPOSE : 컨테이너 외부에 노출할 포트 지정     ENTRYPOINT : 이미지를 컨테이너로 뛰울 때 항상 실행하는 커맨드  Docker Image Push:    우리가 만든 이미지를 업로드 할 수 있다. 이를 위해 대표적인 registry인 Dockerhub에 도커 이미지를 push 할 수 있다. (github과 비슷함)     docker login 명령어로 내 dockerhub 계정을 cli에 연동 할 수 있음.     docker tag {기존 이미지:태그} {새 이미지 이름:태그} dockerhub에 올릴 이미지 이름은 내 계정ID/이미지 이름 형태여야 함.     docker push {이미지이름:태그} dockerhub에 이미지를 psuh 한다. Dockerhub에서 push된 이미지 확인 가능.     내가 push한 이미지는 pull로 언제든지 다시 받을 수 있음.   참고:  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://github. com/zzsza https://aws. amazon. com/ko/what-is/virtualization/ https://cloud. google. com/learn/what-are-containers?hl=ko"
    }, {
    "id": 18,
    "url": "http://localhost:4000/Basic-Linux-2/",
    "title": "Linux Basic - 2",
    "body": "2023/04/27 -  표준 스트림(standard stream): 표준 스트림은 프로그래밍 언어의 인터페이스를 비롯한 유닉스 계열 운영체제에서 컴퓨터 프로그램과 단말기 사이에 미리 연결된 입출력 통로를 가르킨다. 유닉스에서 통작하는 프로그램은 실행 시 3개의 스트림이 자동으로 열린다. 입력을 위한 스트림(Standard Input, STDIN, 0), 출력을 위한 스트림(Standard Output, STDOUT, 1), 마지막으로 오류 메시지의 출력을 위한 스트림(Standard Error , STDERR, 2)가 존재한다. 보통 입출력은 물리적으로 연결된 콘솔을 통해 일어나는데, 표준 스트림을 이것을 추상화한 것이라고 보면 된다.  출처 : https://en. wikipedia. org/wiki/Standard_streams ​  Standard Input, STDIN, 0 : 입력(비밀번호, 커맨드 등) Standard Output, STDOUT, 1 : 출력(터미널에 나오는 값) Standard Error , STDERR, 2 : 디버깅 정보나 에러 출력 Redirection and Pipe: Redirection:  프로그램의 출력을 다른 파일이나 스트림으로 전달하는 것.      &lt;    스트림의 흐름을 바꿔주는 것이라고 이해하면 편하다. Pipe:    프로그램의 출력을 다른 프로그램의 입력으로 사용하고 싶을 때 사용한다. 예를 들어 A라는 명령어의 output을 B의 input으로 사용하고 싶을 경우 처럼, 다양한 커맨드를 조합하는 방식으로 사용 할 수 있다.     ls | grep  vi  : 현재 폴더에 있는 파일 명 중 “vi” 가 들어간 단어를 찾기  서버에서 자주 사용하는 쉘 커맨드: ps:    Process Status의 약자. 현재 실행되고 있는 프로세스를 출력한다.     -e : 모든 프로세스     -f : full format으로 자세히 보여줌   curl:    Client URL의 약자. CL 기반의 data transfer 커맨드이다. Request를 테스트 할 수 있는 명령어이다. 웹 서버를 작성한 후 요청이 제대로 실행되는지 확인할 수 있다.     curl -X localhost:5000/ {data}     curl 외에도 httpie 또는 Postman 등이 있다.   df:    Disk Free의 약자. 현재 사용 중인 디스크의 용량을 확일 할 수 있다.     -h : 읽기 쉬운 형태로 출력  scp:    Secure Copy의 약자. SSH를 이용해 네트워크로 연결된 호스트 간 파일을 주고 받는 명령어이다.     -r : 재귀적으로 복사     -P : SSH 포트 지정     -i : SSH 설정을 활용해 실행  remote to local:  scp user@ip:remote_directory local_pathremote to remote:  scp user@ip:remote_directory user2@ip2:target_remote_directory nohup:    터미널 종료 후에도 계속 작업이 유지하도록 실행한다(백그라운드 실행)     nohup python3 app. py &amp;     nohup으로 실행될 파일은 permission이 755여야 함.      chmod 755 {실행파일}   nohup으로 실행된 파일 종료:    ps ef | grep app. py : app. py의 pid(Process ID) 찾고 kill -9 {pid}로 프로세스를 kill 하면 된다.     Log는 nohup. out에 저장 된다.   chmod:    Change Mod의 약자. 파일의 권한을 변경하는 경우 사용한다. 유닉스에서 파일이나 디엑토리의 시스템 모드를 변경한다.     ls -al로 확인  Permission: r : Read, 4 w : write, 2 x : execute, 1 - : Denied 참고:  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://www. youtube. com/watch?v=EL6AQl-e3AQ 위키피디아-표준 스트림"
    }, {
    "id": 19,
    "url": "http://localhost:4000/Shell-Script-1/",
    "title": "Shell Script Basic - 1",
    "body": "2023/04/26 -  Shell Script:    쉘 스크립트는 쉘에서 사용 할 수 있는 명어들의 조합을 모아서 만든 파일이라고 보면 편하다. 기본적으로 쉘을 이용해서 명령어들을 순차적으로 읽으면서 실행시켜준다.     . sh 파일을 생성해서 그 안에 쉘 커맨드를 추가 할 수 있다. If, while, case 문이 존재하며 작성후 bash {name. sh} 로 실행이 가능하다.   쉘 스크립트의 사용:    #!/bin/bash : 이 스크립트를 Bash 쉘로 해석 하겠다는 선언문 같은 것     $(date +%s) : date를 %s (unix timestamp)로 변형     START=$(date +%s) : START라는 변수에 저장     쉘 스크립트를 통해 편리하게 자동화를 구축할 수 있다. 많이 연습해두자.     쉘 스크립트를 통해 구현 할 수 있는 기능 예시 : https://www. geeksforgeeks. org/introduction-linux-shell-shell-scripting/     위 링크에서 쉘 스크립팅에 대한 더 자세한 내용을 볼 수 있다.   참고:  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://www. youtube. com/watch?v=cXnVygkAg4I https://www. geeksforgeeks. org/introduction-linux-shell-shell-scripting/"
    }, {
    "id": 20,
    "url": "http://localhost:4000/Basic-Linux-1/",
    "title": "Linux Basic - 1",
    "body": "2023/04/26 -  리눅스 개요: What is Linux?: 리눅스는 오픈소스 운영체제(OS, Operating System)이다. 리눅스 세계 최대의 오픈소스 프로젝트이며, 누구든지 자유롭게 운영체제 프로그램의 소스를 변경하여 재배포 시킬 수 있는 프리웨어다.  리눅스를 배워야하는 이유: CLI를 통한 개발은 필수적이다. Shell script의 작성부터 서버 개발까지, 리눅스는 어떻게 보면 개발자를 위한 필수 교양이기 때문에 학습하는 것을 강력하게 권장한다.  다양한 리눅스 배포판: 출처 : https://en. wikipedia. org/wiki/List_of_Linux_distributions  Debian Ubuntu Redhat Centos이 외에도 정말 다양한 리눅스 배포판이 존재한다. 목적에 맞게 골라서 사용하면 된다.  Introduction to Shell: 쉘의 종류: 쉘은 커널(kernel)과 사용자간의 다리역할을 해서, 사용자로부터 명령을 받아서 해석하고 프로그램을 실행해준다. (여기서 커널은 운영체제의 메모리에 항상 올라가 있는 부분으로, 하드웨어와 소프트웨어 사이의 인터페이스를 제공해주는 역할을 해준다고 보면 된다) 조금 더 간단하게 말하면, 사용자가 문자를 입력해 컴퓨터에 명령할 수 있도록 하는 프로그램이다.  sh : 최초의 쉘 bash : 리눅스 표준 쉘 zsh : Mac OS 기본 쉘이것 외에도 다양한 쉘이 존재한다.  쉘을 사용하는 상황:  서버에 접속해서 사용하는 경우 crontab 등 리눅스의 내장 기능을 활용하는 경우 Docker를 사용하는 경우 서버를 관리할 경우 Test code의 실행이나 배포 파이프라인(github action)의 실행이것 외에도 정말 많은 이유로 쉘을 사용하는 상황이 온다. 1kimseungki@DESKTOP-1P30XXX:~ username : 사용자 이름 (kimseungki) hostname : 컴퓨터 네트워크에 접속된 장치에 할당된 이름. IP 대신 기억하기 쉬운 이름으로 저장하는 경우가 많음 (DESKTOP-1P30XXX) Shell Command: 기본적인 shell 명령어: man:  쉘 커맨드의 매뉴얼 문서를 보고 싶은 경우 사용. man python  종료는 q 입력. mkdir:  Make Directory의 약자. 폴더를 생성한다. mkdir linux-test (linux-test라는 폴더를 현재의 경로에 생성) ls:  List Segments의 약자. 현재 접근한 폴더의 구성요소 확인. 옵션 -a : . 으로 시작하는 파일, 폴더를 포함해 전체 파일 출력 -l : 퍼미션, 소유자, 만든 날짜, 용량까지 출력 -h : 용량을 사람이 읽기 쉽도록 표현 ls -a 또는 ls -alh 처럼 사용 pwd:  Print Working Directory의 약자. 현재 폴더의 경로를 절대 경로로 보여줌. pwd cd:  Change Directory의 약자. 명시한 폴더의 경로로 이동한다. cd linux-test echo:  파이썬의 print 처럼 터미널에 텍스트를 출력해준다. echo  hi  : 터미널에 hi 출력 echo `쉘커맨드` 입력시 쉘 커맨드의 결과를 출력  ex. echo `pwd` cp:  Copy의 약자. 파일 또는 폴더를 복사한다. cp vi-test. sh vi-test2. sh 옵션 -r : 디렉토리를 복사할 때 디렉토리 안에 파일이 있으면 재귀적으로 모두 복사 -f : 복사할 때 강제로 실행 vi:  vim 편집기로 파일을 생성한다. INSERT 모드에서만 수정 할 수 있음. vi vi-test. sh 를 사용하면 vim 편집기로 vi-test. sh라는 파일을 생성함. i를 눌러서 INSERT 모드로 변경해서 수정을 할 수 있음.  나가기 위해서는 ESC + wq 또는 ESC + ! 후에 wq 입력으로 저장하고 나갈 수 있다. 그냥 q의 경우 저장하지 않고 나간다. vim editor mode vi 편집기 mode   Command mode      vi 실행시 기본 모드   방향키를 통해 커서 이동 가능   dd : 현재 위치한 한 줄 삭제   i : INSERT 모드로 변경   x : 커서가 위치한 곳의 글자 1개 삭제   p : 현재 커서가 있는 줄 바로 아래에 붙여넣기   k : 커서 위로 / j : 커서 아래로 / l : 커서 오른쪽으로 / h : 커서 왼쪽으로      Last Line mode      ESC 누른 후 콜론(:)을 누르면 나오는 모드   w : 현재 파일명으로 저장   q : vi 종료(저장되지 않음)   q! : vi 강제 종료   wq : 저장 후 종료   set nu : 라인 번호 출력    bash:  bash로 쉘 스크립트 실행bash vi-test. sh 로 vi-test. sh 라는 쉘 스크립트 파일을 실행 vi-test. sh sudo:  관리자 권한으로 실행하고 싶은 경우 앞에 sudo를 붙임. 한 마디로 최고 권한을 가진 슈퍼 유저로 프로그램을 실행하겠다는 뜻이다. sudo의 사용에는 신중을 가하고 사용하는 것을 권장한다. mv:  Move의 약자. 파일 또는 폴더를 이동하기 위해 사용한다. 이름을 바꾸기 위해 사용 할 수 도 있다. mv vi-test. sh vi-test3. sh 를 사용하면 vi-test. sh가 vi-test3. sh로 이름이 변경된다.  mv {원본파일} {이동위치} 로 파일을 이동 시킬 수 있다.  cat:  Concatenate의 약자. 특정 파일 내용을 출력하기 위해 사용한다. 여러 파일을 인자로 주면 합쳐서(concat) 출력 해준다. Concat을 한 상태에서 파일에 저장(overwrite)또는 추가(append) 할 수 있다. cat vi-test3. sh  concat 해서 출력cat vi-test2. sh vi-test3. sh  파일에 overwritecat vi-test2. sh vi-test3. sh &gt; new_test. sh  파일에 appendcat vi-test2. sh vi-test3. sh &gt;&gt; new_test. sh history:  최근데 입력한 쉘 커맨드의 역사를 출력. History 결과에서 느낌표를 붙이고 숫자 입력시 그 커맨드를 다시 활용 할 수 있음. find:  파일 및 디렉토리를 검색할 때 사용 할 수 있다. find . -name  File  : 현재 폴더에서 File이란 이름을 가지는 파일 및 디렉토리 검색 find . -type file -name  *. txt  : 현재 경로에서 하위 디렉토리까지 . txt라는 확장자를 가진 모든 파일 검색 alias:  기본 명령어를 별칭으로 설정 할 수 있음. alias ll2='ls -l' : ll2 입력시 ls -l이 동작 됨 alias gp='git push' : gp 입력시 git push가 동작 됨 tree:  폴더의 하위 구조를 계층적으로 표현해줌. 프로젝트의 구조를 설명 할 때 유용하다. tree -L {level} 의 형태로 사용 tree -L 1 : 1 level 까지 보여주기 head, tail:  파일의 앞 또는 뒤 n행을 출력함. head -n 1 vi-test3. sh : vi-test3. sh의 앞 1 행 출력 cat 로 파일 전체를 보기에 너무 긴 경우 활용 할 수 있음.  sort:  행 단위로 정렬 해줌. -r : 정렬을 내림차순으로 정렬(기본:오름차순) -n : numeric sort cat fruits. txt | sort : fruits. txt를 cat로 출력할때 오름차순 정렬을 해서 출력한다.  uniq:  중복된 행이 연속으로 있는 경우 중복 제거한다. sort와 함께 사용하면 효과적이다. -c : 중복된 행의 개수 출력 cat fruits. txt | sort | uniq grep:  파일에 주어진 패턴 목록과 매칭되는 라인을 검색 해줌. grep은 뒤에서 나올 pipe와 같이 사용하곤 한다. grep {option} {filename} 옵션 -i : 대소문자 구분 없이 찾기 -w : 정확히 그 단어만 찾기 -v : 특정 패턴 제외한 결과 출력 -E : 정규 표현식 사용  cut: 파일에서 특정 필드를 추출한다. -f : 잘라낼 필드 지정 -d : 필드를 구분하는 구분자 참고  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://www. youtube. com/watch?v=EL6AQl-e3AQ FabioLolix/LinuxTimeline: Linux Distributions Timeline"
    }, {
    "id": 21,
    "url": "http://localhost:4000/python-version-control/",
    "title": "Version Control",
    "body": "2023/04/25 -  Python Versioning: Python is Semantic Versioning:    파이썬 3. 11. x 버전은 아래 마이너 버전(3. 10. x, 3. 9. x . . )에 호환      3. 8. x에서 생성한 코드가 있다면 그대로 3. 11. x에 실행해도 문제가 없음   하지만 패키지가 3. 11. x를 지원하지 않는 문제가 있을 수도 있음      파이썬 3. x 버전은 아래 메이저 버전 2. x에 호환 안됨      2. x의 코드는 3. x의 버전에서 실행 되지 않음    프로젝트의 파이썬 버전 표시: 파이썬 버전은 보통 프로젝트의 github readme에 작성    python 3. 8 이상에서 실행 가능      python&gt;=3. 8, python 3. 8+, python 3. 8^      python 3. 8 만 실행 가능      python == 3. 8      python 3. 10 이상, 3. 11 미만에서 실행 가능      python=”&gt;=3. 10, &lt;3. 11”    파이썬 설치 방법: 파이썬의 설치 방법에는 여러 종류가 있고, 각각의 장단점이 있다.  파이썬 공식 홈페이지에서 파일을 다운받아 설치     홈페이지의 바이너리 파일을 다운받아서 설치한다. 이렇게 설치는 케이스가 제일 적다.       Conda를 이용하여 설치          만약 python 3. 11을 설치한다면 conda install python=3. 11. 0 으로 설치한다. Python의 버전 관리를 conda에 맡김.           장점 : conda 사용 중이라면, 별다른 도구 없이 바로 설치 가능           단점 : conda가 무겁기 때문에 production 환경에선 잘 사용되지 않음           사용하는 경우 : conda 중심의 셋팅이 이미 되어 있는 경우          Docker로 파이썬 3. 11. 0 이미지 설치          docker pull python:3. 11. 0으로 파이썬 버전 관리를 컨테이너 이미지로 진행한다. 파이썬을 사용하고 싶으면 docker run -it python python으로 Docker 컨테이너 실행과 접속을 한다.           장점 : 로컬환경에 바이너리를 설치하지 않기 때문에 파이썬 설치 및 삭제가 쉬움           단점 : 파이썬을 이용하기 위해서는 컨데이너에 매번 접속해야 함           사용하는 경우 : 로컬 환경과 파이썬 환경을 완전히 격리하고 싶은 경우          패키지 매니저로 설치          패키지 관리자(brew, apt, winget)로 파이썬 설치          Mac OS의 경우             brew install python@3. 11                Linux의 경우(Ubuntu)             apt install python3. 11                Window의 경우             winget install Python3. 11                         장점 : 설치가 간단           단점 : 패치 버전까지 포함하는 파이썬 특정 버전을 설치할 수 없음           사용하는 경우 : CLI로 빠르고 간단하게 설치하고 싶은 경우          pyenv로 설치하기          pyenv는 파이썬의 여러 버전을 cli로 쉽게 설치할 수 있는 도구. pyenv install 3. 11. 0을 사용해서 설치.           장점 : 파이썬의 여러 버전을 설치하고 다룰 수 있음           단점 : pyenv를 먼저 설치해야 함           사용하는 경우 : 여러 버전의 파이썬을 바꿔줘야 하는 경우       파이썬 설치 시 여러 방법을 사용하면 충돌이 날 가능성이 존재한다. 파이썬 설치 전 지금 사용하는 python이 어디서 설치된 것인지 확인하는 과정이 필요함. which python{version} 으로 확인 가능.  Pyenv: MacOS, Linux: Mac 1brew install pyenvLinux 1sudo apt-get install -y make build-essential libsqlite3-dev wget curl llvm libncurses5-dev libssl-dev zlib1g-dev libbz2-dev libreadline-dev libncursesw5-dev xz-utils tk-dev1curl https://pyenv. run | bashMac이나 linux는 본인이 사용하는 shell 설정 파일(~/. bashrt, ~/. zshrc) 끝에 환경 변수들을 추가해야 함 123export PATH= ~/. pyenv/bin:$PATH eval  $(pyenv init -) eval  $(pyenv virtualenv-init -) shell을 확인하는 방법 1echo $SHELL환경 변수 추가 후 source “shell 설정 파일”로 shell 설정 업데이트 1source ~/. bashrc Windows: Powershell에서 다음 명령어 입력 1Invoke-WebRequest -UseBasicParsing -Uri  https://raw. githubusercontent. com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win. ps1  -OutFile  install-pyenv-win. ps1 ; . /install-pyenv-win. ps1Powershell 재실행, 필요한 경우 환경 변수 추가 pyenv shell 3. 11. 0 으로 현재 shell에 파이썬 버전 활성화 pyenv global 3. 11. 0으로 shell의 기본 파이썬 버전 설정 파이썬 프로젝트의 버전 관리: 가상환경: 하나의 로컬 환경에서 두개 이상의 프로젝트를 진행하면, 각각 사용하는 파이썬이나 패키지의 버전이 달라서 문제가 발생 할 수 있음. 이런 문제를 해결 하고자 가상 환경을 생성해 프로젝트 별로 각자의 환경을 갖게 함.  가상환경을 만드는 방법: venv, conda, pyenv-virtualenv, pipenv 등 다양한 방법이 있음. 그 중 venv가 파이썬 가상 환경 구축에 많이 사용 됨.  venv: 1python -m venv  가상 환경 폴더를 만들 경로  보통 프로젝트 최상위 경로에서 . venv로 만드는 것이 관습 venv는 파이썬 내장 모듈 가상 환경 접속 : source {가상환경폴더}/bin/activate 접속하면 shell 왼쪽에 . venv 같은 가상환경 접속이 표시됨 windows venv activation1path\to\venv\Scripts\activate. bat또는 1path\to\venv\Scripts\Activate. ps1 패키지 매니저: 패키지 매니저는 패키지를 설치하고 버전을 관리해준다. 파이썬의 패키지 매니저에는 pip, poetry, conda 등이 존재한다. (conda는 anaconda 자체의 패키지 매니저로 보는 것이 맞다) pip: pip는 항상 최신 버전의 pip를 사용하는 것이 좋음 패키지 설치 pip install {package name}[==version] ex. pip install pandas==2. 0. 0 패키지 목록 확인 pip list pip list --not-required --format=freeze (의존성 패키지 제외) 설치한 패키지 목록을 저장 freeze &gt; requirements. txt 저장한 패키지 목록을 다른 환경에서 설치 pip install -r requirements. txt pip의 단점   개발 환경과 배포 환경의 패키지가 분리되지 않음      black이라는 파이썬 코드 formatter 패키지가 있는데, black은 개발 환경에서만 사용될 뿐, 실제 배포 환경에서는 사용하지 않음   pip를 사용할 경우 requirements. txt에 black이 포함되고 실제 배포할 때 설치되어 용량을 더 사용하게 됨      pip list로 패키지간 의존성을 알 수 없음      pip install로 설치한 패키지는 black 하나 뿐인데 pip list에는 이 외의 패키지들도 등장한다. 이 패키지들은 black이 의존하는 패키지들인데, 이런 의존성에 대한 정보가 없음      pip uninstall 시 의존성이 있던 패키지들은 삭제되지 않음      black을 삭제해도 black과 함께 설치된 패키지들은 삭제되지 않음   요약하자면 pip로는 정교한 패키지 관리가 불가능하기 때문에 협업을 하는 경우 곤란한 상황이 올 수도 있다.  Poetry: pip의 문제를 해결하기 위해 poetry라는 대체재가 등장했다. Poetry 설치는 공식문서 참조 poetry 사용   프로젝트의 경로에서 poetry init 으로 파이썬 프로젝트 초기화. 기본적인 설정을 하고나면 프로젝트 경로에 pyproject. toml 이라는 파일이 생성된다. pyproject. toml는 파이썬 프로젝트에 대한 메타 정보를 담고 있는 파일임.     패키지의 설치는 poetry add 명령어로 설치한다. -D 옵션을 붙일 경우 개발 환경에서만 사용할 패키지를 설치 할 수 있음.  ex. add black -D  pyproject. toml 에서 dev 환경과 build 환경을 나눠서 관리 할 수 있기 때문에 정교한 패키지 관리가 가능함. 참고:  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://peps. python. org/pep-0440/"
    }, {
    "id": 22,
    "url": "http://localhost:4000/Versioning/",
    "title": "Versioning",
    "body": "2023/04/25 -  Version and Versioning: 버전(Version):  소프트웨어 제품의 특정 릴리스에 대한 고유한 식별자 소프트웨어의 출시나 업데이트가 이루어질 때마다 새로운 버전을 부여함 버저닝(Versioning):  소프트웨어의 버전 작성은 특정 상태에 대한 유일한 버전 번호를 결정하는 일이라고 보면 된다 다양한 버전을 관리하고 식별하기 위해 사용되는 방법 버저닝 방법(Versioning strategy):    CalVer(Calendar Versioning)      날짜 기반 시스템을 활용한 버저닝   버전 번호는 연도와 월로 구성   날짜 기반으로 출시 시기 예측이 수월   ex. Ubuntu 20. 04       출처 - https://blog. datalust. co/switching-to-calendar-versioning/      SemVer(Semantic Versioning)      마침표로 구분된 주 번호, 부 번호, 패치 번호로 구성   이전 버전과 호환되지 않은 변경이 있는 경우 주 번호 증가   이전 버전과 호환되며 새로운 기능이 추가되면 부 번호 증가   이전 버전의 버그 수정이 진행되면 패치 번호가 증가   ex. Python 3. 11. 0    출처 - https://forums. ubports. com/topic/1822/semantic-versioning-for-ut   HashVer(Hash Versioning)     SHA-1, SHA-256 해시 알고리즘을 사용해 버전에 대한 고유 식별자를 생성   코드가 변결될 때마다 해시가 변경되므로 모든 버전이 고유한 식별자를 가지도록 보장   ex. Git command 7e6d3fd   버저닝이라는 것은 결국 코드의 특정 상태를 표현하는 것이 핵심이다. 협업을 할 때에도 특정 상태에 대한 통일된 명칭을 만들어야 커뮤니케이션이 원활하다는 것을 알 것이다.  참고:  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://semver. org/ https://calver. org/"
    }, {
    "id": 23,
    "url": "http://localhost:4000/Software-engineering/",
    "title": "Software Engineering",
    "body": "2023/04/24 -  소프트웨어 엔지니어링이란: 소프트웨어의 개발, 운용, 유지보수 등의 life cycle 전반을 체계적이고 정량적으로 다루는 개념이다. 한 마디로 소프트웨어의 품질과 유지 보수성을 보장하는 학문이라고 봐도 무방할 것 같다.  Software Development Life Cycle(SDLC): 소프트웨어의 개발 수명 주기는 고품질 소프트웨어를 설계하고 구축하기 위해 필수적인 비용 및 시간 효율적인 프로세스이다.  계획(Planning) &amp; 분석(Analysis):  비용 분석, 스케쥴링, 리소스 추정 및 할당과 같은 작업 client, 전문가, 관리자 등 여러 이해 관계자들의 요구 사항을 수집하여 공통 목표를 정의     보통 협의된 요구사항들에 대해서 문서화 해서 수령하고, 이 요구사항에 대한 문서를 SRS(Software Requirement Specification)라고 부릅니다    공통 목표를 달성하기 위한 세부 계획을 수립 설계(Design architecture):  요구 사항을 만족하는 최적의 솔루션 찾기 모듈을 통합하거나, 기술을 선택하고, 개발 도구를 찾고 기능이 동작할 수 있는 아키텍쳐를 설계하는 단계 데이터의 flow나 동작에 대한 고민 구현(Implementation):  실제적인 제품의 개발이 시작되는 단계 개발 가이드라인을 준수하면서 코드의 개발부터 시작해서 통합해서 빌드하는 단계까지 모두 포함 검증(Testing):  기능이 동작하는지, 오류가 있는지 테스트하는 단계 client의 요구 사항을 충족하는지 확인하는 작업이 포함 구현 단계와 동시에 진행되는 경우가 많음 배포(Deployment):  사용자가 사용하는 소프트웨어를 프로덕션 이라고 하고 개발팀에서 지속적으로 개발하고 테스트하는 소프트웨어의 복사본을 테스트 환경 또는 빌드 환경 패키징, 환경 구성 및 설치 하는 작업도 배포에 포함 유지관리(Maintenance):  소프트웨어의 변경 사항 관리, 버그 픽스, 성능 및 사용자 환경 모니터링이 들어가는 단계 출처 - https://bigwater. consulting/2019/04/08/software-development-life-cycle-sdlc/ SDLC는 위 과정을 계속 반복하는 프로세스. SDLC 모델들은 여러가지가 존재하고, 다른 수명 주기 방법론과 intersect 하는 부분도 많기 때문에 관심이 있다면 terminology에 대한 명확한 설명을 더 찾아보는 것도 좋을 것 같다.  소프트웨어의 설계: Modularity, Cohesion, Coupling:    모듈성(modularity)      소프트웨어에서 임의의 두 부분이 직접적인 상호관계가 많아지면 모듈성이 떨어짐   시스템의 구성 요소가 분리되고 재결합 될 수 있는 정도      응집도(cohesion)      모듈 내부의 기능적인 응집 정도   하나의 모듈은 하나의 기능을 수행하는 것이 이상적   하나의 클래스에 모든 기능을 구현하는 것이 아닌 목적에 맞게 나누고 교류하는 인터페이스가 중요      결합도(coupling)      모듈과 모듈같의 상호 결합 정도, 모듈 간의 상호의존성을 나타내는 정도   응집도와 결합도에서 보통 응집도는 높을수록 좋고 결합도는 낮을수록 이상적이다. 응집도와 결합도의 다양한 유형에 대해 추가적으로 알아봐도 좋을 것 같다.  출처 - https://www. geeksforgeeks. org/software-engineering-coupling-and-cohesion  Testing: 소프트웨어 개발에서의 테스트는 넓게 보면 프로그램이 예상대로 작동하고 문제가 없는지 확인하는 과정이라고 생각하면 좋을 것 같다. 조금 더 자세히 말하자면 사용자가 안정적으로 소프트웨어를 사용할 수 있도록, 기능이 추가될 때 기존 시스템에서의 오류 확인, 아키텍쳐 확인, 서버에 대한 확인, 데이터베이스의 연결에 대한 확인 등 여러가지 단계가 포함된다.  출처 : https://www. geeksforgeeks. org/levels-of-software-testing 딥러닝에서의 testing life cycle에 대해서 더 알아봐야겠다.  문서화(Documentation): 소프트웨어를 위한 Readme, API 문서, 아키텍쳐 문서 등이 여기에 포함. 파이토치의 documentation을 예시로 들자면  Pytorch에 대한 소개와 설명 OS별 설치 방법 시작 방법 추가 학습 자료 오픈소스에 기여하는 방법 소프트웨어 엔지니어링 역량의 필요성: 머신러닝 모델을 설계하고 만드는 것은 전체 과정의 극히 일부. 결국 product를 serving하기 위해서는 소프트웨어 엔지니어링은 필수적이다. 전체 시스템을 알기 위해서는 소프트웨어 엔지니어링 관점으로 생각을 확장해야 함.  출처 : Hidden Technical Debt in Machine Learning Systems  참고:  Naver Connection Boostcamp AI Tech 5th - Product Serving(변성윤) https://zzsza. github. io/ https://aws. amazon. com/ko/what-is/sdlc/ https://www. geeksforgeeks. org/software-engineering-coupling-and-cohesion/"
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});