<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/assets/images/logo.png">

<title>Object Detection Overview | Seungki1011's Dev Blog</title>

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Object Detection Overview | Seungki1011â€™s Dev Blog</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Object Detection Overview" />
<meta name="author" content="seungki" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Object Detection Classification + Localization í•˜ë‚˜ì˜ ê°ì²´ì— ëŒ€í•´ì„œ í´ë˜ìŠ¤ë¥¼ íŒë³„ í•˜ê³ , ê·¸ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ëŠ” bounding boxë¥¼ ì°¾ì•„ì£¼ëŠ” ì‘ì—…ì„ classification and localization taskë¼ê³  í•œë‹¤. ê¸°ë³¸ì ì¸ ì•„í‚¤í…ì³ì˜ ê²½ìš° CNN ë„¤íŠ¸ì›Œí¬ì— class scoreë¥¼ ì •í•´ì£¼ëŠ” FC layerì™€ box coordinateì„ ì •í•´ì£¼ëŠ” FC layerë¡œ êµ¬ì„±ëœë‹¤. ì´ ê²½ìš° ê³„ì‚°í•˜ëŠ” lossëŠ” ë‘ ê°œì´ê³ , í•™ìŠµí•˜ëŠ” dataëŠ” ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ê³¼ bounding boxê°€ ì •í•´ì§„ ground truthë¥¼ ê°€ì§„ í˜•íƒœì´ë‹¤. í•™ìŠµì„ í•  ë•Œ ë‘ ê°œì˜ lossì— ëŒ€í•œ ê°€ì¤‘í•©ì„ í•™ìŠµí•œë‹¤. ì´ ë•Œ ê° lossì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ hyper parameter í˜•íƒœë¡œ ì¡°ì ˆí•´ì¤˜ì•¼í•˜ê³ , ì´ëŸ° multi-lossì— ëŒ€í•œ hyper parameterë¥¼ ê²°ì •í•˜ëŠ” ì‘ì—…ì€ ê¹Œë‹¤ë¡­ë‹¤. two losses for classification and localization - ì¶œì²˜ : CS231n What is Object Detection? ì•ì„œ ë§í•œ classification + localizationê³¼ëŠ” ë‹¤ë¥´ê²Œ ê°ì²´ê°€ ì—¬ëŸ¬ê°œê°€ ì¡´ì¬í•´ì„œ, ê° ê°ì²´ì— ëŒ€í•œ bounding boxì™€ classë¥¼ ì •í•´ì¤˜ì•¼ í•˜ëŠ” taskì´ë‹¤. Object detectionì€ ê²°êµ­ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë‚´ì—ì„œ multi objectì— ëŒ€í•œ classification and localizationì„ í•œë‹¤ê³  ë³´ë©´ ëœë‹¤(í•™ìŠµì„ ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¤ë¦„). ì¶œì²˜ - YOLOv3: An Incremental Improvement Ideas Used for Object Detection Sliding Window Object detectionì„ ìœ„í•´ ì´ˆê¸°ì— ì‹œë„ ë˜ì—ˆë˜ ë°©ë²•ì´ë‹¤. Windowë¥¼ ì´ë¯¸ì§€ ë‚´ì—ì„œ sliding(ì´ë™) ì‹œí‚¤ë©´ì„œ ëª¨ë“  windowì˜ ê²½ìš°ì— ëŒ€í•´ classificationì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ì´ë‹¤. Semantic segmentationì˜ sliding windowì™€ ê±°ì˜ ë™ì¼í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° brute force ë°©ì‹ì˜ ì ‘ê·¼ì€ ê²°êµ­ ë„ˆë¬´ ë†’ì€ computational costë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì—, íŠ¹íˆ ë†’ì€ ìš©ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” computer visionì—ì„œ ì§€ì–‘í•´ì•¼í•œë‹¤. sliding window Region Proposal(RoI - Regions of Interest) ê°ì²´ê°€ ìˆì„ ë²•í•œ í›„ë³´êµ°ë“¤ì˜ region ì°¾ì•„ì„œ ê·¸ regionë“¤ì— ëŒ€í•´ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ì´ë‹¤. ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ìë©´, region proposalì„ ë½‘ì•„ì„œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì¤˜ì„œ object detectionì„ ìˆ˜í–‰í•œë‹¤ê³  ë³´ë©´ ëœë‹¤. ì´ ê²½ìš° ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ ë§ê³  ëª‡ëª‡(~2k)ê°œì˜ í›„ë³´êµ°ë§Œ í™•ì¸í•˜ë©´ ë˜ëŠ” ë°©ì‹ì´ë¼ê³  brute forceë³´ë‹¤ íš¨ìœ¨ì ì´ë‹¤. Region proposal ë°©ì‹ì€ R-CNN(Rich feature hierarchies for accurate object detection and semantic segmentation)ì˜ ë…¼ë¬¸ì— ì²˜ìŒ ì†Œê°œ ë˜ì—ˆë‹¤. R-CNN R-CNNì€ selective searchë¼ëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë²•(í•™ìŠµ x)ì„ í†µí•´ RoIë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤. ë½‘íŒ RoIì˜ ì‚¬ì´ì¦ˆëŠ” ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì—, classificationì„ ìœ„í•œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ê¸° ìœ„í•´ì„œëŠ” imageì˜ ì‚¬ì´ì¦ˆë¥¼ FC layerì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆê²Œ ì „ë¶€ ë™ì¼í•˜ê²Œ ê³ ì •ëœ ì‚¬ì´ì¦ˆë¡œ ë³€ê²½í•´ì¤˜ì•¼ í•œë‹¤. ì´ ë•Œ ë³€ê²½ëœ ì´ë¯¸ì§€ëŠ” warped image regionì´ë¼ê³  í•œë‹¤. Warped images ê°ê°ì€ CNN ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ ì‹œí‚¤ê³  classificationì„ ìœ„í•´ì„œ SVM(2014ë…„ì„ì„ ê³ ë ¤í•˜ì)ì„ ì‚¬ìš©í•œë‹¤. ë˜í•œ, RoIë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ regression ê³¼ì •ë„ ê±°ì¹œë‹¤. ë³´ì •ì˜ ê²½ìš° RoIì™€ bounding boxê°€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ offset ê°’ì„ 4ê°œ ì˜ˆì¸¡ í•´ì¤€ë‹¤ê³  ë³´ë©´ ëœë‹¤. R-CNN architecture - ì¶œì²˜ : CS231n â€‹ R-CNN ë°©ì‹ì€ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  selective searchë¥¼ í†µí•œ CNN ì—°ì‚°ì„ 2000ë²ˆ ë„˜ê²Œ ì—°ì‚°ìœ¼ë¡œ ì¸í•´ computational costê°€ ë†’ê³ , selective searchë„ cpuë¥¼ í†µí•œ ì—°ì‚°ì´ê¸° ë•Œë¬¸ì— ìƒëŒ€ì ìœ¼ë¡œ ì†ë„ê°€ ëŠë¦¬ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Fast R-CNNì´ ë“±ì¥ í–ˆë‹¤. Fast R-CNN Fast R-CNNì˜ ê²½ìš° ì•ì„œ ë§í•œ RCNNê³¼ ë™ì¼í•˜ê²Œ selective searchë¼ëŠ” region proposal methodë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, RCNNê³¼ ë‹¤ë¥¸ì ì€ selective searchë¡œ êµ¬í•œ RoI ê°ê°ì„ CNN ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼ì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ input image í•˜ë‚˜ì— ëŒ€í•´ CNNì— í†µê³¼ì‹œí‚¤ê³ , RoIë“¤ì€ ì¶•ì†Œëœ í˜•íƒœë¡œ ì—¬ëŸ¬ê°€ì§€ ì‚¬ì´ì¦ˆë¡œ feature mapì— ë‚˜íƒ€ë‚œë‹¤. ì´ë ‡ê²Œ í•œë‹¤ë©´, RCNNê³¼ ë‹¤ë¥´ê²Œ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ CNNì„ ì—°ì‚°í•˜ê³ , ê°ê°ì˜ RoIì— ëŒ€í•´ì„œ classificationê³¼ regressionì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— ë” íš¨ìœ¨ì ì´ë‹¤. ì¡°ê¸ˆ ë” ì„¸ë¶€í•˜ê²Œ ê³¼ì •ì„ ì‚´í”¼ìë©´, feature mapì˜ RoIë“¤ì€ ì‚¬ì´ì¦ˆê°€ ì œê°ê° ì´ê¸° ë•Œë¬¸ì— RoI poolingì´ë¼ëŠ” ê³¼ì •ì„ í†µí•´ì„œ FC layerì˜ ì…ë ¥ì— ë„£ì„ ìˆ˜ ìˆë„ë¡ ê³ ì •ëœ í¬ê¸°ì˜ vectorë¡œ ë³€í™˜í•´ì•¼í•œë‹¤. ì´ RoI feature vectorëŠ” softmax ì—°ì‚°ì„ í†µí•´ classificationì„ í•˜ê³ , bounding box regressionìœ¼ë¡œ bounding boxë¥¼ ìœ„í•œ ë³´ì •ê°’ì„ ì˜ˆì¸¡í•œë‹¤. Fast R-CNN architecture - ì¶œì²˜ : Fast R-CNN, CS231n Fast R-CNNì—ì„œë„ í•œê³„ì ì€ ìˆë‹¤. í•™ìŠµ ì‹œí‚¤ì§€ ì•ŠëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ì˜ selective searchê°€ bottleneckì˜ ì›ì¸ ë˜ì—ˆê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ Faster R-CNNì´ë¼ëŠ” ë°©ë²•ì´ ë“±ì¥í–ˆë‹¤. Faster R-CNN ì•ì˜ Fast R-CNNì˜ í•œê³„ëŠ” ê²°êµ­ region proposal ë‹¨ê³„ì˜ bottleneck ë•Œë¬¸ì´ë‹¤. Faster R-CNNì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„¤íŠ¸ì›Œí¬ê°€ region proposalì„ í•™ìŠµ í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê°„ë‹¨íˆ ë§í•˜ìë©´ RPN(Region Proposal Network)ë¥¼ RoI poolingê³¼ í•¨ê»˜ GPUë‹¨ì—ì„œ í•´ê²° í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. Faster R-CNN architecture - ì¶œì²˜ : CS231n ì§€ê¸ˆê¹Œì§€ ì„¤ëª…í•œ R-CNN ê³„ì—´ì˜ ë„¤íŠ¸ì›Œí¬ë“¤ì€ region based methodë¥¼ ì‚¬ìš©í•˜ëŠ” 2 stage detector ë°©ì‹ì´ë‹¤. ì´ ë‹¤ìŒìœ¼ë¡œ 1 stage detectorì™€ 2 stage detectorì˜ ì°¨ì´ ê·¸ë¦¬ê³  ëŒ€í‘œì ì¸ 1 stage detector ë°©ì‹ì¸ YOLOë¥¼ ì‚´í´ë³´ì. R-CNN comparison - ì¶œì²˜ : Recent Advances in Deep Learning for Object Detection 1-stage detector vs 2-stage detector 1 stage vs 2 stage - ì¶œì²˜ : A Survey of Deep Learning-Based Object Detection 2 stage detector localizationê³¼ classificationì„ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²° ì†ë„ê°€ ëŠë¦¼ RCNN familyê°€ ëŒ€í‘œì ì¸ 2 stage detector 1 stage detector localizationê³¼ classificationì„ ë™ì‹œì— í•´ê²° feature extractionê³¼ object detectionì´ ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì´ë£¨ì–´ì§€ëŠ” ê°„ë‹¨í•œ ë””ìì¸ ì†ë„ê°€ ë¹ ë¦„(real time detectionì´ ê°€ëŠ¥) ë‚®ì€ background error YOLOê°€ ëŒ€í‘œì ì¸ 1 stage detector Metrics For Object Detection Precision and Recall precision and recall - ì¶œì²˜ : https://www.datacamp.com/tutorial/precision-recall-curve-tutorial accuracy - ì¶œì²˜ : https://www.datacamp.com/tutorial/precision-recall-curve-tutorial Precision(ì •í™•ë„) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ëª¨ë¸ì´ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP+FP) Recall(ì¬í˜„ìœ¨) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ì‹¤ì œ ì •ë‹µ ë¬¼ì²´ì˜ ìˆ˜(TP+FN) ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì— ë”°ë¥¸ Trade Off ëª¨ë“  ì˜ì—­ì— ëŒ€í•˜ì—¬ ì „ë¬´ ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì¬í˜„ìœ¨ì€ ë†’ì•„ì§€ì§€ë§Œ ì •í™•ë„ê°€ ë–¨ì–´ì§„ë‹¤. í™•ì‹¤í•  ë•Œë§Œ(confident í•œ ê²½ìš°ë§Œ) ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì •í™•ë„ëŠ” ë†’ì•„ì§€ì§€ë§Œ, ì¬í˜„ìœ¨ì´ ë–¨ì–´ì§„ë‹¤. Mean Average Precision (mAP) ì¶œì²˜ - End-to-end training of object class detectors for mean average precision ì¶œì²˜ - End-to-end training of object class detectors for mean average precision Precisionê³¼ recallì€ ë³´í†µ ë°˜ë¹„ë¡€ ê´€ê³„ë¥¼ ê°€ì§„ë‹¤. mAPë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ê° í´ë˜ìŠ¤ì˜ average precision(AP)ë¥¼ ê³„ì‚°í•œë‹¤. APëŠ” ê° precision-recall ê·¸ë˜í”„ì˜ ë„“ì´ë¡œ ê³„ì‚° í•  ìˆ˜ ìˆë‹¤. ê·¸ ë‹¤ìŒ ëª¨ë“  APë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•˜ë©´ mAPë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. Intersection over Union (IoU) True Positive(TP)ì™€ False Positive(FP)ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ IoUë¥¼ ì‚¬ìš©í•œë‹¤. IoUë¥¼ ê°„ëµíˆ ì„¤ëª…í•˜ìë©´ ë‘ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨ë¡œ ìƒê° í•  ìˆ˜ ìˆë‹¤. ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ mAP@0.5ëŠ” ground truthì™€ predictionì˜ IoUê°€ 50% ì´ìƒì¼ ë•Œ ì •ë‹µìœ¼ë¡œ íŒì •í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ NMS ê³„ì‚°ì˜ ê²½ìš°, ê°™ì€ í´ë˜ìŠ¤ë¼ë¦¬ IoUê°€ 50% ì´ìƒì¼ ë•Œ ë‚®ì€ confidenceì˜ bounding boxë¥¼ ì œê±°í•œë‹¤ Non Maximum Suppression (NMS) ì˜ë¯¸ë§Œ í•´ì„í•˜ìë©´ ì œì¼ í° ê²ƒì„ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” suppress í•˜ìëŠ” ì˜ë¯¸ì´ë‹¤. Object detectionì—ì„œ í•˜ë‚˜ì˜ instanceì—ëŠ” í•˜ë‚˜ì˜ bounding boxê°€ ì ìš©ë˜ì–´ì•¼ í•œë‹¤. ê·¸ë ‡ê²Œ ë•Œë¬¸ì— í•˜ë‚˜ì˜ ë¬¼ì²´ì— ëŒ€í•´ ì—¬ëŸ¬ê°œì˜ bounding boxê°€ ê²¹ì³ì ¸ ìˆì„ ê²½ìš° í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë°©ë²•ì´ í•„ìš”í•˜ë‹¤. NMSëŠ” ë³´í†µ IoUê°€ íŠ¹ì • thresholdë¥¼ ë„˜ì–´ê°€ëŠ” ì¤‘ë³µë˜ëŠ” boxë¥¼ ì œê±°í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì¶œì²˜ - https://wikidocs.net/163295 YOLO (You Look Only Once) YOLO timeline - ì¶œì²˜ : https://www.researchgate.net/figure/Timeline-of-You-Only-Look-Once-YOLO-variants_fig1_369379818 YOLO v1 : í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì˜ bboxì™€ classificationì„ ë™ì‹œì— ì˜ˆì¸¡í•˜ëŠ” 1 stage detectorì˜ ë“±ì¥ YOLO v3 : multi scale feature mapì˜ ì‚¬ìš© YOLO v5 : small, medium, large í¬ê¸° ë³„ë¡œ ëª¨ë¸ êµ¬ì„± Unified Detection in YOLO detection in YOLO - ì¶œì²˜ : You Only Look Once YOLOì—ì„œ object detectionì„ regression problemìœ¼ë¡œ ì „í™˜í•´ì„œ í’€ê³  ìˆë‹¤. ë˜í•œ ê°„ë‹¨í•œ êµ¬ì¡°ì˜ end to end ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. YOLOì—ì„œ unified detectionì˜ ê³¼ì •ì„ ì„¤ëª…í•˜ìë©´, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ SxS ê·¸ë¦¬ë“œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ê·¸ë¦¬ë“œ ì˜ì—­ë§ˆë‹¤ Bê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³  Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. (parameter used in YOLO, S=7, B=2, C=20) Confidence scoreëŠ” ê·¸ë¦¬ë“œì—ì„œ (objectê°€ ì¡´ì¬í•  í™•ë¥ ) x (ground truthì™€ IoU)ë¡œ ê³„ì‚°í•œë‹¤. ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. \(confidence = Pr(object) \times IoU^{truth}_{pred}\) Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤. \(class probability = Pr(Class_{i}|Object)\) ê°„ë‹¨í•˜ê²Œ ìš”ì•½ì„ í•˜ìë©´, input ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì´ë¯¸ì§€ë¥¼ 7x7(49ê°œ)ì˜ ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ„ê³ , ê° ê·¸ë¦¬ë“œ ë§ˆë‹¤ 2ê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³ , ê° ê·¸ë¦¬ë“œ(49ê°œì˜ ê·¸ë¦¬ë“œ)ë§ˆë‹¤ ì–´ë–¤ í´ë˜ìŠ¤ì¸ì§€ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. Network Design of YOLO YOLO&#39;s architecture - ì¶œì²˜ : You Only Look Once googlenetì˜ ë³€í˜• ì‚¬ìš© 24 conv layers for feature extraction 2 fully connected layers for prediction output tensor of YOLO - ì¶œì²˜ : https://wikidocs.net/187967 outputì€ 7x7x30ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ bbox 1, 2ì— ëŒ€í•œ (xì¢Œí‘œ, yì¢Œí‘œ, ë„ˆë¹„, ë†’ì´, confidence score) + 20ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  Inference ê° bounding boxì˜ confidence scoreë¥¼ 20ê°œì˜ í´ë˜ìŠ¤ í™•ë¥ ê³¼ ê³±í•´ì„œ ê° bounding boxê°€ ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì–´ë–¤ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. YOLO test time - ì¶œì²˜ : You Only Look Once 49ê°œì˜ ê·¸ë¦¬ë“œë‹¹ 2ê°œì˜ bounding boxë¥¼ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— ì´ 98ê°œì˜ boxì— ëŒ€í•œ class specific confidence scoreë¥¼ ê³„ì‚°í•œë‹¤. Advantages and Disadvantages of YOLO ì¥ì  ì†ë„ê°€ ë¹¨ë¼ì„œ real time detectionì— í™œìš© ê°€ëŠ¥í•˜ë‹¤ ë¬¼ì²´ì˜ ì¼ë°˜í™”ëœ íŠ¹ì§•ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ ë‹¨ì  ê·¸ë¦¬ë“œë³´ë‹¤ ì‘ì€ í¬ê¸°ì˜ ë¬¼ì²´ ê²€ì¶œì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ ì‹ ê²½ë§ì„ í†µê³¼í•  ë•Œ ë§ˆì§€ë§‰ featureë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì •í™•ë„ê°€ í•˜ë½í•œë‹¤ Further Studying Object Detectionì˜ milestoneì„ í™•ì¸í•´ë³´ê¸° YOLO vs SSD ë¹„êµí•´ë³´ê¸° ìµœê·¼ SOTA Object Detection ëª¨ë¸ë“¤ì˜ íŠ¸ë Œë“œ ì‚´í´ë³´ê¸° ì°¸ê³  You Only Look Once: Unified, Real-Time Object Detection End-to-end training of object class detectors for mean average precision Rich feature hierarchies for accurate object detection and semantic segmentation boostcourse : ì¬í™œìš© ì“°ë ˆê¸°ë¥¼ í™œìš©í•œ ë”¥ëŸ¬ë‹ - Detection CS231n" />
<meta property="og:description" content="Object Detection Classification + Localization í•˜ë‚˜ì˜ ê°ì²´ì— ëŒ€í•´ì„œ í´ë˜ìŠ¤ë¥¼ íŒë³„ í•˜ê³ , ê·¸ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ëŠ” bounding boxë¥¼ ì°¾ì•„ì£¼ëŠ” ì‘ì—…ì„ classification and localization taskë¼ê³  í•œë‹¤. ê¸°ë³¸ì ì¸ ì•„í‚¤í…ì³ì˜ ê²½ìš° CNN ë„¤íŠ¸ì›Œí¬ì— class scoreë¥¼ ì •í•´ì£¼ëŠ” FC layerì™€ box coordinateì„ ì •í•´ì£¼ëŠ” FC layerë¡œ êµ¬ì„±ëœë‹¤. ì´ ê²½ìš° ê³„ì‚°í•˜ëŠ” lossëŠ” ë‘ ê°œì´ê³ , í•™ìŠµí•˜ëŠ” dataëŠ” ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ê³¼ bounding boxê°€ ì •í•´ì§„ ground truthë¥¼ ê°€ì§„ í˜•íƒœì´ë‹¤. í•™ìŠµì„ í•  ë•Œ ë‘ ê°œì˜ lossì— ëŒ€í•œ ê°€ì¤‘í•©ì„ í•™ìŠµí•œë‹¤. ì´ ë•Œ ê° lossì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ hyper parameter í˜•íƒœë¡œ ì¡°ì ˆí•´ì¤˜ì•¼í•˜ê³ , ì´ëŸ° multi-lossì— ëŒ€í•œ hyper parameterë¥¼ ê²°ì •í•˜ëŠ” ì‘ì—…ì€ ê¹Œë‹¤ë¡­ë‹¤. two losses for classification and localization - ì¶œì²˜ : CS231n What is Object Detection? ì•ì„œ ë§í•œ classification + localizationê³¼ëŠ” ë‹¤ë¥´ê²Œ ê°ì²´ê°€ ì—¬ëŸ¬ê°œê°€ ì¡´ì¬í•´ì„œ, ê° ê°ì²´ì— ëŒ€í•œ bounding boxì™€ classë¥¼ ì •í•´ì¤˜ì•¼ í•˜ëŠ” taskì´ë‹¤. Object detectionì€ ê²°êµ­ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë‚´ì—ì„œ multi objectì— ëŒ€í•œ classification and localizationì„ í•œë‹¤ê³  ë³´ë©´ ëœë‹¤(í•™ìŠµì„ ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¤ë¦„). ì¶œì²˜ - YOLOv3: An Incremental Improvement Ideas Used for Object Detection Sliding Window Object detectionì„ ìœ„í•´ ì´ˆê¸°ì— ì‹œë„ ë˜ì—ˆë˜ ë°©ë²•ì´ë‹¤. Windowë¥¼ ì´ë¯¸ì§€ ë‚´ì—ì„œ sliding(ì´ë™) ì‹œí‚¤ë©´ì„œ ëª¨ë“  windowì˜ ê²½ìš°ì— ëŒ€í•´ classificationì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ì´ë‹¤. Semantic segmentationì˜ sliding windowì™€ ê±°ì˜ ë™ì¼í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° brute force ë°©ì‹ì˜ ì ‘ê·¼ì€ ê²°êµ­ ë„ˆë¬´ ë†’ì€ computational costë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì—, íŠ¹íˆ ë†’ì€ ìš©ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” computer visionì—ì„œ ì§€ì–‘í•´ì•¼í•œë‹¤. sliding window Region Proposal(RoI - Regions of Interest) ê°ì²´ê°€ ìˆì„ ë²•í•œ í›„ë³´êµ°ë“¤ì˜ region ì°¾ì•„ì„œ ê·¸ regionë“¤ì— ëŒ€í•´ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ì´ë‹¤. ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ìë©´, region proposalì„ ë½‘ì•„ì„œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì¤˜ì„œ object detectionì„ ìˆ˜í–‰í•œë‹¤ê³  ë³´ë©´ ëœë‹¤. ì´ ê²½ìš° ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ ë§ê³  ëª‡ëª‡(~2k)ê°œì˜ í›„ë³´êµ°ë§Œ í™•ì¸í•˜ë©´ ë˜ëŠ” ë°©ì‹ì´ë¼ê³  brute forceë³´ë‹¤ íš¨ìœ¨ì ì´ë‹¤. Region proposal ë°©ì‹ì€ R-CNN(Rich feature hierarchies for accurate object detection and semantic segmentation)ì˜ ë…¼ë¬¸ì— ì²˜ìŒ ì†Œê°œ ë˜ì—ˆë‹¤. R-CNN R-CNNì€ selective searchë¼ëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë²•(í•™ìŠµ x)ì„ í†µí•´ RoIë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤. ë½‘íŒ RoIì˜ ì‚¬ì´ì¦ˆëŠ” ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì—, classificationì„ ìœ„í•œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ê¸° ìœ„í•´ì„œëŠ” imageì˜ ì‚¬ì´ì¦ˆë¥¼ FC layerì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆê²Œ ì „ë¶€ ë™ì¼í•˜ê²Œ ê³ ì •ëœ ì‚¬ì´ì¦ˆë¡œ ë³€ê²½í•´ì¤˜ì•¼ í•œë‹¤. ì´ ë•Œ ë³€ê²½ëœ ì´ë¯¸ì§€ëŠ” warped image regionì´ë¼ê³  í•œë‹¤. Warped images ê°ê°ì€ CNN ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ ì‹œí‚¤ê³  classificationì„ ìœ„í•´ì„œ SVM(2014ë…„ì„ì„ ê³ ë ¤í•˜ì)ì„ ì‚¬ìš©í•œë‹¤. ë˜í•œ, RoIë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ regression ê³¼ì •ë„ ê±°ì¹œë‹¤. ë³´ì •ì˜ ê²½ìš° RoIì™€ bounding boxê°€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ offset ê°’ì„ 4ê°œ ì˜ˆì¸¡ í•´ì¤€ë‹¤ê³  ë³´ë©´ ëœë‹¤. R-CNN architecture - ì¶œì²˜ : CS231n â€‹ R-CNN ë°©ì‹ì€ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  selective searchë¥¼ í†µí•œ CNN ì—°ì‚°ì„ 2000ë²ˆ ë„˜ê²Œ ì—°ì‚°ìœ¼ë¡œ ì¸í•´ computational costê°€ ë†’ê³ , selective searchë„ cpuë¥¼ í†µí•œ ì—°ì‚°ì´ê¸° ë•Œë¬¸ì— ìƒëŒ€ì ìœ¼ë¡œ ì†ë„ê°€ ëŠë¦¬ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Fast R-CNNì´ ë“±ì¥ í–ˆë‹¤. Fast R-CNN Fast R-CNNì˜ ê²½ìš° ì•ì„œ ë§í•œ RCNNê³¼ ë™ì¼í•˜ê²Œ selective searchë¼ëŠ” region proposal methodë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, RCNNê³¼ ë‹¤ë¥¸ì ì€ selective searchë¡œ êµ¬í•œ RoI ê°ê°ì„ CNN ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼ì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ input image í•˜ë‚˜ì— ëŒ€í•´ CNNì— í†µê³¼ì‹œí‚¤ê³ , RoIë“¤ì€ ì¶•ì†Œëœ í˜•íƒœë¡œ ì—¬ëŸ¬ê°€ì§€ ì‚¬ì´ì¦ˆë¡œ feature mapì— ë‚˜íƒ€ë‚œë‹¤. ì´ë ‡ê²Œ í•œë‹¤ë©´, RCNNê³¼ ë‹¤ë¥´ê²Œ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ CNNì„ ì—°ì‚°í•˜ê³ , ê°ê°ì˜ RoIì— ëŒ€í•´ì„œ classificationê³¼ regressionì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— ë” íš¨ìœ¨ì ì´ë‹¤. ì¡°ê¸ˆ ë” ì„¸ë¶€í•˜ê²Œ ê³¼ì •ì„ ì‚´í”¼ìë©´, feature mapì˜ RoIë“¤ì€ ì‚¬ì´ì¦ˆê°€ ì œê°ê° ì´ê¸° ë•Œë¬¸ì— RoI poolingì´ë¼ëŠ” ê³¼ì •ì„ í†µí•´ì„œ FC layerì˜ ì…ë ¥ì— ë„£ì„ ìˆ˜ ìˆë„ë¡ ê³ ì •ëœ í¬ê¸°ì˜ vectorë¡œ ë³€í™˜í•´ì•¼í•œë‹¤. ì´ RoI feature vectorëŠ” softmax ì—°ì‚°ì„ í†µí•´ classificationì„ í•˜ê³ , bounding box regressionìœ¼ë¡œ bounding boxë¥¼ ìœ„í•œ ë³´ì •ê°’ì„ ì˜ˆì¸¡í•œë‹¤. Fast R-CNN architecture - ì¶œì²˜ : Fast R-CNN, CS231n Fast R-CNNì—ì„œë„ í•œê³„ì ì€ ìˆë‹¤. í•™ìŠµ ì‹œí‚¤ì§€ ì•ŠëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ì˜ selective searchê°€ bottleneckì˜ ì›ì¸ ë˜ì—ˆê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ Faster R-CNNì´ë¼ëŠ” ë°©ë²•ì´ ë“±ì¥í–ˆë‹¤. Faster R-CNN ì•ì˜ Fast R-CNNì˜ í•œê³„ëŠ” ê²°êµ­ region proposal ë‹¨ê³„ì˜ bottleneck ë•Œë¬¸ì´ë‹¤. Faster R-CNNì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„¤íŠ¸ì›Œí¬ê°€ region proposalì„ í•™ìŠµ í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê°„ë‹¨íˆ ë§í•˜ìë©´ RPN(Region Proposal Network)ë¥¼ RoI poolingê³¼ í•¨ê»˜ GPUë‹¨ì—ì„œ í•´ê²° í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. Faster R-CNN architecture - ì¶œì²˜ : CS231n ì§€ê¸ˆê¹Œì§€ ì„¤ëª…í•œ R-CNN ê³„ì—´ì˜ ë„¤íŠ¸ì›Œí¬ë“¤ì€ region based methodë¥¼ ì‚¬ìš©í•˜ëŠ” 2 stage detector ë°©ì‹ì´ë‹¤. ì´ ë‹¤ìŒìœ¼ë¡œ 1 stage detectorì™€ 2 stage detectorì˜ ì°¨ì´ ê·¸ë¦¬ê³  ëŒ€í‘œì ì¸ 1 stage detector ë°©ì‹ì¸ YOLOë¥¼ ì‚´í´ë³´ì. R-CNN comparison - ì¶œì²˜ : Recent Advances in Deep Learning for Object Detection 1-stage detector vs 2-stage detector 1 stage vs 2 stage - ì¶œì²˜ : A Survey of Deep Learning-Based Object Detection 2 stage detector localizationê³¼ classificationì„ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²° ì†ë„ê°€ ëŠë¦¼ RCNN familyê°€ ëŒ€í‘œì ì¸ 2 stage detector 1 stage detector localizationê³¼ classificationì„ ë™ì‹œì— í•´ê²° feature extractionê³¼ object detectionì´ ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì´ë£¨ì–´ì§€ëŠ” ê°„ë‹¨í•œ ë””ìì¸ ì†ë„ê°€ ë¹ ë¦„(real time detectionì´ ê°€ëŠ¥) ë‚®ì€ background error YOLOê°€ ëŒ€í‘œì ì¸ 1 stage detector Metrics For Object Detection Precision and Recall precision and recall - ì¶œì²˜ : https://www.datacamp.com/tutorial/precision-recall-curve-tutorial accuracy - ì¶œì²˜ : https://www.datacamp.com/tutorial/precision-recall-curve-tutorial Precision(ì •í™•ë„) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ëª¨ë¸ì´ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP+FP) Recall(ì¬í˜„ìœ¨) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ì‹¤ì œ ì •ë‹µ ë¬¼ì²´ì˜ ìˆ˜(TP+FN) ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì— ë”°ë¥¸ Trade Off ëª¨ë“  ì˜ì—­ì— ëŒ€í•˜ì—¬ ì „ë¬´ ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì¬í˜„ìœ¨ì€ ë†’ì•„ì§€ì§€ë§Œ ì •í™•ë„ê°€ ë–¨ì–´ì§„ë‹¤. í™•ì‹¤í•  ë•Œë§Œ(confident í•œ ê²½ìš°ë§Œ) ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì •í™•ë„ëŠ” ë†’ì•„ì§€ì§€ë§Œ, ì¬í˜„ìœ¨ì´ ë–¨ì–´ì§„ë‹¤. Mean Average Precision (mAP) ì¶œì²˜ - End-to-end training of object class detectors for mean average precision ì¶œì²˜ - End-to-end training of object class detectors for mean average precision Precisionê³¼ recallì€ ë³´í†µ ë°˜ë¹„ë¡€ ê´€ê³„ë¥¼ ê°€ì§„ë‹¤. mAPë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ê° í´ë˜ìŠ¤ì˜ average precision(AP)ë¥¼ ê³„ì‚°í•œë‹¤. APëŠ” ê° precision-recall ê·¸ë˜í”„ì˜ ë„“ì´ë¡œ ê³„ì‚° í•  ìˆ˜ ìˆë‹¤. ê·¸ ë‹¤ìŒ ëª¨ë“  APë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•˜ë©´ mAPë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. Intersection over Union (IoU) True Positive(TP)ì™€ False Positive(FP)ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ IoUë¥¼ ì‚¬ìš©í•œë‹¤. IoUë¥¼ ê°„ëµíˆ ì„¤ëª…í•˜ìë©´ ë‘ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨ë¡œ ìƒê° í•  ìˆ˜ ìˆë‹¤. ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ mAP@0.5ëŠ” ground truthì™€ predictionì˜ IoUê°€ 50% ì´ìƒì¼ ë•Œ ì •ë‹µìœ¼ë¡œ íŒì •í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ NMS ê³„ì‚°ì˜ ê²½ìš°, ê°™ì€ í´ë˜ìŠ¤ë¼ë¦¬ IoUê°€ 50% ì´ìƒì¼ ë•Œ ë‚®ì€ confidenceì˜ bounding boxë¥¼ ì œê±°í•œë‹¤ Non Maximum Suppression (NMS) ì˜ë¯¸ë§Œ í•´ì„í•˜ìë©´ ì œì¼ í° ê²ƒì„ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” suppress í•˜ìëŠ” ì˜ë¯¸ì´ë‹¤. Object detectionì—ì„œ í•˜ë‚˜ì˜ instanceì—ëŠ” í•˜ë‚˜ì˜ bounding boxê°€ ì ìš©ë˜ì–´ì•¼ í•œë‹¤. ê·¸ë ‡ê²Œ ë•Œë¬¸ì— í•˜ë‚˜ì˜ ë¬¼ì²´ì— ëŒ€í•´ ì—¬ëŸ¬ê°œì˜ bounding boxê°€ ê²¹ì³ì ¸ ìˆì„ ê²½ìš° í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë°©ë²•ì´ í•„ìš”í•˜ë‹¤. NMSëŠ” ë³´í†µ IoUê°€ íŠ¹ì • thresholdë¥¼ ë„˜ì–´ê°€ëŠ” ì¤‘ë³µë˜ëŠ” boxë¥¼ ì œê±°í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì¶œì²˜ - https://wikidocs.net/163295 YOLO (You Look Only Once) YOLO timeline - ì¶œì²˜ : https://www.researchgate.net/figure/Timeline-of-You-Only-Look-Once-YOLO-variants_fig1_369379818 YOLO v1 : í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì˜ bboxì™€ classificationì„ ë™ì‹œì— ì˜ˆì¸¡í•˜ëŠ” 1 stage detectorì˜ ë“±ì¥ YOLO v3 : multi scale feature mapì˜ ì‚¬ìš© YOLO v5 : small, medium, large í¬ê¸° ë³„ë¡œ ëª¨ë¸ êµ¬ì„± Unified Detection in YOLO detection in YOLO - ì¶œì²˜ : You Only Look Once YOLOì—ì„œ object detectionì„ regression problemìœ¼ë¡œ ì „í™˜í•´ì„œ í’€ê³  ìˆë‹¤. ë˜í•œ ê°„ë‹¨í•œ êµ¬ì¡°ì˜ end to end ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. YOLOì—ì„œ unified detectionì˜ ê³¼ì •ì„ ì„¤ëª…í•˜ìë©´, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ SxS ê·¸ë¦¬ë“œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ê·¸ë¦¬ë“œ ì˜ì—­ë§ˆë‹¤ Bê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³  Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. (parameter used in YOLO, S=7, B=2, C=20) Confidence scoreëŠ” ê·¸ë¦¬ë“œì—ì„œ (objectê°€ ì¡´ì¬í•  í™•ë¥ ) x (ground truthì™€ IoU)ë¡œ ê³„ì‚°í•œë‹¤. ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. \(confidence = Pr(object) \times IoU^{truth}_{pred}\) Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤. \(class probability = Pr(Class_{i}|Object)\) ê°„ë‹¨í•˜ê²Œ ìš”ì•½ì„ í•˜ìë©´, input ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì´ë¯¸ì§€ë¥¼ 7x7(49ê°œ)ì˜ ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ„ê³ , ê° ê·¸ë¦¬ë“œ ë§ˆë‹¤ 2ê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³ , ê° ê·¸ë¦¬ë“œ(49ê°œì˜ ê·¸ë¦¬ë“œ)ë§ˆë‹¤ ì–´ë–¤ í´ë˜ìŠ¤ì¸ì§€ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. Network Design of YOLO YOLO&#39;s architecture - ì¶œì²˜ : You Only Look Once googlenetì˜ ë³€í˜• ì‚¬ìš© 24 conv layers for feature extraction 2 fully connected layers for prediction output tensor of YOLO - ì¶œì²˜ : https://wikidocs.net/187967 outputì€ 7x7x30ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ bbox 1, 2ì— ëŒ€í•œ (xì¢Œí‘œ, yì¢Œí‘œ, ë„ˆë¹„, ë†’ì´, confidence score) + 20ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  Inference ê° bounding boxì˜ confidence scoreë¥¼ 20ê°œì˜ í´ë˜ìŠ¤ í™•ë¥ ê³¼ ê³±í•´ì„œ ê° bounding boxê°€ ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì–´ë–¤ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. YOLO test time - ì¶œì²˜ : You Only Look Once 49ê°œì˜ ê·¸ë¦¬ë“œë‹¹ 2ê°œì˜ bounding boxë¥¼ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— ì´ 98ê°œì˜ boxì— ëŒ€í•œ class specific confidence scoreë¥¼ ê³„ì‚°í•œë‹¤. Advantages and Disadvantages of YOLO ì¥ì  ì†ë„ê°€ ë¹¨ë¼ì„œ real time detectionì— í™œìš© ê°€ëŠ¥í•˜ë‹¤ ë¬¼ì²´ì˜ ì¼ë°˜í™”ëœ íŠ¹ì§•ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ ë‹¨ì  ê·¸ë¦¬ë“œë³´ë‹¤ ì‘ì€ í¬ê¸°ì˜ ë¬¼ì²´ ê²€ì¶œì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ ì‹ ê²½ë§ì„ í†µê³¼í•  ë•Œ ë§ˆì§€ë§‰ featureë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì •í™•ë„ê°€ í•˜ë½í•œë‹¤ Further Studying Object Detectionì˜ milestoneì„ í™•ì¸í•´ë³´ê¸° YOLO vs SSD ë¹„êµí•´ë³´ê¸° ìµœê·¼ SOTA Object Detection ëª¨ë¸ë“¤ì˜ íŠ¸ë Œë“œ ì‚´í´ë³´ê¸° ì°¸ê³  You Only Look Once: Unified, Real-Time Object Detection End-to-end training of object class detectors for mean average precision Rich feature hierarchies for accurate object detection and semantic segmentation boostcourse : ì¬í™œìš© ì“°ë ˆê¸°ë¥¼ í™œìš©í•œ ë”¥ëŸ¬ë‹ - Detection CS231n" />
<link rel="canonical" href="http://localhost:4000/objectdetection/" />
<meta property="og:url" content="http://localhost:4000/objectdetection/" />
<meta property="og:site_name" content="Seungki1011â€™s Dev Blog" />
<meta property="og:image" content="http://localhost:4000/post_images/objectdetection.jpeg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-04-29T00:00:00+09:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/post_images/objectdetection.jpeg" />
<meta property="twitter:title" content="Object Detection Overview" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"seungki"},"dateModified":"2023-04-29T00:00:00+09:00","datePublished":"2023-04-29T00:00:00+09:00","description":"Object Detection Classification + Localization í•˜ë‚˜ì˜ ê°ì²´ì— ëŒ€í•´ì„œ í´ë˜ìŠ¤ë¥¼ íŒë³„ í•˜ê³ , ê·¸ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ëŠ” bounding boxë¥¼ ì°¾ì•„ì£¼ëŠ” ì‘ì—…ì„ classification and localization taskë¼ê³  í•œë‹¤. ê¸°ë³¸ì ì¸ ì•„í‚¤í…ì³ì˜ ê²½ìš° CNN ë„¤íŠ¸ì›Œí¬ì— class scoreë¥¼ ì •í•´ì£¼ëŠ” FC layerì™€ box coordinateì„ ì •í•´ì£¼ëŠ” FC layerë¡œ êµ¬ì„±ëœë‹¤. ì´ ê²½ìš° ê³„ì‚°í•˜ëŠ” lossëŠ” ë‘ ê°œì´ê³ , í•™ìŠµí•˜ëŠ” dataëŠ” ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ê³¼ bounding boxê°€ ì •í•´ì§„ ground truthë¥¼ ê°€ì§„ í˜•íƒœì´ë‹¤. í•™ìŠµì„ í•  ë•Œ ë‘ ê°œì˜ lossì— ëŒ€í•œ ê°€ì¤‘í•©ì„ í•™ìŠµí•œë‹¤. ì´ ë•Œ ê° lossì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ hyper parameter í˜•íƒœë¡œ ì¡°ì ˆí•´ì¤˜ì•¼í•˜ê³ , ì´ëŸ° multi-lossì— ëŒ€í•œ hyper parameterë¥¼ ê²°ì •í•˜ëŠ” ì‘ì—…ì€ ê¹Œë‹¤ë¡­ë‹¤. two losses for classification and localization - ì¶œì²˜ : CS231n What is Object Detection? ì•ì„œ ë§í•œ classification + localizationê³¼ëŠ” ë‹¤ë¥´ê²Œ ê°ì²´ê°€ ì—¬ëŸ¬ê°œê°€ ì¡´ì¬í•´ì„œ, ê° ê°ì²´ì— ëŒ€í•œ bounding boxì™€ classë¥¼ ì •í•´ì¤˜ì•¼ í•˜ëŠ” taskì´ë‹¤. Object detectionì€ ê²°êµ­ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë‚´ì—ì„œ multi objectì— ëŒ€í•œ classification and localizationì„ í•œë‹¤ê³  ë³´ë©´ ëœë‹¤(í•™ìŠµì„ ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¤ë¦„). ì¶œì²˜ - YOLOv3: An Incremental Improvement Ideas Used for Object Detection Sliding Window Object detectionì„ ìœ„í•´ ì´ˆê¸°ì— ì‹œë„ ë˜ì—ˆë˜ ë°©ë²•ì´ë‹¤. Windowë¥¼ ì´ë¯¸ì§€ ë‚´ì—ì„œ sliding(ì´ë™) ì‹œí‚¤ë©´ì„œ ëª¨ë“  windowì˜ ê²½ìš°ì— ëŒ€í•´ classificationì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ì´ë‹¤. Semantic segmentationì˜ sliding windowì™€ ê±°ì˜ ë™ì¼í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° brute force ë°©ì‹ì˜ ì ‘ê·¼ì€ ê²°êµ­ ë„ˆë¬´ ë†’ì€ computational costë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì—, íŠ¹íˆ ë†’ì€ ìš©ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” computer visionì—ì„œ ì§€ì–‘í•´ì•¼í•œë‹¤. sliding window Region Proposal(RoI - Regions of Interest) ê°ì²´ê°€ ìˆì„ ë²•í•œ í›„ë³´êµ°ë“¤ì˜ region ì°¾ì•„ì„œ ê·¸ regionë“¤ì— ëŒ€í•´ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ì´ë‹¤. ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ìë©´, region proposalì„ ë½‘ì•„ì„œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì¤˜ì„œ object detectionì„ ìˆ˜í–‰í•œë‹¤ê³  ë³´ë©´ ëœë‹¤. ì´ ê²½ìš° ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ ë§ê³  ëª‡ëª‡(~2k)ê°œì˜ í›„ë³´êµ°ë§Œ í™•ì¸í•˜ë©´ ë˜ëŠ” ë°©ì‹ì´ë¼ê³  brute forceë³´ë‹¤ íš¨ìœ¨ì ì´ë‹¤. Region proposal ë°©ì‹ì€ R-CNN(Rich feature hierarchies for accurate object detection and semantic segmentation)ì˜ ë…¼ë¬¸ì— ì²˜ìŒ ì†Œê°œ ë˜ì—ˆë‹¤. R-CNN R-CNNì€ selective searchë¼ëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë²•(í•™ìŠµ x)ì„ í†µí•´ RoIë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤. ë½‘íŒ RoIì˜ ì‚¬ì´ì¦ˆëŠ” ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì—, classificationì„ ìœ„í•œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ê¸° ìœ„í•´ì„œëŠ” imageì˜ ì‚¬ì´ì¦ˆë¥¼ FC layerì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆê²Œ ì „ë¶€ ë™ì¼í•˜ê²Œ ê³ ì •ëœ ì‚¬ì´ì¦ˆë¡œ ë³€ê²½í•´ì¤˜ì•¼ í•œë‹¤. ì´ ë•Œ ë³€ê²½ëœ ì´ë¯¸ì§€ëŠ” warped image regionì´ë¼ê³  í•œë‹¤. Warped images ê°ê°ì€ CNN ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ ì‹œí‚¤ê³  classificationì„ ìœ„í•´ì„œ SVM(2014ë…„ì„ì„ ê³ ë ¤í•˜ì)ì„ ì‚¬ìš©í•œë‹¤. ë˜í•œ, RoIë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ regression ê³¼ì •ë„ ê±°ì¹œë‹¤. ë³´ì •ì˜ ê²½ìš° RoIì™€ bounding boxê°€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ offset ê°’ì„ 4ê°œ ì˜ˆì¸¡ í•´ì¤€ë‹¤ê³  ë³´ë©´ ëœë‹¤. R-CNN architecture - ì¶œì²˜ : CS231n â€‹ R-CNN ë°©ì‹ì€ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  selective searchë¥¼ í†µí•œ CNN ì—°ì‚°ì„ 2000ë²ˆ ë„˜ê²Œ ì—°ì‚°ìœ¼ë¡œ ì¸í•´ computational costê°€ ë†’ê³ , selective searchë„ cpuë¥¼ í†µí•œ ì—°ì‚°ì´ê¸° ë•Œë¬¸ì— ìƒëŒ€ì ìœ¼ë¡œ ì†ë„ê°€ ëŠë¦¬ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Fast R-CNNì´ ë“±ì¥ í–ˆë‹¤. Fast R-CNN Fast R-CNNì˜ ê²½ìš° ì•ì„œ ë§í•œ RCNNê³¼ ë™ì¼í•˜ê²Œ selective searchë¼ëŠ” region proposal methodë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, RCNNê³¼ ë‹¤ë¥¸ì ì€ selective searchë¡œ êµ¬í•œ RoI ê°ê°ì„ CNN ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼ì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ input image í•˜ë‚˜ì— ëŒ€í•´ CNNì— í†µê³¼ì‹œí‚¤ê³ , RoIë“¤ì€ ì¶•ì†Œëœ í˜•íƒœë¡œ ì—¬ëŸ¬ê°€ì§€ ì‚¬ì´ì¦ˆë¡œ feature mapì— ë‚˜íƒ€ë‚œë‹¤. ì´ë ‡ê²Œ í•œë‹¤ë©´, RCNNê³¼ ë‹¤ë¥´ê²Œ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ CNNì„ ì—°ì‚°í•˜ê³ , ê°ê°ì˜ RoIì— ëŒ€í•´ì„œ classificationê³¼ regressionì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— ë” íš¨ìœ¨ì ì´ë‹¤. ì¡°ê¸ˆ ë” ì„¸ë¶€í•˜ê²Œ ê³¼ì •ì„ ì‚´í”¼ìë©´, feature mapì˜ RoIë“¤ì€ ì‚¬ì´ì¦ˆê°€ ì œê°ê° ì´ê¸° ë•Œë¬¸ì— RoI poolingì´ë¼ëŠ” ê³¼ì •ì„ í†µí•´ì„œ FC layerì˜ ì…ë ¥ì— ë„£ì„ ìˆ˜ ìˆë„ë¡ ê³ ì •ëœ í¬ê¸°ì˜ vectorë¡œ ë³€í™˜í•´ì•¼í•œë‹¤. ì´ RoI feature vectorëŠ” softmax ì—°ì‚°ì„ í†µí•´ classificationì„ í•˜ê³ , bounding box regressionìœ¼ë¡œ bounding boxë¥¼ ìœ„í•œ ë³´ì •ê°’ì„ ì˜ˆì¸¡í•œë‹¤. Fast R-CNN architecture - ì¶œì²˜ : Fast R-CNN, CS231n Fast R-CNNì—ì„œë„ í•œê³„ì ì€ ìˆë‹¤. í•™ìŠµ ì‹œí‚¤ì§€ ì•ŠëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ì˜ selective searchê°€ bottleneckì˜ ì›ì¸ ë˜ì—ˆê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ Faster R-CNNì´ë¼ëŠ” ë°©ë²•ì´ ë“±ì¥í–ˆë‹¤. Faster R-CNN ì•ì˜ Fast R-CNNì˜ í•œê³„ëŠ” ê²°êµ­ region proposal ë‹¨ê³„ì˜ bottleneck ë•Œë¬¸ì´ë‹¤. Faster R-CNNì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„¤íŠ¸ì›Œí¬ê°€ region proposalì„ í•™ìŠµ í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê°„ë‹¨íˆ ë§í•˜ìë©´ RPN(Region Proposal Network)ë¥¼ RoI poolingê³¼ í•¨ê»˜ GPUë‹¨ì—ì„œ í•´ê²° í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. Faster R-CNN architecture - ì¶œì²˜ : CS231n ì§€ê¸ˆê¹Œì§€ ì„¤ëª…í•œ R-CNN ê³„ì—´ì˜ ë„¤íŠ¸ì›Œí¬ë“¤ì€ region based methodë¥¼ ì‚¬ìš©í•˜ëŠ” 2 stage detector ë°©ì‹ì´ë‹¤. ì´ ë‹¤ìŒìœ¼ë¡œ 1 stage detectorì™€ 2 stage detectorì˜ ì°¨ì´ ê·¸ë¦¬ê³  ëŒ€í‘œì ì¸ 1 stage detector ë°©ì‹ì¸ YOLOë¥¼ ì‚´í´ë³´ì. R-CNN comparison - ì¶œì²˜ : Recent Advances in Deep Learning for Object Detection 1-stage detector vs 2-stage detector 1 stage vs 2 stage - ì¶œì²˜ : A Survey of Deep Learning-Based Object Detection 2 stage detector localizationê³¼ classificationì„ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²° ì†ë„ê°€ ëŠë¦¼ RCNN familyê°€ ëŒ€í‘œì ì¸ 2 stage detector 1 stage detector localizationê³¼ classificationì„ ë™ì‹œì— í•´ê²° feature extractionê³¼ object detectionì´ ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì´ë£¨ì–´ì§€ëŠ” ê°„ë‹¨í•œ ë””ìì¸ ì†ë„ê°€ ë¹ ë¦„(real time detectionì´ ê°€ëŠ¥) ë‚®ì€ background error YOLOê°€ ëŒ€í‘œì ì¸ 1 stage detector Metrics For Object Detection Precision and Recall precision and recall - ì¶œì²˜ : https://www.datacamp.com/tutorial/precision-recall-curve-tutorial accuracy - ì¶œì²˜ : https://www.datacamp.com/tutorial/precision-recall-curve-tutorial Precision(ì •í™•ë„) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ëª¨ë¸ì´ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP+FP) Recall(ì¬í˜„ìœ¨) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ì‹¤ì œ ì •ë‹µ ë¬¼ì²´ì˜ ìˆ˜(TP+FN) ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì— ë”°ë¥¸ Trade Off ëª¨ë“  ì˜ì—­ì— ëŒ€í•˜ì—¬ ì „ë¬´ ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì¬í˜„ìœ¨ì€ ë†’ì•„ì§€ì§€ë§Œ ì •í™•ë„ê°€ ë–¨ì–´ì§„ë‹¤. í™•ì‹¤í•  ë•Œë§Œ(confident í•œ ê²½ìš°ë§Œ) ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì •í™•ë„ëŠ” ë†’ì•„ì§€ì§€ë§Œ, ì¬í˜„ìœ¨ì´ ë–¨ì–´ì§„ë‹¤. Mean Average Precision (mAP) ì¶œì²˜ - End-to-end training of object class detectors for mean average precision ì¶œì²˜ - End-to-end training of object class detectors for mean average precision Precisionê³¼ recallì€ ë³´í†µ ë°˜ë¹„ë¡€ ê´€ê³„ë¥¼ ê°€ì§„ë‹¤. mAPë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ê° í´ë˜ìŠ¤ì˜ average precision(AP)ë¥¼ ê³„ì‚°í•œë‹¤. APëŠ” ê° precision-recall ê·¸ë˜í”„ì˜ ë„“ì´ë¡œ ê³„ì‚° í•  ìˆ˜ ìˆë‹¤. ê·¸ ë‹¤ìŒ ëª¨ë“  APë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•˜ë©´ mAPë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. Intersection over Union (IoU) True Positive(TP)ì™€ False Positive(FP)ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ IoUë¥¼ ì‚¬ìš©í•œë‹¤. IoUë¥¼ ê°„ëµíˆ ì„¤ëª…í•˜ìë©´ ë‘ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨ë¡œ ìƒê° í•  ìˆ˜ ìˆë‹¤. ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ mAP@0.5ëŠ” ground truthì™€ predictionì˜ IoUê°€ 50% ì´ìƒì¼ ë•Œ ì •ë‹µìœ¼ë¡œ íŒì •í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ NMS ê³„ì‚°ì˜ ê²½ìš°, ê°™ì€ í´ë˜ìŠ¤ë¼ë¦¬ IoUê°€ 50% ì´ìƒì¼ ë•Œ ë‚®ì€ confidenceì˜ bounding boxë¥¼ ì œê±°í•œë‹¤ Non Maximum Suppression (NMS) ì˜ë¯¸ë§Œ í•´ì„í•˜ìë©´ ì œì¼ í° ê²ƒì„ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” suppress í•˜ìëŠ” ì˜ë¯¸ì´ë‹¤. Object detectionì—ì„œ í•˜ë‚˜ì˜ instanceì—ëŠ” í•˜ë‚˜ì˜ bounding boxê°€ ì ìš©ë˜ì–´ì•¼ í•œë‹¤. ê·¸ë ‡ê²Œ ë•Œë¬¸ì— í•˜ë‚˜ì˜ ë¬¼ì²´ì— ëŒ€í•´ ì—¬ëŸ¬ê°œì˜ bounding boxê°€ ê²¹ì³ì ¸ ìˆì„ ê²½ìš° í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë°©ë²•ì´ í•„ìš”í•˜ë‹¤. NMSëŠ” ë³´í†µ IoUê°€ íŠ¹ì • thresholdë¥¼ ë„˜ì–´ê°€ëŠ” ì¤‘ë³µë˜ëŠ” boxë¥¼ ì œê±°í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì¶œì²˜ - https://wikidocs.net/163295 YOLO (You Look Only Once) YOLO timeline - ì¶œì²˜ : https://www.researchgate.net/figure/Timeline-of-You-Only-Look-Once-YOLO-variants_fig1_369379818 YOLO v1 : í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì˜ bboxì™€ classificationì„ ë™ì‹œì— ì˜ˆì¸¡í•˜ëŠ” 1 stage detectorì˜ ë“±ì¥ YOLO v3 : multi scale feature mapì˜ ì‚¬ìš© YOLO v5 : small, medium, large í¬ê¸° ë³„ë¡œ ëª¨ë¸ êµ¬ì„± Unified Detection in YOLO detection in YOLO - ì¶œì²˜ : You Only Look Once YOLOì—ì„œ object detectionì„ regression problemìœ¼ë¡œ ì „í™˜í•´ì„œ í’€ê³  ìˆë‹¤. ë˜í•œ ê°„ë‹¨í•œ êµ¬ì¡°ì˜ end to end ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. YOLOì—ì„œ unified detectionì˜ ê³¼ì •ì„ ì„¤ëª…í•˜ìë©´, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ SxS ê·¸ë¦¬ë“œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ê·¸ë¦¬ë“œ ì˜ì—­ë§ˆë‹¤ Bê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³  Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. (parameter used in YOLO, S=7, B=2, C=20) Confidence scoreëŠ” ê·¸ë¦¬ë“œì—ì„œ (objectê°€ ì¡´ì¬í•  í™•ë¥ ) x (ground truthì™€ IoU)ë¡œ ê³„ì‚°í•œë‹¤. ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. \\(confidence = Pr(object) \\times IoU^{truth}_{pred}\\) Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤. \\(class probability = Pr(Class_{i}|Object)\\) ê°„ë‹¨í•˜ê²Œ ìš”ì•½ì„ í•˜ìë©´, input ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì´ë¯¸ì§€ë¥¼ 7x7(49ê°œ)ì˜ ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ„ê³ , ê° ê·¸ë¦¬ë“œ ë§ˆë‹¤ 2ê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³ , ê° ê·¸ë¦¬ë“œ(49ê°œì˜ ê·¸ë¦¬ë“œ)ë§ˆë‹¤ ì–´ë–¤ í´ë˜ìŠ¤ì¸ì§€ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. Network Design of YOLO YOLO&#39;s architecture - ì¶œì²˜ : You Only Look Once googlenetì˜ ë³€í˜• ì‚¬ìš© 24 conv layers for feature extraction 2 fully connected layers for prediction output tensor of YOLO - ì¶œì²˜ : https://wikidocs.net/187967 outputì€ 7x7x30ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ bbox 1, 2ì— ëŒ€í•œ (xì¢Œí‘œ, yì¢Œí‘œ, ë„ˆë¹„, ë†’ì´, confidence score) + 20ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  Inference ê° bounding boxì˜ confidence scoreë¥¼ 20ê°œì˜ í´ë˜ìŠ¤ í™•ë¥ ê³¼ ê³±í•´ì„œ ê° bounding boxê°€ ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì–´ë–¤ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. YOLO test time - ì¶œì²˜ : You Only Look Once 49ê°œì˜ ê·¸ë¦¬ë“œë‹¹ 2ê°œì˜ bounding boxë¥¼ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— ì´ 98ê°œì˜ boxì— ëŒ€í•œ class specific confidence scoreë¥¼ ê³„ì‚°í•œë‹¤. Advantages and Disadvantages of YOLO ì¥ì  ì†ë„ê°€ ë¹¨ë¼ì„œ real time detectionì— í™œìš© ê°€ëŠ¥í•˜ë‹¤ ë¬¼ì²´ì˜ ì¼ë°˜í™”ëœ íŠ¹ì§•ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ ë‹¨ì  ê·¸ë¦¬ë“œë³´ë‹¤ ì‘ì€ í¬ê¸°ì˜ ë¬¼ì²´ ê²€ì¶œì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ ì‹ ê²½ë§ì„ í†µê³¼í•  ë•Œ ë§ˆì§€ë§‰ featureë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì •í™•ë„ê°€ í•˜ë½í•œë‹¤ Further Studying Object Detectionì˜ milestoneì„ í™•ì¸í•´ë³´ê¸° YOLO vs SSD ë¹„êµí•´ë³´ê¸° ìµœê·¼ SOTA Object Detection ëª¨ë¸ë“¤ì˜ íŠ¸ë Œë“œ ì‚´í´ë³´ê¸° ì°¸ê³  You Only Look Once: Unified, Real-Time Object Detection End-to-end training of object class detectors for mean average precision Rich feature hierarchies for accurate object detection and semantic segmentation boostcourse : ì¬í™œìš© ì“°ë ˆê¸°ë¥¼ í™œìš©í•œ ë”¥ëŸ¬ë‹ - Detection CS231n","headline":"Object Detection Overview","image":"http://localhost:4000/post_images/objectdetection.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/objectdetection/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"seungki"},"url":"http://localhost:4000/objectdetection/"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<link href="/assets/css/custom.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="Seungki1011's Dev Blog">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/about">About Me</a>
                </li>

                <!-- <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/wowthemesnet/mediumish-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>
                </li> -->

                <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">Seungki1011's Dev Blog</h1>
    <p class="lead">
        ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ì˜ ê³µë¶€ ë¸”ë¡œê·¸ ğŸ™‚
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Object Detection Overview&url=http://localhost:4000/objectdetection/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/objectdetection/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/objectdetection/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="/assets/images/avatar.png" alt="Seungki">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="">Seungki</a><a target="_blank" href="" class="btn follow">Follow</a>
                        <span class="author-description">Trying to find a career for ML engineering in Seoul & Pangyo.</span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Object Detection Overview</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid" src="/post_images/objectdetection.jpeg" alt="Object Detection Overview">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#object-detection">Object Detection</a>
    <ul>
      <li><a href="#classification--localization">Classification + Localization</a></li>
      <li><a href="#what-is-object-detection">What is Object Detection?</a></li>
      <li><a href="#ideas-used-for-object-detection">Ideas Used for Object Detection</a>
        <ul>
          <li><a href="#sliding-window">Sliding Window</a></li>
          <li><a href="#region-proposalroi---regions-of-interest">Region Proposal(RoI - Regions of Interest)</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#r-cnn">R-CNN</a></li>
  <li><a href="#fast-r-cnn">Fast R-CNN</a></li>
  <li><a href="#faster-r-cnn">Faster R-CNN</a></li>
  <li><a href="#1-stage-detector-vs-2-stage-detector">1-stage detector vs 2-stage detector</a>
    <ul>
      <li><a href="#2-stage-detector">2 stage detector</a></li>
      <li><a href="#1-stage-detector">1 stage detector</a></li>
    </ul>
  </li>
  <li><a href="#metrics-for-object-detection">Metrics For Object Detection</a>
    <ul>
      <li><a href="#precision-and-recall">Precision and Recall</a></li>
      <li><a href="#ì •í™•ë„ì™€-ì¬í˜„ìœ¨ì—-ë”°ë¥¸-trade-off">ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì— ë”°ë¥¸ Trade Off</a></li>
      <li><a href="#mean-average-precision-map">Mean Average Precision (mAP)</a></li>
      <li><a href="#intersection-over-union-iou">Intersection over Union (IoU)</a></li>
      <li><a href="#non-maximum-suppression-nms">Non Maximum Suppression (NMS)</a></li>
    </ul>
  </li>
  <li><a href="#yolo-you-look-only-once">YOLO (You Look Only Once)</a>
    <ul>
      <li><a href="#unified-detection-in-yolo">Unified Detection in YOLO</a></li>
      <li><a href="#network-design-of-yolo">Network Design of YOLO</a></li>
      <li><a href="#inference">Inference</a></li>
      <li><a href="#advantages-and-disadvantages-of-yolo">Advantages and Disadvantages of YOLO</a>
        <ul>
          <li><a href="#ì¥ì ">ì¥ì </a></li>
          <li><a href="#ë‹¨ì ">ë‹¨ì </a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#further-studying">Further Studying</a></li>
  <li><a href="#ì°¸ê³ ">ì°¸ê³ </a></li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <hr />
<h2 id="object-detection">Object Detection</h2>
<h3 id="classification--localization">Classification + Localization</h3>
<p>í•˜ë‚˜ì˜ ê°ì²´ì— ëŒ€í•´ì„œ í´ë˜ìŠ¤ë¥¼ íŒë³„ í•˜ê³ , ê·¸ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ëŠ” bounding boxë¥¼ ì°¾ì•„ì£¼ëŠ” ì‘ì—…ì„ classification and localization taskë¼ê³  í•œë‹¤. ê¸°ë³¸ì ì¸ ì•„í‚¤í…ì³ì˜ ê²½ìš° CNN ë„¤íŠ¸ì›Œí¬ì— class scoreë¥¼ ì •í•´ì£¼ëŠ” FC layerì™€ box coordinateì„ ì •í•´ì£¼ëŠ” FC layerë¡œ êµ¬ì„±ëœë‹¤.</p>

<p>ì´ ê²½ìš° ê³„ì‚°í•˜ëŠ” lossëŠ” ë‘ ê°œì´ê³ , í•™ìŠµí•˜ëŠ” dataëŠ” ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ê³¼ bounding boxê°€ ì •í•´ì§„ ground truthë¥¼ ê°€ì§„ í˜•íƒœì´ë‹¤. í•™ìŠµì„ í•  ë•Œ ë‘ ê°œì˜ lossì— ëŒ€í•œ ê°€ì¤‘í•©ì„ í•™ìŠµí•œë‹¤. ì´ ë•Œ ê° lossì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ hyper parameter í˜•íƒœë¡œ ì¡°ì ˆí•´ì¤˜ì•¼í•˜ê³ , ì´ëŸ° multi-lossì— ëŒ€í•œ hyper parameterë¥¼ ê²°ì •í•˜ëŠ” ì‘ì—…ì€ ê¹Œë‹¤ë¡­ë‹¤.</p>

<p><img src="../post_images/objectdetection/localization and classification.PNG" alt="localization and classification" style="zoom:67%;" class="center-image" /></p>

<p align="center">two losses for classification and localization - ì¶œì²˜ : CS231n </p>

<h3 id="what-is-object-detection">What is Object Detection?</h3>

<p>ì•ì„œ ë§í•œ classification + localizationê³¼ëŠ” ë‹¤ë¥´ê²Œ ê°ì²´ê°€ ì—¬ëŸ¬ê°œê°€ ì¡´ì¬í•´ì„œ, ê° ê°ì²´ì— ëŒ€í•œ bounding boxì™€ classë¥¼ ì •í•´ì¤˜ì•¼ í•˜ëŠ” taskì´ë‹¤. Object detectionì€ ê²°êµ­ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë‚´ì—ì„œ multi objectì— ëŒ€í•œ classification and localizationì„ í•œë‹¤ê³  ë³´ë©´ ëœë‹¤(í•™ìŠµì„ ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¤ë¦„).</p>

<p><img src="../post_images/objectdetection/object detection 1.PNG" alt="object detection 1" style="zoom:67%;" class="center-image" /></p>

<p align="center">ì¶œì²˜ - YOLOv3: An Incremental Improvement </p>

<h3 id="ideas-used-for-object-detection">Ideas Used for Object Detection</h3>

<h4 id="sliding-window">Sliding Window</h4>

<p>Object detectionì„ ìœ„í•´ ì´ˆê¸°ì— ì‹œë„ ë˜ì—ˆë˜ ë°©ë²•ì´ë‹¤. Windowë¥¼ ì´ë¯¸ì§€ ë‚´ì—ì„œ sliding(ì´ë™) ì‹œí‚¤ë©´ì„œ ëª¨ë“  windowì˜ ê²½ìš°ì— ëŒ€í•´ classificationì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ì´ë‹¤. Semantic segmentationì˜ sliding windowì™€ ê±°ì˜ ë™ì¼í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° brute force ë°©ì‹ì˜ ì ‘ê·¼ì€ ê²°êµ­ ë„ˆë¬´ ë†’ì€ computational costë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì—, íŠ¹íˆ ë†’ì€ ìš©ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” computer visionì—ì„œ ì§€ì–‘í•´ì•¼í•œë‹¤.</p>

<p><img src="../post_images/objectdetection/sliding_window_example.gif" alt="sliding_window_example" style="zoom:100%;" class="center-image" /></p>

<p align="center">sliding window</p>

<h4 id="region-proposalroi---regions-of-interest">Region Proposal(RoI - Regions of Interest)</h4>

<p>ê°ì²´ê°€ ìˆì„ ë²•í•œ í›„ë³´êµ°ë“¤ì˜ region ì°¾ì•„ì„œ ê·¸ regionë“¤ì— ëŒ€í•´ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ì´ë‹¤. ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ìë©´, region proposalì„ ë½‘ì•„ì„œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì¤˜ì„œ object detectionì„ ìˆ˜í–‰í•œë‹¤ê³  ë³´ë©´ ëœë‹¤. ì´ ê²½ìš° ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ ë§ê³  ëª‡ëª‡(~2k)ê°œì˜ í›„ë³´êµ°ë§Œ í™•ì¸í•˜ë©´ ë˜ëŠ” ë°©ì‹ì´ë¼ê³  brute forceë³´ë‹¤ íš¨ìœ¨ì ì´ë‹¤. Region proposal ë°©ì‹ì€ R-CNN(<a href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a>)ì˜ ë…¼ë¬¸ì— ì²˜ìŒ ì†Œê°œ ë˜ì—ˆë‹¤.</p>

<hr />

<h2 id="r-cnn">R-CNN</h2>

<p>R-CNNì€ selective searchë¼ëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë²•(í•™ìŠµ x)ì„ í†µí•´ RoIë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤. ë½‘íŒ RoIì˜ ì‚¬ì´ì¦ˆëŠ” ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì—, classificationì„ ìœ„í•œ CNN ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ê¸° ìœ„í•´ì„œëŠ” imageì˜ ì‚¬ì´ì¦ˆë¥¼ FC layerì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆê²Œ ì „ë¶€ ë™ì¼í•˜ê²Œ ê³ ì •ëœ ì‚¬ì´ì¦ˆë¡œ ë³€ê²½í•´ì¤˜ì•¼ í•œë‹¤. ì´ ë•Œ ë³€ê²½ëœ ì´ë¯¸ì§€ëŠ” warped image regionì´ë¼ê³  í•œë‹¤. Warped images ê°ê°ì€ CNN ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ ì‹œí‚¤ê³  classificationì„ ìœ„í•´ì„œ SVM(2014ë…„ì„ì„ ê³ ë ¤í•˜ì)ì„ ì‚¬ìš©í•œë‹¤. ë˜í•œ, RoIë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ regression ê³¼ì •ë„ ê±°ì¹œë‹¤. ë³´ì •ì˜ ê²½ìš° RoIì™€ bounding boxê°€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ë³´ì •í•˜ê¸° ìœ„í•œ offset ê°’ì„ 4ê°œ ì˜ˆì¸¡ í•´ì¤€ë‹¤ê³  ë³´ë©´ ëœë‹¤.</p>

<p><img src="../post_images/objectdetection/RCNN1.PNG" alt="RCNN1" style="zoom:67%;" class="center-image" /></p>

<p align="center">R-CNN architecture - ì¶œì²˜ : CS231n </p>

<p>â€‹</p>

<p>R-CNN ë°©ì‹ì€ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  selective searchë¥¼ í†µí•œ CNN ì—°ì‚°ì„ 2000ë²ˆ ë„˜ê²Œ ì—°ì‚°ìœ¼ë¡œ ì¸í•´ computational costê°€ ë†’ê³ , selective searchë„ cpuë¥¼ í†µí•œ ì—°ì‚°ì´ê¸° ë•Œë¬¸ì— ìƒëŒ€ì ìœ¼ë¡œ ì†ë„ê°€ ëŠë¦¬ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Fast R-CNNì´ ë“±ì¥ í–ˆë‹¤.</p>

<hr />

<h2 id="fast-r-cnn">Fast R-CNN</h2>

<p>Fast R-CNNì˜ ê²½ìš° ì•ì„œ ë§í•œ RCNNê³¼ ë™ì¼í•˜ê²Œ selective searchë¼ëŠ” region proposal methodë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, RCNNê³¼ ë‹¤ë¥¸ì ì€ selective searchë¡œ êµ¬í•œ RoI ê°ê°ì„ CNN ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼ì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ input image í•˜ë‚˜ì— ëŒ€í•´ CNNì— í†µê³¼ì‹œí‚¤ê³ , RoIë“¤ì€ ì¶•ì†Œëœ í˜•íƒœë¡œ ì—¬ëŸ¬ê°€ì§€ ì‚¬ì´ì¦ˆë¡œ feature mapì— ë‚˜íƒ€ë‚œë‹¤. ì´ë ‡ê²Œ í•œë‹¤ë©´, RCNNê³¼ ë‹¤ë¥´ê²Œ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ CNNì„ ì—°ì‚°í•˜ê³ , ê°ê°ì˜ RoIì— ëŒ€í•´ì„œ classificationê³¼ regressionì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— ë” íš¨ìœ¨ì ì´ë‹¤. ì¡°ê¸ˆ ë” ì„¸ë¶€í•˜ê²Œ ê³¼ì •ì„ ì‚´í”¼ìë©´, feature mapì˜ RoIë“¤ì€ ì‚¬ì´ì¦ˆê°€ ì œê°ê° ì´ê¸° ë•Œë¬¸ì— RoI poolingì´ë¼ëŠ” ê³¼ì •ì„ í†µí•´ì„œ FC layerì˜ ì…ë ¥ì— ë„£ì„ ìˆ˜ ìˆë„ë¡ ê³ ì •ëœ í¬ê¸°ì˜ vectorë¡œ ë³€í™˜í•´ì•¼í•œë‹¤. ì´ RoI feature vectorëŠ” softmax ì—°ì‚°ì„ í†µí•´ classificationì„ í•˜ê³ , bounding box regressionìœ¼ë¡œ bounding boxë¥¼ ìœ„í•œ ë³´ì •ê°’ì„ ì˜ˆì¸¡í•œë‹¤.</p>

<p><img src="../post_images/objectdetection/fRCNN architecture 1.png" alt="fRCNN architecture 1" style="zoom:67%;" class="center-image" /></p>

<p align="center">Fast R-CNN architecture - ì¶œì²˜ : Fast R-CNN, CS231n </p>

<p>Fast R-CNNì—ì„œë„ í•œê³„ì ì€ ìˆë‹¤. í•™ìŠµ ì‹œí‚¤ì§€ ì•ŠëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ì˜ selective searchê°€ bottleneckì˜ ì›ì¸ ë˜ì—ˆê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ Faster R-CNNì´ë¼ëŠ” ë°©ë²•ì´ ë“±ì¥í–ˆë‹¤.</p>

<hr />

<h2 id="faster-r-cnn">Faster R-CNN</h2>

<p>ì•ì˜ Fast R-CNNì˜ í•œê³„ëŠ” ê²°êµ­ region proposal ë‹¨ê³„ì˜ bottleneck ë•Œë¬¸ì´ë‹¤. Faster R-CNNì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„¤íŠ¸ì›Œí¬ê°€ region proposalì„ í•™ìŠµ í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê°„ë‹¨íˆ ë§í•˜ìë©´ RPN(Region Proposal Network)ë¥¼ RoI poolingê³¼ í•¨ê»˜ GPUë‹¨ì—ì„œ í•´ê²° í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤.</p>

<p><img src="../post_images/objectdetection/Faster RCNN architecture 2.PNG" alt="Faster RCNN architecture 2" style="zoom:67%;" class="center-image" /></p>

<p align="center">Faster R-CNN architecture - ì¶œì²˜ : CS231n </p>

<p>ì§€ê¸ˆê¹Œì§€ ì„¤ëª…í•œ R-CNN ê³„ì—´ì˜ ë„¤íŠ¸ì›Œí¬ë“¤ì€ region based methodë¥¼ ì‚¬ìš©í•˜ëŠ” 2 stage detector ë°©ì‹ì´ë‹¤. ì´ ë‹¤ìŒìœ¼ë¡œ 1 stage detectorì™€ 2 stage detectorì˜ ì°¨ì´ ê·¸ë¦¬ê³  ëŒ€í‘œì ì¸ 1 stage detector ë°©ì‹ì¸ YOLOë¥¼ ì‚´í´ë³´ì.</p>

<p><img src="../post_images/objectdetection/rcnná„€á…¨á„‹á…§á†¯á„‡á…µá„€á…­.PNG" alt="rcnná„€á…¨á„‹á…§á†¯á„‡á…µá„€á…­" style="zoom:100%;" class="center-image" /></p>

<p align="center">R-CNN comparison - ì¶œì²˜ : Recent Advances in Deep Learning for Object Detection </p>

<hr />

<h2 id="1-stage-detector-vs-2-stage-detector">1-stage detector vs 2-stage detector</h2>

<p><img src="../post_images/objectdetection/1stage vs 2 stage.png" alt="1stage vs 2 stage" style="zoom:67%;" class="center-image" /></p>

<p align="center">1 stage vs 2 stage - ì¶œì²˜ : A Survey of Deep Learning-Based Object Detection </p>

<h3 id="2-stage-detector">2 stage detector</h3>

<ul>
  <li>localizationê³¼ classificationì„ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²°</li>
  <li>ì†ë„ê°€ ëŠë¦¼</li>
  <li>RCNN familyê°€ ëŒ€í‘œì ì¸ 2 stage detector</li>
</ul>

<h3 id="1-stage-detector">1 stage detector</h3>

<ul>
  <li>localizationê³¼ classificationì„ ë™ì‹œì— í•´ê²°</li>
  <li>feature extractionê³¼ object detectionì´ ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì´ë£¨ì–´ì§€ëŠ” ê°„ë‹¨í•œ ë””ìì¸</li>
  <li>ì†ë„ê°€ ë¹ ë¦„(real time detectionì´ ê°€ëŠ¥)</li>
  <li>ë‚®ì€ background error</li>
  <li>YOLOê°€ ëŒ€í‘œì ì¸ 1 stage detector</li>
</ul>

<hr />

<h2 id="metrics-for-object-detection">Metrics For Object Detection</h2>

<h3 id="precision-and-recall">Precision and Recall</h3>

<p><img src="../post_images/objectdetection/Precision_recall_Representation_1052507280.png" alt="Precision_recall_Representation_1052507280" style="zoom:67%;" class="center-image" /></p>

<p align="center">precision and recall - ì¶œì²˜ : 
https://www.datacamp.com/tutorial/precision-recall-curve-tutorial </p>

<p><img src="../post_images/objectdetection/Precision_Recall_Accuracy_f1a9096d20.png" alt="Precision_Recall_Accuracy_f1a9096d20" style="zoom:80%;" class="center-image" /></p>

<p align="center">accuracy - ì¶œì²˜ : 
https://www.datacamp.com/tutorial/precision-recall-curve-tutorial </p>

<ul>
  <li>
    <p>Precision(ì •í™•ë„) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ëª¨ë¸ì´ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP+FP)</p>
  </li>
  <li>
    <p>Recall(ì¬í˜„ìœ¨) - ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¬¼ì²´ì˜ ìˆ˜(TP) / ì‹¤ì œ ì •ë‹µ ë¬¼ì²´ì˜ ìˆ˜(TP+FN)</p>
  </li>
</ul>

<h3 id="ì •í™•ë„ì™€-ì¬í˜„ìœ¨ì—-ë”°ë¥¸-trade-off">ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì— ë”°ë¥¸ Trade Off</h3>

<p>ëª¨ë“  ì˜ì—­ì— ëŒ€í•˜ì—¬ ì „ë¬´ ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì¬í˜„ìœ¨ì€ ë†’ì•„ì§€ì§€ë§Œ ì •í™•ë„ê°€ ë–¨ì–´ì§„ë‹¤.</p>

<p>í™•ì‹¤í•  ë•Œë§Œ(confident í•œ ê²½ìš°ë§Œ) ë¬¼ì²´ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ì„ í•˜ëŠ” ê²½ìš°, ì •í™•ë„ëŠ” ë†’ì•„ì§€ì§€ë§Œ, ì¬í˜„ìœ¨ì´ ë–¨ì–´ì§„ë‹¤.</p>

<h3 id="mean-average-precision-map">Mean Average Precision (mAP)</h3>

<p><img src="../post_images/objectdetection/mAP.PNG" alt="mAP" style="zoom:100%;" class="center-image" /></p>

<p align="center">ì¶œì²˜ - 
End-to-end training of object class detectors for mean average precision </p>

<p><img src="../post_images/objectdetection/average precision.PNG" alt="average precision" style="zoom:100%;" class="center-image" /></p>

<p align="center">ì¶œì²˜ - 
End-to-end training of object class detectors for mean average precision </p>

<ul>
  <li>Precisionê³¼ recallì€ ë³´í†µ ë°˜ë¹„ë¡€ ê´€ê³„ë¥¼ ê°€ì§„ë‹¤.</li>
  <li>mAPë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ê° í´ë˜ìŠ¤ì˜ average precision(AP)ë¥¼ ê³„ì‚°í•œë‹¤. APëŠ” ê° precision-recall ê·¸ë˜í”„ì˜ ë„“ì´ë¡œ ê³„ì‚° í•  ìˆ˜ ìˆë‹¤. ê·¸ ë‹¤ìŒ ëª¨ë“  APë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•˜ë©´ mAPë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

<h3 id="intersection-over-union-iou">Intersection over Union (IoU)</h3>

<p>True Positive(TP)ì™€ False Positive(FP)ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ  IoUë¥¼ ì‚¬ìš©í•œë‹¤. IoUë¥¼ ê°„ëµíˆ ì„¤ëª…í•˜ìë©´ ë‘ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨ë¡œ ìƒê° í•  ìˆ˜ ìˆë‹¤.</p>

<p><img src="../post_images/objectdetection/iou_stop_sign.png" alt="iou_stop_sign" style="zoom:67%;" class="center-image" /></p>

<p align="center">ì¶œì²˜ - pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ </p>

<p><img src="../post_images/objectdetection/iou_equation.png" alt="iou_equation" style="zoom:100%;" class="center-image" /></p>

<p align="center">ì¶œì²˜ - 
pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/ </p>

<ul>
  <li>mAP@0.5ëŠ” ground truthì™€ predictionì˜ IoUê°€ 50% ì´ìƒì¼ ë•Œ ì •ë‹µìœ¼ë¡œ íŒì •í•˜ê² ë‹¤ëŠ” ì˜ë¯¸</li>
  <li>NMS ê³„ì‚°ì˜ ê²½ìš°, ê°™ì€ í´ë˜ìŠ¤ë¼ë¦¬ IoUê°€ 50% ì´ìƒì¼ ë•Œ ë‚®ì€ confidenceì˜ bounding boxë¥¼ ì œê±°í•œë‹¤</li>
</ul>

<h3 id="non-maximum-suppression-nms">Non Maximum Suppression (NMS)</h3>

<p>ì˜ë¯¸ë§Œ í•´ì„í•˜ìë©´ ì œì¼ í° ê²ƒì„ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” suppress í•˜ìëŠ” ì˜ë¯¸ì´ë‹¤. Object detectionì—ì„œ í•˜ë‚˜ì˜ instanceì—ëŠ” í•˜ë‚˜ì˜ bounding boxê°€ ì ìš©ë˜ì–´ì•¼ í•œë‹¤. ê·¸ë ‡ê²Œ ë•Œë¬¸ì— í•˜ë‚˜ì˜ ë¬¼ì²´ì— ëŒ€í•´ ì—¬ëŸ¬ê°œì˜ bounding boxê°€ ê²¹ì³ì ¸ ìˆì„ ê²½ìš° í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë°©ë²•ì´ í•„ìš”í•˜ë‹¤. NMSëŠ” ë³´í†µ IoUê°€ íŠ¹ì • thresholdë¥¼ ë„˜ì–´ê°€ëŠ” ì¤‘ë³µë˜ëŠ” boxë¥¼ ì œê±°í•˜ëŠ” ë°©ì‹ì´ë‹¤.</p>

<p><img src="../post_images/objectdetection/NMS_4.png" alt="NMS_4" style="zoom:100%;" class="center-image" /></p>

<p align="center">ì¶œì²˜ - 
https://wikidocs.net/163295 </p>

<hr />

<h2 id="yolo-you-look-only-once">YOLO (You Look Only Once)</h2>

<p><img src="../post_images/objectdetection/Timeline-of-You-Only-Look-Once-YOLO-variants.png" alt="Timeline-of-You-Only-Look-Once-YOLO-variants" style="zoom:100%;" class="center-image" /></p>

<p align="center">YOLO timeline - ì¶œì²˜ : https://www.researchgate.net/figure/Timeline-of-You-Only-Look-Once-YOLO-variants_fig1_369379818 </p>

<ul>
  <li>YOLO v1 : í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì˜ bboxì™€ classificationì„ ë™ì‹œì— ì˜ˆì¸¡í•˜ëŠ” 1 stage detectorì˜ ë“±ì¥</li>
  <li>YOLO v3 : multi scale feature mapì˜ ì‚¬ìš©</li>
  <li>YOLO v5 : small, medium, large í¬ê¸° ë³„ë¡œ ëª¨ë¸ êµ¬ì„±</li>
</ul>

<h3 id="unified-detection-in-yolo">Unified Detection in YOLO</h3>

<p><img src="../post_images/objectdetection/yolo unified detection.PNG" alt="yolo unified detection" style="zoom:67%;" class="center-image" /></p>

<p align="center">detection in YOLO  - ì¶œì²˜ : You Only Look Once</p>

<p>YOLOì—ì„œ object detectionì„ regression problemìœ¼ë¡œ ì „í™˜í•´ì„œ í’€ê³  ìˆë‹¤. ë˜í•œ ê°„ë‹¨í•œ êµ¬ì¡°ì˜ end to end ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. YOLOì—ì„œ unified detectionì˜ ê³¼ì •ì„ ì„¤ëª…í•˜ìë©´, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ SxS ê·¸ë¦¬ë“œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ê·¸ë¦¬ë“œ ì˜ì—­ë§ˆë‹¤ Bê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³  Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. (parameter used in YOLO, S=7, B=2, C=20)</p>

<p>Confidence scoreëŠ” ê·¸ë¦¬ë“œì—ì„œ (objectê°€ ì¡´ì¬í•  í™•ë¥ ) x (ground truthì™€ IoU)ë¡œ ê³„ì‚°í•œë‹¤. ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
\(confidence = Pr(object) \times IoU^{truth}_{pred}\)
Cê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤.
\(class probability = Pr(Class_{i}|Object)\)
ê°„ë‹¨í•˜ê²Œ ìš”ì•½ì„ í•˜ìë©´, input ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì´ë¯¸ì§€ë¥¼ 7x7(49ê°œ)ì˜ ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ„ê³ , ê° ê·¸ë¦¬ë“œ ë§ˆë‹¤ 2ê°œì˜ bounding boxì™€ confidence scoreë¥¼ ê³„ì‚°í•˜ê³ , ê° ê·¸ë¦¬ë“œ(49ê°œì˜ ê·¸ë¦¬ë“œ)ë§ˆë‹¤ ì–´ë–¤ í´ë˜ìŠ¤ì¸ì§€ í•´ë‹¹ í´ë˜ìŠ¤ì¼  í™•ë¥ ì„ ê³„ì‚°í•œë‹¤.</p>

<h3 id="network-design-of-yolo">Network Design of YOLO</h3>

<p><img src="../post_images/objectdetection/yolo design.PNG" alt="yolo design" style="zoom:100%;" class="center-image" /></p>

<p align="center">YOLO's architecture  - ì¶œì²˜ : You Only Look Once</p>

<ul>
  <li>
    <p>googlenetì˜ ë³€í˜• ì‚¬ìš©</p>
  </li>
  <li>
    <p>24 conv layers for feature extraction</p>
  </li>
  <li>
    <p>2 fully connected layers for prediction</p>
  </li>
</ul>

<p><img src="../post_images/objectdetection/yolo output.PNG" alt="yolo output" style="zoom:100%;" class="center-image" /></p>

<p align="center">output tensor of YOLO  - ì¶œì²˜ : https://wikidocs.net/187967</p>

<ul>
  <li>outputì€ 7x7x30ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤</li>
  <li>bbox 1, 2ì— ëŒ€í•œ (xì¢Œí‘œ, yì¢Œí‘œ, ë„ˆë¹„, ë†’ì´, confidence score) + 20ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ </li>
</ul>

<h3 id="inference">Inference</h3>

<p>ê° bounding boxì˜ confidence scoreë¥¼ 20ê°œì˜ í´ë˜ìŠ¤ í™•ë¥ ê³¼ ê³±í•´ì„œ ê° bounding boxê°€ ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì–´ë–¤ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤.</p>

<p><img src="../post_images/objectdetection/yolo tt.PNG" alt="yolo tt" style="zoom:100%;" class="center-image" /></p>

<p align="center">YOLO test time  - ì¶œì²˜ : You Only Look Once</p>

<p>49ê°œì˜ ê·¸ë¦¬ë“œë‹¹ 2ê°œì˜ bounding boxë¥¼ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— ì´ 98ê°œì˜ boxì— ëŒ€í•œ class specific confidence scoreë¥¼ ê³„ì‚°í•œë‹¤.</p>

<h3 id="advantages-and-disadvantages-of-yolo">Advantages and Disadvantages of YOLO</h3>

<h4 id="ì¥ì ">ì¥ì </h4>

<ul>
  <li>ì†ë„ê°€ ë¹¨ë¼ì„œ real time detectionì— í™œìš© ê°€ëŠ¥í•˜ë‹¤</li>
  <li>ë¬¼ì²´ì˜ ì¼ë°˜í™”ëœ íŠ¹ì§•ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤</li>
</ul>

<h4 id="ë‹¨ì ">ë‹¨ì </h4>

<ul>
  <li>ê·¸ë¦¬ë“œë³´ë‹¤ ì‘ì€ í¬ê¸°ì˜ ë¬¼ì²´ ê²€ì¶œì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤</li>
  <li>ì‹ ê²½ë§ì„ í†µê³¼í•  ë•Œ ë§ˆì§€ë§‰ featureë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì •í™•ë„ê°€ í•˜ë½í•œë‹¤</li>
</ul>

<hr />

<h2 id="further-studying">Further Studying</h2>

<ol>
  <li>Object Detectionì˜ milestoneì„ í™•ì¸í•´ë³´ê¸°</li>
  <li>YOLO vs SSD ë¹„êµí•´ë³´ê¸°</li>
  <li>ìµœê·¼ SOTA Object Detection ëª¨ë¸ë“¤ì˜ íŠ¸ë Œë“œ ì‚´í´ë³´ê¸°</li>
</ol>

<p><br /></p>

<h2 id="ì°¸ê³ ">ì°¸ê³ </h2>

<hr />

<ol>
  <li><a href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a></li>
  <li><a href="https://arxiv.org/abs/1607.03476">End-to-end training of object class detectors for mean average precision</a></li>
  <li><a href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a></li>
  <li><a href="https://www.boostcourse.org/ai341">boostcourse : ì¬í™œìš© ì“°ë ˆê¸°ë¥¼ í™œìš©í•œ ë”¥ëŸ¬ë‹ - Detection</a></li>
  <li><a href="https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk">CS231n</a></li>
</ol>

            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2023-04-29">29 Apr 2023</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/categories#CV">CV</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Object-Detection">Object Detection</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="//Docker-Basic-1/"> &laquo; Docker Basic - 1</a>
            
            
            <a class="next d-block col-md-6 text-lg-right" href="//Debugging/">Debugging &raquo; </a>
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'roadtoml'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

</div>


<!-- Bottom Alert Bar
================================================== -->
<div class="alertbar">
	<div class="container text-center">
		<span class="center-vertically"> <a href="https://github.com/seungki1011" target="_blank"><img src="../assets/images/github-mark.png" alt="Seungki1011's Dev Blog"><b class="bold-with-margin">&nbsp; My Github</b></a></span>
        <!-- <form action="" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate>
            <div class="mc-field-group">
            <input type="email" placeholder="Email" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required>
            <input type="submit" value="Subscribe" name="subscribe" class="heart">
            </div>
        </form> -->
	</div>
</div>

    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">â†’</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="/categories#Python">Python (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Software-Engineering">Software Engineering (5)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Linux">Linux (3)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Docker">Docker (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#CV">CV (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Object-Detection">Object Detection (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Debugging">Debugging (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Segmentation">Segmentation (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Cloud">Cloud (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#CI/CD">CI/CD (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Backend">Backend (4)</a>
                
                    <a class="mt-1 mb-1" href="/categories#FastAPI">FastAPI (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#DB">DB (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Data">Data (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Airflow">Airflow (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Mlops">Mlops (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#MLflow">MLflow (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#MLops">MLops (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#BentoML">BentoML (1)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright Â© 2023 Seungki1011's Dev Blog 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//roadtoml.disqus.com/count.js"></script>


</body>
</html>
